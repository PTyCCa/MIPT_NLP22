{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"\"Fine-tuned NER.ipynb\" try 90\"",
      "provenance": [],
      "collapsed_sections": [
        "JDKwo_nVVwb_",
        "XRQxl71HzPlB",
        "StpXkWt7z3xa",
        "znaSoIXhiroZ",
        "yIzeoTSkmOUv",
        "e7ZGAYSlnCWg",
        "TRl-b0BHIreg",
        "XWiP2CZ_FnH8",
        "fVlzbA51Fan3",
        "y-NtDnfT8dcM",
        "hUzVT37ex4oR",
        "EbvNGlZ298Qm",
        "ESgCyGxqAgH8",
        "3pPi8m_LCg_X",
        "jXbSqyXxE_yM",
        "Ty7uVyma351k"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "rm -rf /usr/local/cuda \n",
        "ln -s /usr/local/cuda-10.1 /usr/local/cuda"
      ],
      "metadata": {
        "id": "e7GaH_dD05c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW2**\n",
        "## **Named Entity Recognition**\n",
        "*deadline*: **25-03-2022 00:30**\n",
        "\n",
        "You should build your own NER system. You can use all pretrained models except models that trained on our test set. Data for this HW was taken from https://github.com/dialogue-evaluation/factRuEval-2016 and http://bsnlp.cs.helsinki.fi/shared-task.html\n",
        "\n",
        "Final score will be computed by join competition results https://www.kaggle.com/c/mipt-nlp-hw2-2022 and minimal theory. For the five top places you obtain additional points:\n",
        "\n",
        "1. 10\n",
        "2. 8\n",
        "3. 6\n",
        "4. 5\n",
        "5. 4  \n",
        "\n",
        "All submissions to any task should have your team name.\n",
        "\n",
        "### Rules\n",
        "1. Homework is done in a group of up to 3 people. If you are doing a task in a group when sending to anytask, please indicate the logins of the group members so that they can be found in the anytask system.\n",
        "2. Homework is submitted through anytask, invites will be additionally sent.\n",
        "3. Homework is made in the form of a report either in a .pdf file, or in an ipython notebook.\n",
        "4. The report should contain: the numbering of tasks and items that you completed, the solution code, and a clear step-by-step description of what you did. The report should be written in an academic style, without excessive use of slang and in compliance with the norms of the Russian language.\n",
        "5. Do not copy fragments of lectures, articles and Wikipedia into your report.\n",
        "Reports consisting solely of code will not be validated and will automatically be scored at zero.\n",
        "6. Plagiarism and any unfair quotation leads to zeroing of the score."
      ],
      "metadata": {
        "id": "EVf1F0cG6CYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. Analyze and prepare\n",
        "***\n",
        "1.  Analyze distribution of labels and draw a plot.\n",
        "2.  Remove unexcepted labels from data (if it's needed) and describe how (if it's needed)."
      ],
      "metadata": {
        "id": "JDKwo_nVVwb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data from Kaggle and unzip to drive directory. "
      ],
      "metadata": {
        "id": "mJl9L3ZbdxWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/kaggle HW2/mipt-nlp-hw2-2022.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/drive/MyDrive/kaggle HW2\")"
      ],
      "metadata": {
        "id": "-sNlBDVdV-Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read out unziped data."
      ],
      "metadata": {
        "id": "47GrRlSIe-kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = pd.read_csv(\"/content/drive/MyDrive/kaggle HW2/train.csv\", sep=\"\\t\")\n",
        "test_raw = pd.read_csv(\"/content/drive/MyDrive/kaggle HW2/test.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "-_OAi-gnXAgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for NAN values in our datasets."
      ],
      "metadata": {
        "id": "BX6GOxGvfFdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw.isna().values.any(), test_raw.isna().values.any(), train_raw.isnull().values.any(), test_raw.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlAnRQx5XcJv",
        "outputId": "84dae5eb-c8d3-4e01-e727-821d6b2d3cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, False, False, False)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/kaggle HW2/final_data_NER.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "Tsh384h1WhFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess text with Natasha library"
      ],
      "metadata": {
        "id": "3HTtRQRHi768"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing and importing Natasha"
      ],
      "metadata": {
        "id": "zabE4EeBjRAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZaK73HggdFZ",
        "outputId": "a465b49c-09bc-479c-dd42-236c53fa19a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 1.9 MB/s \n",
            "\u001b[?25hCollecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 112 kB/s \n",
            "\u001b[?25hCollecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.5)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 32.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=bdcd836362d683b877679a1503f23a069a4eb7ad57b095363034a7f88e6a4ee2\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "\n",
        "    Doc\n",
        ")\n",
        "\n",
        "\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "\n",
        "names_extractor = NamesExtractor(morph_vocab)"
      ],
      "metadata": {
        "id": "XUjRNVXSgh7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function for get POS-Tags"
      ],
      "metadata": {
        "id": "07Vi51nEjZCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos(sent):\n",
        "    doc = Doc(sent)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    res = [word.pos for word in doc.tokens]\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "O8GGIGuwhlRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define function for get word lemms"
      ],
      "metadata": {
        "id": "eo56LbnMje6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemm(sent):\n",
        "    doc = Doc(sent)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for i in doc.tokens:\n",
        "        i.lemmatize(morph_vocab)\n",
        "    res = [token.lemma for token in doc.tokens]\n",
        "    return res"
      ],
      "metadata": {
        "id": "yO0n5oiOmp3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply our functions to dataset"
      ],
      "metadata": {
        "id": "CjvjAxebkFS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw['pos'] = train_raw['text'].apply(get_pos)"
      ],
      "metadata": {
        "id": "ocLHdyz9ilxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw['sent'] = train_raw['text'].str.split()\n"
      ],
      "metadata": {
        "id": "RgOjnIjs6UwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw['lemm'] = train_raw['text'].apply(get_lemm)\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MQ8lO93Piz1N",
        "outputId": "30e1e4b6-9ef9-47c4-d1e0-0056c6166a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 labels  \\\n",
              "0     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...   \n",
              "1     O O O O O O O O O O O B_LOC B_PER I_PER O O O ...   \n",
              "2     O O O O O O O O O O O O O O O O O O O O B_PER ...   \n",
              "3                     O O O O O O O O O O O O O O O O O   \n",
              "4     O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...   \n",
              "...                                                 ...   \n",
              "1514                                      O O O O O O O   \n",
              "1515  O B_LOC B_PER I_PER O O O B_PER I_PER O O O O ...   \n",
              "1516            O O O O O O O O O O O O O B_LOC O B_LOC   \n",
              "1517            O O O O O O O O O O O B_LOC I_LOC I_LOC   \n",
              "1518  O O O O O O O O O O O B_LOC O O O O O O O O O ...   \n",
              "\n",
              "                                                   text    clf  \\\n",
              "0     В понедельник 28 июня у здания мэрии Москвы на...  False   \n",
              "1     Среди требований , выдвигаемых организаторами ...  False   \n",
              "2     Участникам акции предлагалось принести с собой...  False   \n",
              "3     Начало акции было намечено на 19 часов ; подчё...   True   \n",
              "4     Освещающие акцию блоггеры сообщили , что автоб...  False   \n",
              "...                                                 ...    ...   \n",
              "1514  Сделка способствует укреплений растущих связей...   True   \n",
              "1515  Председатель КНР Ху Цзиньтао и российский през...  False   \n",
              "1516  Новые поставки нефти почти вдвое увеличат объе...  False   \n",
              "1517  До сих пор доставка сырой нефти осуществлялись...  False   \n",
              "1518  По договору между двумя странами о нефтепровод...  False   \n",
              "\n",
              "                                                    pos  \\\n",
              "0     [ADP, NOUN, ADJ, NOUN, ADP, NOUN, NOUN, PROPN,...   \n",
              "1     [ADP, NOUN, PUNCT, VERB, NOUN, NOUN, PUNCT, PU...   \n",
              "2     [NOUN, NOUN, VERB, VERB, ADP, PRON, NOUN, NOUN...   \n",
              "3     [NOUN, NOUN, AUX, VERB, ADP, NUM, NOUN, PUNCT,...   \n",
              "4     [ADJ, NOUN, NOUN, VERB, PUNCT, SCONJ, NOUN, AD...   \n",
              "...                                                 ...   \n",
              "1514          [NOUN, VERB, NOUN, VERB, NOUN, ADP, NOUN]   \n",
              "1515  [NOUN, PROPN, PROPN, PROPN, CCONJ, ADJ, NOUN, ...   \n",
              "1516  [ADJ, NOUN, NOUN, ADV, ADV, VERB, NOUN, PUNCT,...   \n",
              "1517  [ADP, DET, NOUN, NOUN, ADJ, NOUN, VERB, ADP, A...   \n",
              "1518  [ADP, NOUN, ADP, NUM, NOUN, ADP, NOUN, ADP, AD...   \n",
              "\n",
              "                                                   sent  \\\n",
              "0     [В, понедельник, 28, июня, у, здания, мэрии, М...   \n",
              "1     [Среди, требований, ,, выдвигаемых, организато...   \n",
              "2     [Участникам, акции, предлагалось, принести, с,...   \n",
              "3     [Начало, акции, было, намечено, на, 19, часов,...   \n",
              "4     [Освещающие, акцию, блоггеры, сообщили, ,, что...   \n",
              "...                                                 ...   \n",
              "1514  [Сделка, способствует, укреплений, растущих, с...   \n",
              "1515  [Председатель, КНР, Ху, Цзиньтао, и, российски...   \n",
              "1516  [Новые, поставки, нефти, почти, вдвое, увелича...   \n",
              "1517  [До, сих, пор, доставка, сырой, нефти, осущест...   \n",
              "1518  [По, договору, между, двумя, странами, о, нефт...   \n",
              "\n",
              "                                                   lemm  \n",
              "0     [в, понедельник, 28, июнь, у, здание, мэрия, м...  \n",
              "1     [среди, требование, ,, выдвигать, организатор,...  \n",
              "2     [участник, акция, предлагаться, принести, с, с...  \n",
              "3     [начало, акция, быть, наметить, на, 19, час, ;...  \n",
              "4     [освещать, акция, блогер, сообщить, ,, что, ав...  \n",
              "...                                                 ...  \n",
              "1514  [сделка, способствовать, укрепление, расти, св...  \n",
              "1515  [председатель, кнр, ху, цзиньтао, и, российски...  \n",
              "1516  [новый, поставка, нефть, почти, вдвое, увеличи...  \n",
              "1517  [до, сей, пора, доставка, сырой, нефть, осущес...  \n",
              "1518  [по, договор, между, два, страна, о, нефтепров...  \n",
              "\n",
              "[1519 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44e10bba-4d91-46fd-a507-51524e99ee53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>pos</th>\n",
              "      <th>sent</th>\n",
              "      <th>lemm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>False</td>\n",
              "      <td>[ADP, NOUN, ADJ, NOUN, ADP, NOUN, NOUN, PROPN,...</td>\n",
              "      <td>[В, понедельник, 28, июня, у, здания, мэрии, М...</td>\n",
              "      <td>[в, понедельник, 28, июнь, у, здание, мэрия, м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O O O O O O O O O O O B_LOC B_PER I_PER O O O ...</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>False</td>\n",
              "      <td>[ADP, NOUN, PUNCT, VERB, NOUN, NOUN, PUNCT, PU...</td>\n",
              "      <td>[Среди, требований, ,, выдвигаемых, организато...</td>\n",
              "      <td>[среди, требование, ,, выдвигать, организатор,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_PER ...</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>False</td>\n",
              "      <td>[NOUN, NOUN, VERB, VERB, ADP, PRON, NOUN, NOUN...</td>\n",
              "      <td>[Участникам, акции, предлагалось, принести, с,...</td>\n",
              "      <td>[участник, акция, предлагаться, принести, с, с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>True</td>\n",
              "      <td>[NOUN, NOUN, AUX, VERB, ADP, NUM, NOUN, PUNCT,...</td>\n",
              "      <td>[Начало, акции, было, намечено, на, 19, часов,...</td>\n",
              "      <td>[начало, акция, быть, наметить, на, 19, час, ;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>False</td>\n",
              "      <td>[ADJ, NOUN, NOUN, VERB, PUNCT, SCONJ, NOUN, AD...</td>\n",
              "      <td>[Освещающие, акцию, блоггеры, сообщили, ,, что...</td>\n",
              "      <td>[освещать, акция, блогер, сообщить, ,, что, ав...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>O O O O O O O</td>\n",
              "      <td>Сделка способствует укреплений растущих связей...</td>\n",
              "      <td>True</td>\n",
              "      <td>[NOUN, VERB, NOUN, VERB, NOUN, ADP, NOUN]</td>\n",
              "      <td>[Сделка, способствует, укреплений, растущих, с...</td>\n",
              "      <td>[сделка, способствовать, укрепление, расти, св...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>O B_LOC B_PER I_PER O O O B_PER I_PER O O O O ...</td>\n",
              "      <td>Председатель КНР Ху Цзиньтао и российский през...</td>\n",
              "      <td>False</td>\n",
              "      <td>[NOUN, PROPN, PROPN, PROPN, CCONJ, ADJ, NOUN, ...</td>\n",
              "      <td>[Председатель, КНР, Ху, Цзиньтао, и, российски...</td>\n",
              "      <td>[председатель, кнр, ху, цзиньтао, и, российски...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>O O O O O O O O O O O O O B_LOC O B_LOC</td>\n",
              "      <td>Новые поставки нефти почти вдвое увеличат объе...</td>\n",
              "      <td>False</td>\n",
              "      <td>[ADJ, NOUN, NOUN, ADV, ADV, VERB, NOUN, PUNCT,...</td>\n",
              "      <td>[Новые, поставки, нефти, почти, вдвое, увелича...</td>\n",
              "      <td>[новый, поставка, нефть, почти, вдвое, увеличи...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC I_LOC</td>\n",
              "      <td>До сих пор доставка сырой нефти осуществлялись...</td>\n",
              "      <td>False</td>\n",
              "      <td>[ADP, DET, NOUN, NOUN, ADJ, NOUN, VERB, ADP, A...</td>\n",
              "      <td>[До, сих, пор, доставка, сырой, нефти, осущест...</td>\n",
              "      <td>[до, сей, пора, доставка, сырой, нефть, осущес...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>O O O O O O O O O O O B_LOC O O O O O O O O O ...</td>\n",
              "      <td>По договору между двумя странами о нефтепровод...</td>\n",
              "      <td>False</td>\n",
              "      <td>[ADP, NOUN, ADP, NUM, NOUN, ADP, NOUN, ADP, AD...</td>\n",
              "      <td>[По, договору, между, двумя, странами, о, нефт...</td>\n",
              "      <td>[по, договор, между, два, страна, о, нефтепров...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1519 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44e10bba-4d91-46fd-a507-51524e99ee53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44e10bba-4d91-46fd-a507-51524e99ee53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44e10bba-4d91-46fd-a507-51524e99ee53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make shure that all preparations are correct i've decided to check leghts of our features"
      ],
      "metadata": {
        "id": "qiJJRVSKkngm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['text_len'] = train['sent'].str.len()\n",
        "train['lbs'] = train['labels'].str.split()\n",
        "train['lb_len'] = train['lbs'].str.len()\n",
        "train['pos_len'] = train['pos'].str.len()\n",
        "train['lemm_len'] = train['lemm'].str.len()\n"
      ],
      "metadata": {
        "id": "nA34lt_I663A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check = train[['lb_len', 'pos_len', 'lemm_len', 'text_len']]\n",
        "res = check[(check['pos_len'] != check['lemm_len'])]\n"
      ],
      "metadata": {
        "id": "fNY11x9L8dEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On that step there were some mismatches because of domain names in text (.РФ, .ru, lenta.ru, etc.) which were tokenized by Natasha as separate words"
      ],
      "metadata": {
        "id": "uhTtASann0d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SNND8msypqfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After all preparations I wroute all new data to a file"
      ],
      "metadata": {
        "id": "B2vCUcGno5z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw['pos_str'] = train_raw['pos'].apply(lambda x: ' '.join(map(str, x)))\n",
        "train_raw['lemm_srt'] = train_raw['lemm'].apply(lambda x: ' '.join(map(str, x)))\n",
        "train_my = train_raw[[\"labels\", \"text\", \"clf\", \"pos_str\", \"lemm_srt\"]]\n",
        "train_my.to_csv('final_data_NER.csv', sep='\\t')"
      ],
      "metadata": {
        "id": "K2XVQ_dWpQht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze distribution of labels and draw a plot."
      ],
      "metadata": {
        "id": "KiEnoPohqDIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here is our prepared dataset"
      ],
      "metadata": {
        "id": "SXZ0QGDIqVqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/final_data_NER.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "uSVZJPPeqc-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cJI91ZDaXiYZ",
        "outputId": "9ed6392b-da29-4d67-d199-33517f9d51c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  \\\n",
              "0              0             0   \n",
              "1              1             1   \n",
              "2              2             2   \n",
              "3              3             3   \n",
              "4              4             4   \n",
              "...          ...           ...   \n",
              "1514        1514          1514   \n",
              "1515        1515          1515   \n",
              "1516        1516          1516   \n",
              "1517        1517          1517   \n",
              "1518        1518          1518   \n",
              "\n",
              "                                                 labels  \\\n",
              "0     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...   \n",
              "1     O O O O O O O O O O O B_LOC B_PER I_PER O O O ...   \n",
              "2     O O O O O O O O O O O O O O O O O O O O B_PER ...   \n",
              "3                     O O O O O O O O O O O O O O O O O   \n",
              "4     O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...   \n",
              "...                                                 ...   \n",
              "1514                                      O O O O O O O   \n",
              "1515  O B_LOC B_PER I_PER O O O B_PER I_PER O O O O ...   \n",
              "1516            O O O O O O O O O O O O O B_LOC O B_LOC   \n",
              "1517            O O O O O O O O O O O B_LOC I_LOC I_LOC   \n",
              "1518  O O O O O O O O O O O B_LOC O O O O O O O O O ...   \n",
              "\n",
              "                                                   text    clf  \\\n",
              "0     В понедельник 28 июня у здания мэрии Москвы на...  False   \n",
              "1     Среди требований , выдвигаемых организаторами ...  False   \n",
              "2     Участникам акции предлагалось принести с собой...  False   \n",
              "3     Начало акции было намечено на 19 часов ; подчё...   True   \n",
              "4     Освещающие акцию блоггеры сообщили , что автоб...  False   \n",
              "...                                                 ...    ...   \n",
              "1514  Сделка способствует укреплений растущих связей...   True   \n",
              "1515  Председатель КНР Ху Цзиньтао и российский през...  False   \n",
              "1516  Новые поставки нефти почти вдвое увеличат объе...  False   \n",
              "1517  До сих пор доставка сырой нефти осуществлялись...  False   \n",
              "1518  По договору между двумя странами о нефтепровод...  False   \n",
              "\n",
              "                                                pos_str  \\\n",
              "0     ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...   \n",
              "1     ADP NOUN PUNCT VERB NOUN NOUN PUNCT PUNCT ADJ ...   \n",
              "2     NOUN NOUN VERB VERB ADP PRON NOUN NOUN CCONJ N...   \n",
              "3     NOUN NOUN AUX VERB ADP NUM NOUN PUNCT VERB PUN...   \n",
              "4     ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...   \n",
              "...                                                 ...   \n",
              "1514                  NOUN VERB NOUN VERB NOUN ADP NOUN   \n",
              "1515  NOUN PROPN PROPN PROPN CCONJ ADJ NOUN PROPN PR...   \n",
              "1516  ADJ NOUN NOUN ADV ADV VERB NOUN PUNCT ADJ NOUN...   \n",
              "1517  ADP DET NOUN NOUN ADJ NOUN VERB ADP ADJ NOUN A...   \n",
              "1518  ADP NOUN ADP NUM NOUN ADP NOUN ADP ADJ NOUN PU...   \n",
              "\n",
              "                                               lemm_srt  \n",
              "0     в понедельник 28 июнь у здание мэрия москва на...  \n",
              "1     среди требование , выдвигать организатор акция...  \n",
              "2     участник акция предлагаться принести с себя ли...  \n",
              "3     начало акция быть наметить на 19 час ; подчерк...  \n",
              "4     освещать акция блогер сообщить , что автобус с...  \n",
              "...                                                 ...  \n",
              "1514  сделка способствовать укрепление расти связь м...  \n",
              "1515  председатель кнр ху цзиньтао и российский през...  \n",
              "1516  новый поставка нефть почти вдвое увеличить объ...  \n",
              "1517  до сей пора доставка сырой нефть осуществлятьс...  \n",
              "1518  по договор между два страна о нефтепровод от 2...  \n",
              "\n",
              "[1519 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eac3c7bc-4327-43bc-9164-017c351c3e79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>pos_str</th>\n",
              "      <th>lemm_srt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...</td>\n",
              "      <td>в понедельник 28 июнь у здание мэрия москва на...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>O O O O O O O O O O O B_LOC B_PER I_PER O O O ...</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN PUNCT VERB NOUN NOUN PUNCT PUNCT ADJ ...</td>\n",
              "      <td>среди требование , выдвигать организатор акция...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_PER ...</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>False</td>\n",
              "      <td>NOUN NOUN VERB VERB ADP PRON NOUN NOUN CCONJ N...</td>\n",
              "      <td>участник акция предлагаться принести с себя ли...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>True</td>\n",
              "      <td>NOUN NOUN AUX VERB ADP NUM NOUN PUNCT VERB PUN...</td>\n",
              "      <td>начало акция быть наметить на 19 час ; подчерк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...</td>\n",
              "      <td>освещать акция блогер сообщить , что автобус с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>1514</td>\n",
              "      <td>1514</td>\n",
              "      <td>O O O O O O O</td>\n",
              "      <td>Сделка способствует укреплений растущих связей...</td>\n",
              "      <td>True</td>\n",
              "      <td>NOUN VERB NOUN VERB NOUN ADP NOUN</td>\n",
              "      <td>сделка способствовать укрепление расти связь м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>1515</td>\n",
              "      <td>1515</td>\n",
              "      <td>O B_LOC B_PER I_PER O O O B_PER I_PER O O O O ...</td>\n",
              "      <td>Председатель КНР Ху Цзиньтао и российский през...</td>\n",
              "      <td>False</td>\n",
              "      <td>NOUN PROPN PROPN PROPN CCONJ ADJ NOUN PROPN PR...</td>\n",
              "      <td>председатель кнр ху цзиньтао и российский през...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>1516</td>\n",
              "      <td>1516</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC O B_LOC</td>\n",
              "      <td>Новые поставки нефти почти вдвое увеличат объе...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN NOUN ADV ADV VERB NOUN PUNCT ADJ NOUN...</td>\n",
              "      <td>новый поставка нефть почти вдвое увеличить объ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1517</td>\n",
              "      <td>1517</td>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC I_LOC</td>\n",
              "      <td>До сих пор доставка сырой нефти осуществлялись...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP DET NOUN NOUN ADJ NOUN VERB ADP ADJ NOUN A...</td>\n",
              "      <td>до сей пора доставка сырой нефть осуществлятьс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>1518</td>\n",
              "      <td>1518</td>\n",
              "      <td>O O O O O O O O O O O B_LOC O O O O O O O O O ...</td>\n",
              "      <td>По договору между двумя странами о нефтепровод...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADP NUM NOUN ADP NOUN ADP ADJ NOUN PU...</td>\n",
              "      <td>по договор между два страна о нефтепровод от 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1519 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eac3c7bc-4327-43bc-9164-017c351c3e79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eac3c7bc-4327-43bc-9164-017c351c3e79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eac3c7bc-4327-43bc-9164-017c351c3e79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's transform out dataset to word-based approach, and encode our sentences"
      ],
      "metadata": {
        "id": "5ClyhJoQq0hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = train_df.text.str.split(expand=True).stack()\n",
        "labels = train_df.labels.str.split(expand=True).stack()\n",
        "pos = train_df.pos_str.str.split(expand=True).stack()\n",
        "lemm = train_df.lemm_srt.str.split(expand=True).stack()\n",
        "\n",
        "train_words_df = pd.DataFrame({\n",
        "    'Sentence': words.index.get_level_values(0) + 1, \n",
        "    'Word': words.values,\n",
        "    'Label': labels.values,\n",
        "    'POS': pos.values,\n",
        "    'Lemm': lemm.values,\n",
        "})"
      ],
      "metadata": {
        "id": "IbB5qLPLiSgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_words_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YYEgAx89jwFf",
        "outputId": "ccfe1418-2503-4fad-dbfc-5864cdd66fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence         Word Label   POS         Lemm\n",
              "0         1            В     O   ADP            в\n",
              "1         1  понедельник     O  NOUN  понедельник\n",
              "2         1           28     O   ADJ           28\n",
              "3         1         июня     O  NOUN         июнь\n",
              "4         1            у     O   ADP            у"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f3b93d5-aa50-4b3f-8bef-228c09c9c93f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "      <th>POS</th>\n",
              "      <th>Lemm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В</td>\n",
              "      <td>O</td>\n",
              "      <td>ADP</td>\n",
              "      <td>в</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>понедельник</td>\n",
              "      <td>O</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>понедельник</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>O</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>июня</td>\n",
              "      <td>O</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>июнь</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>у</td>\n",
              "      <td>O</td>\n",
              "      <td>ADP</td>\n",
              "      <td>у</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f3b93d5-aa50-4b3f-8bef-228c09c9c93f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f3b93d5-aa50-4b3f-8bef-228c09c9c93f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f3b93d5-aa50-4b3f-8bef-228c09c9c93f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make some preparations to whatch dataset summary later"
      ],
      "metadata": {
        "id": "9Xmiws-zumzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = train_words_df.groupby(\"Sentence\")[\"Word\"].agg([\"count\"])\n",
        "word_counts = word_counts.rename(columns={\"count\": \"Word count\"})\n",
        "MAX_SENTENCE = word_counts.max()[0]\n",
        "longest_sentence_id = word_counts[word_counts[\"Word count\"]==MAX_SENTENCE].index[0]\n",
        "longest_sentence = train_words_df[train_words_df[\"Sentence\"]==longest_sentence_id][\"Word\"].str.cat(sep=' ')\n",
        "all_words = list(set(train_words_df[\"Word\"].values))\n",
        "all_tags = list(set(train_words_df[\"Label\"].values))"
      ],
      "metadata": {
        "id": "SGz59pn9sy7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [label for sentence in list(map(lambda x: x.split(), train_df.labels)) for label in sentence]"
      ],
      "metadata": {
        "id": "iLoxKN_qY3Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JERSC7O5ZK7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_counter = Counter(train_labels)"
      ],
      "metadata": {
        "id": "i_Fu2zdHdEWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_words_df['Sentence'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i0AgtERkQPV",
        "outputId": "6233b51a-7f1f-4b44-9b0b-4c3b529e6196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1339    151\n",
              "1221    133\n",
              "825      95\n",
              "906      95\n",
              "456      86\n",
              "       ... \n",
              "349       1\n",
              "231       1\n",
              "1404      1\n",
              "1406      1\n",
              "1408      1\n",
              "Name: Sentence, Length: 1519, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJxtVdYWcsYI",
        "outputId": "3169a12c-3c42-481c-fccd-ec7dff40a791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'B_LOC': 888,\n",
              "         'B_ORG': 727,\n",
              "         'B_PER': 702,\n",
              "         'I_LOC': 182,\n",
              "         'I_ORG': 854,\n",
              "         'I_PER': 503,\n",
              "         'O': 25158})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = set(list(train_words_df['Word'].values))\n",
        "#words.add('PADword')\n",
        "n_words = len(words)\n",
        "n_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPmgHOwfkqD9",
        "outputId": "9596337d-440e-40d6-9105-e30f07be9b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10183"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Join our features to one sentence"
      ],
      "metadata": {
        "id": "Ub8Ss4Zuu_Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg_func = lambda s: [(w, t, p, l) for w, t, p, l in zip(s[\"Word\"], s[\"Label\"], train_words_df[\"POS\"].values.tolist(), train_words_df[\"Lemm\"].values.tolist())] #, train_words_df[\"POS\"].values.tolist(), train_words_df[\"Lemm\"].values.tolist()"
      ],
      "metadata": {
        "id": "uHNHYD9slYIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_words_df[[\"Sentence\", \"Word\", \"POS\", \"Label\"]]"
      ],
      "metadata": {
        "id": "kJM_U841v6kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = train_words_df.groupby(\"Sentence\").apply(agg_func)\n"
      ],
      "metadata": {
        "id": "w_pC0azov_QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpuUJMLUx9nd",
        "outputId": "9aaa85c6-94f7-42a2-be99-1462af7c0805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence\n",
              "1       [(В, O, ADP, в), (понедельник, O, NOUN, понеде...\n",
              "2       [(Среди, O, ADP, в), (требований, O, NOUN, пон...\n",
              "3       [(Участникам, O, ADP, в), (акции, O, NOUN, пон...\n",
              "4       [(Начало, O, ADP, в), (акции, O, NOUN, понедел...\n",
              "5       [(Освещающие, O, ADP, в), (акцию, O, NOUN, пон...\n",
              "                              ...                        \n",
              "1515    [(Сделка, O, ADP, в), (способствует, O, NOUN, ...\n",
              "1516    [(Председатель, O, ADP, в), (КНР, B_LOC, NOUN,...\n",
              "1517    [(Новые, O, ADP, в), (поставки, O, NOUN, понед...\n",
              "1518    [(До, O, ADP, в), (сих, O, NOUN, понедельник),...\n",
              "1519    [(По, O, ADP, в), (договору, O, NOUN, понедель...\n",
              "Length: 1519, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [s for s in grouped]\n"
      ],
      "metadata": {
        "id": "HPaddlRL9bbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plots and dataset summary"
      ],
      "metadata": {
        "id": "3vXWxyMvvniF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axs = plt.subplots(2,2,figsize=(20,5))\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "train_words_df[\"POS\"].value_counts().sort_values(ascending=False).plot(kind = 'bar', width=1)\n",
        "plt.title(\"POS tags\")\n",
        "plt.ylabel(\"Total Tags\")\n",
        "plt.xlabel(\"POS Tag\")\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.hist([len(sentence) for sentence in sentences], bins= 50)\n",
        "plt.title(\"Sentence len distribution\")\n",
        "plt.ylabel(\"Freq\")\n",
        "plt.xlabel(\"Words count\")\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.hist([key for key, val in train_label_counter.items() for _ in range(val) if key != 'O'], 6)\n",
        "plt.title(\"Labels without 'O'\")\n",
        "plt.ylabel(\"Total labels\")\n",
        "plt.xlabel(\"Labels\")\n",
        "\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.hist([key for key, val in train_label_counter.items() for _ in range(val)], 7)\n",
        "plt.title(\"All labels\")\n",
        "plt.ylabel(\"Total labels\")\n",
        "plt.xlabel(\"Labels\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "print(\"Total number of sentences in the dataset: {:,}\".format(train_df[\"text\"].nunique() + 1))\n",
        "print(\"Total words in the dataset: {:,}\".format(train_words_df.shape[0]))\n",
        "print(\"Number of unique words: {}\".format(train_words_df[\"Word\"].nunique()))\n",
        "print(\"Number of unique tags : {}\".format(train_words_df[\"Label\"].nunique()))\n",
        "print(\"Longest sentence in the corpus contains {} words.\".format(MAX_SENTENCE))\n",
        "print(\"ID of the longest sentence is {}.\".format(longest_sentence_id))\n",
        "print(\"The longest sentence in the corpus is:\\n\")\n",
        "print(longest_sentence)"
      ],
      "metadata": {
        "id": "lhOlk7CTATTW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "700a64f2-aeb4-4284-9118-9d1d756fb148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sentences in the dataset: 1,519\n",
            "Total words in the dataset: 29,014\n",
            "Number of unique words: 10183\n",
            "Number of unique tags : 7\n",
            "Longest sentence in the corpus contains 151 words.\n",
            "ID of the longest sentence is 1339.\n",
            "The longest sentence in the corpus is:\n",
            "\n",
            "Участники турнира • Веселин Топалов ( Болгария , 30 лет , рейтинг — 2801 ) • Вишванатан Ананд ( Индия , 36 , 2792 ) • Левон Аронян ( Армения , 23 , 2752 ) • Петер Леко ( Венгрия , 26 , 2740 ) • Василий Иванчук ( Украина , 36 , 2729 ) • Борис Гельфанд ( Израиль , 37 , 2723 ) • Этьенн Бакро ( Франция , 22 , 2717 ) • Шахрияр Мамедьяров ( Азербайджан , 20 , 2709 ) • Майкл Адамс ( Великобритания , 34 , 2707 ) • Иван Соколов ( Нидеоланды , 37 , 2689 ) • Гата Камский ( США , 31 , 2686 ) • Сергей Тивяков ( Нидерланды , 32 , 2669 ) • Сергей Карякин ( Украина , 15 , 2660 ) • Люк Ван Велли ( Нидерланды , 33 , 2647 ) Средний рейтинг турнира — 2716\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2. Try a baseline\n",
        "***\n",
        "1.  Performe baseline from this tutorial https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html.\n",
        "2.  Make crossvalidation.\n",
        "3.  Describe your features and results."
      ],
      "metadata": {
        "id": "XRQxl71HzPlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features\n",
        "\n",
        "Let's define some features.  \n",
        "For the first try we will use word identity, word suffix, word shape, word POS tag, word lemm and word stemms.  \n",
        "Also, we will use some information from nearby words, and markers for beginning and end of sentence."
      ],
      "metadata": {
        "id": "StpXkWt7z3xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2features(sent, i, use_emd=False):\n",
        "\n",
        "    word = sent[i][0]\n",
        "    label = sent[i][1]\n",
        "    pos = sent[i][2]\n",
        "    lemm = sent[i][3]\n",
        "\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'word[:-1]': word[:-1],\n",
        "        'word[:-2]': word[:-2],\n",
        "        'word.pos': pos,\n",
        "        'word.lemm': lemm\n",
        "    }\n",
        "    if use_emd:\n",
        "      for idx, e in enumerate(model[word]):\n",
        "        features[f\"embedding{idx}\"] = e\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        pos1 = sent[i-1][2]\n",
        "        lemm1 = sent[i-1][3]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:word.pos': pos1,\n",
        "            '-1:word.lemm': lemm1\n",
        "        })\n",
        "        for idx, e in enumerate(model[word1]):\n",
        "            features[f\"-1:embedding{idx}\"] = e\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        pos1 = sent[i+1][2]\n",
        "        lemm1 = sent[i+1][3]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:word.pos': pos1,\n",
        "            '+1:word.lemm': lemm1\n",
        "        })\n",
        "        for idx, e in enumerate(model[word1]):\n",
        "            features[f\"+1:embedding{idx}\"] = e\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "                \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent, use_emd=False):\n",
        "    return [word2features(sent, i, use_emd=use_emd) for i in range(len(sent))]"
      ],
      "metadata": {
        "id": "II1ylpzY3CLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence example"
      ],
      "metadata": {
        "id": "slny1KkQ2ZR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEoU-Mjw3wAd",
        "outputId": "1ccca545-c1fb-4ed5-b2fe-7ab3d4ac4d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('В', 'O', 'ADP', 'в'),\n",
              " ('понедельник', 'O', 'NOUN', 'понедельник'),\n",
              " ('28', 'O', 'ADJ', '28'),\n",
              " ('июня', 'O', 'NOUN', 'июнь'),\n",
              " ('у', 'O', 'ADP', 'у'),\n",
              " ('здания', 'O', 'NOUN', 'здание'),\n",
              " ('мэрии', 'B_ORG', 'NOUN', 'мэрия'),\n",
              " ('Москвы', 'I_ORG', 'PROPN', 'москва'),\n",
              " ('на', 'O', 'ADP', 'на'),\n",
              " ('Тверской', 'B_LOC', 'ADJ', 'тверской'),\n",
              " ('площади', 'I_LOC', 'NOUN', 'площадь'),\n",
              " ('состоялась', 'O', 'VERB', 'состояться'),\n",
              " ('очередная', 'O', 'ADJ', 'очередной'),\n",
              " ('несанкционированная', 'O', 'ADJ', 'несанкционированный'),\n",
              " ('акция', 'O', 'NOUN', 'акция'),\n",
              " ('протеста', 'O', 'NOUN', 'протест'),\n",
              " ('«', 'O', 'PUNCT', '«'),\n",
              " ('День', 'O', 'NOUN', 'день'),\n",
              " ('гнева', 'O', 'NOUN', 'гнев'),\n",
              " ('»', 'O', 'PUNCT', '»'),\n",
              " (',', 'O', 'PUNCT', ','),\n",
              " ('в', 'O', 'ADP', 'в'),\n",
              " ('этот', 'O', 'DET', 'этот'),\n",
              " ('раз', 'O', 'NOUN', 'раз'),\n",
              " ('направленная', 'O', 'VERB', 'направить'),\n",
              " (',', 'O', 'PUNCT', ','),\n",
              " ('главным', 'O', 'ADJ', 'главный'),\n",
              " ('образом', 'O', 'NOUN', 'образ'),\n",
              " (',', 'O', 'PUNCT', ','),\n",
              " ('против', 'O', 'ADP', 'против'),\n",
              " ('политики', 'O', 'NOUN', 'политика'),\n",
              " ('московских', 'O', 'ADJ', 'московский'),\n",
              " ('и', 'O', 'CCONJ', 'и'),\n",
              " ('подмосковных', 'O', 'ADJ', 'подмосковный'),\n",
              " ('властей', 'O', 'NOUN', 'власть')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what word2features extracts:"
      ],
      "metadata": {
        "id": "3uhT_oxy2sFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent2features(grouped.iloc[0], use_emd=False)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX3YsHbk3flr",
        "outputId": "fa420cb2-018d-48b3-da7b-e12e92b2c4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'+1:word.istitle()': False,\n",
              " '+1:word.isupper()': False,\n",
              " '+1:word.lemm': 'понедельник',\n",
              " '+1:word.lower()': 'понедельник',\n",
              " '+1:word.pos': 'NOUN',\n",
              " 'BOS': True,\n",
              " 'bias': 1.0,\n",
              " 'word.isdigit()': False,\n",
              " 'word.istitle()': True,\n",
              " 'word.isupper()': True,\n",
              " 'word.lemm': 'в',\n",
              " 'word.lower()': 'в',\n",
              " 'word.pos': 'ADP',\n",
              " 'word[-2:]': 'В',\n",
              " 'word[-3:]': 'В',\n",
              " 'word[:-1]': '',\n",
              " 'word[:-2]': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get our labels for training part:"
      ],
      "metadata": {
        "id": "Ev2q9KJp2zVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent2labels(sent):\n",
        "    return [label for token, label, postag, lemm in sent]"
      ],
      "metadata": {
        "id": "3Le7SBBTFh_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "EF_h63TNHFlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract features from the data:"
      ],
      "metadata": {
        "id": "oPeTiRmh26EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = [sent2features(s) for s in grouped]\n",
        "Y = [sent2labels(s) for s in grouped]"
      ],
      "metadata": {
        "id": "WfnvJVdi71CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "HgZizFgiG3qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "CakTsV123GrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the first try we will not use word embendings, just pre-install models"
      ],
      "metadata": {
        "id": "1pIN4A0C3jnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igojFK-bsM6o",
        "outputId": "76149571-feea-43e9-fc4d-817eba8e0779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==3.8.0\n",
            "  Downloading gensim-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.21.5)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://rusvectores.org/static/models/rusvectores4/fasttext/araneum_none_fasttextskipgram_300_5_2018.tgz"
      ],
      "metadata": {
        "id": "S_zP0axbsRhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4159c5d6-0329-4fa3-e9e0-96d772a6c41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-21 11:41:02--  https://rusvectores.org/static/models/rusvectores4/fasttext/araneum_none_fasttextskipgram_300_5_2018.tgz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2659449819 (2.5G) [application/x-gzip]\n",
            "Saving to: ‘araneum_none_fasttextskipgram_300_5_2018.tgz’\n",
            "\n",
            "m_none_fasttextskip   2%[                    ]  71.63M  19.8MB/s    eta 2m 44s ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf araneum_none_fasttextskipgram_300_5_2018.tgz"
      ],
      "metadata": {
        "id": "M6vYBvZYsSY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e2d6bc-4d64-467e-eb0b-69b1f1ae829b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "gzip: stdin: unexpected end of file\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-crfsuite==0.3.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMV56K3-sU28",
        "outputId": "24fe976c-fd6b-4f8c-9d09-f34b2b0b9c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite==0.3.6 in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite==0.3.6) (4.63.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite==0.3.6) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite==0.3.6) (0.8.9)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite==0.3.6) (0.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U 'scikit-learn<0.24'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QLFyAIasqfW",
        "outputId": "51d6cf55-d5e8-4455-f212-b8ccb621e380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn<0.24 in /usr/local/lib/python3.7/dist-packages (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "vN8XEBIXszg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKQHPYKvUYvT"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECqq2qmuUYvT"
      },
      "source": [
        "model = gensim.models.KeyedVectors.load('araneum_none_fasttextskipgram_300_5_2018.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ],
      "metadata": {
        "id": "y3hYL_pISLN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
      ],
      "metadata": {
        "id": "_drVwG6j3cem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx_-AJqNOuHX",
        "outputId": "be2d5991-5213-47b5-ee56-825cc4850797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.99 s, sys: 13.8 ms, total: 3 s\n",
            "Wall time: 3.12 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "LL6zy0-bfyEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's look at our classes:"
      ],
      "metadata": {
        "id": "7ENMppoygR71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(crf.classes_)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8frCUIqcP6Dc",
        "outputId": "32d28c8f-80d7-4b21-c425-12c68022f3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B_LOC', 'B_ORG', 'I_LOC', 'I_ORG', 'B_PER', 'I_PER']"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And some model score:"
      ],
      "metadata": {
        "id": "ypGmjG3Ngjx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred,\n",
        "                      average='weighted', labels=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7IzpaQwP_bB",
        "outputId": "aa9431d8-64a4-4e55-a5d6-d0b2f9ffc36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.944003937422749"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect per-class results in more detail:"
      ],
      "metadata": {
        "id": "tyMW3Sdog1dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIMSsWQ1QErJ",
        "outputId": "b518a74b-7eab-4f54-fda1-c950f348ad3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.971     0.989     0.980      8271\n",
            "       B_LOC      0.858     0.821     0.839       301\n",
            "       I_LOC      0.688     0.361     0.473        61\n",
            "       B_ORG      0.764     0.508     0.610       242\n",
            "       I_ORG      0.630     0.456     0.529       250\n",
            "       B_PER      0.784     0.825     0.804       251\n",
            "       I_PER      0.793     0.931     0.856       189\n",
            "\n",
            "    accuracy                          0.948      9565\n",
            "   macro avg      0.784     0.699     0.727      9565\n",
            "weighted avg      0.943     0.948     0.944      9565\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is much more 'O' entities in data set, but we’re more interested in other entities.  \n",
        "To account for this we’ll use averaged F1 score computed for all labels except for 'O'. "
      ],
      "metadata": {
        "id": "SjfuNvyZhssu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(crf.classes_)\n",
        "labels.remove('O')\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8564ef79-599f-4391-a200-3ba74a4e8c25",
        "id": "4owS3ZAiTQIh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B_LOC', 'B_ORG', 'I_LOC', 'I_ORG', 'B_PER', 'I_PER']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "metrics.flat_f1_score(y_test, y_pred,\n",
        "                      average='weighted', labels=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNs7P-ZJTUVN",
        "outputId": "2024615e-2024-4520-e983-f882c4162140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7147819650625025"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3FJOwZXTW4k",
        "outputId": "f2388b79-8757-4530-b950-6ad7523c1c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B_LOC      0.858     0.821     0.839       301\n",
            "       I_LOC      0.688     0.361     0.473        61\n",
            "       B_ORG      0.764     0.508     0.610       242\n",
            "       I_ORG      0.630     0.456     0.529       250\n",
            "       B_PER      0.784     0.825     0.804       251\n",
            "       I_PER      0.793     0.931     0.856       189\n",
            "\n",
            "   micro avg      0.774     0.687     0.728      1294\n",
            "   macro avg      0.753     0.650     0.685      1294\n",
            "weighted avg      0.764     0.687     0.715      1294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Optimization\n",
        "To improve quality try to select regularization parameters using randomized search and 3-fold cross-validation."
      ],
      "metadata": {
        "id": "znaSoIXhiroZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# define fixed parameters and parameters to search\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "params_space = {\n",
        "    'c1': scipy.stats.expon(scale=0.5),\n",
        "    'c2': scipy.stats.expon(scale=0.05),\n",
        "}\n",
        "\n",
        "# use the same metric for evaluation\n",
        "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
        "                        average='weighted', labels=labels)\n",
        "\n",
        "# search\n",
        "rs = RandomizedSearchCV(crf, params_space,\n",
        "                        cv=3,\n",
        "                        verbose=1,\n",
        "                        n_jobs=-1,\n",
        "                        n_iter=50,\n",
        "                        scoring=f1_scorer)\n",
        "rs.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmdgCXRyTp8e",
        "outputId": "a6484d23-1b7b-4692-bca9-ea9b6f97f092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  8.5min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7min 57s, sys: 1.23 s, total: 7min 58s\n",
            "Wall time: 8min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of our best results:"
      ],
      "metadata": {
        "id": "xSm_jNJpi8dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crf = rs.best_estimator_\n",
        "print('best params:', rs.best_params_)\n",
        "print('best CV score:', rs.best_score_)\n",
        "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcuqu5QaUE7L",
        "outputId": "8244d977-530c-4df5-bc5f-e2efe35510ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best params: {'c1': 0.011527652233033548, 'c2': 0.07634581193247741}\n",
            "best CV score: 0.6733123978128884\n",
            "model size: 1.18M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check parameter space"
      ],
      "metadata": {
        "id": "yIzeoTSkmOUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_x = [s for s in rs.cv_results_['param_c1']]\n",
        "_y = [s for s in rs.cv_results_['param_c2']]\n",
        "_c = [s for s in rs.cv_results_['mean_test_score']]\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(12, 12)\n",
        "ax = plt.gca()\n",
        "ax.set_yscale('log')\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('C1')\n",
        "ax.set_ylabel('C2')\n",
        "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
        "    min(_c), max(_c)\n",
        "))\n",
        "\n",
        "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
        "\n",
        "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "UwwEbklgW6yz",
        "outputId": "e21ae8b3-c6a9-4d02-c4d6-0d290b1c95d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dark blue => 0.5201, dark red => 0.6733\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x864 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAALRCAYAAABoN3S3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhMZ/sH8O+ZyTZZZJddEBJbkYh9iSDWqqVKlZa3tFSVtlpepaXVlmotpdXaSlFL1dJWi6J2tQSxRYh9SYgkQmSRZe7fH36Z18hk00wmy/dzXbmuzPOc5T5z5pxzzzPPeY4iIgIiIiIiIjIKlakDICIiIiIqz5hwExEREREZERNuIiIiIiIjYsJNRERERGRETLiJiIiIiIyICTcRERERkREx4SaTunLlChRFwb59+4y+rsmTJ6NGjRpGX0/VqlXx6aefGn09RP9WSR5/ZZkxj+nw8HB4eHggJSXlXy1n6dKlMDMzK6aoiP6nU6dOmDt3rqnDKPOYcFdwgwcPhqIoUBQFarUa3t7eeOWVV3Dz5k1Th1bs3nvvPRw8eNDUYWDXrl1QFAU3btzIVTd48GB06NDBBFFVPPv27YOiKLhy5YrR19OxY0e4urrCysoKvr6+6NOnD65evWrU9ZaEFStWoE2bNrC3t4eNjQ3q1auHsWPH4ubNm9iwYQMURUFkZKTBeUeMGAFfX19otVqD9W3bttWdm8zNzVG1alW89dZbSEpKMuYmFUqNGjUwefLkYlnWO++8g7Fjx8LGxuZfLadfv34lct5OTk7Ga6+9BmdnZ9jY2KBLly64ePFivvPknPOe/Fu0aJFumr179+L555+Ht7c3NBoNatasicmTJ+Phw4fG3iSTmz59Onx9fWFpaYnAwED89ddfhZpv48aNaNq0KTQaDezt7dGmTRs8ePAAQN7vuaIo+PLLL3XLeO+991CrVi3Y2trC3t4eLVq0wB9//KG3nilTpmDy5Mm4f/9+8W10BcSEm9C6dWvExsbi2rVrWLlyJY4fP44XXnjB1GEVO1tbW7i4uJg6jDIjMzOzTC7bFDIyMgyWnz17FmFhYahZsya2b9+Os2fPYunSpahatarRL15arRbZ2dlGW/6QIUMwZMgQtGnTBps3b0ZkZCTmzJmDW7duYcaMGejevTs8PDywcOHCXPOmpqZi5cqVGDJkCFSqvC9DL730EmJjY3H58mV8//33WL9+PUaMGGG0bSppR44cwZEjRzB48OB/vSyNRgM3N7d/H1QBXn75ZezYsQO//PIL9u3bBxFBWFgY0tLSCpz32LFjiI2N1f0NGDBAV7d//374+flh5cqViIyMxBdffIF58+bh7bffNubmmNzs2bMxadIkTJkyBREREQgLC0P37t1x8uTJfOdbvHgxXnnlFQwYMADHjh3D4cOH8dZbb0GtVgMAWrRoofdex8bGYubMmVCpVOjbt69uOXXr1sW3336LEydO4NChQ2jTpg169OiBo0eP6qZp0qQJvLy8sGzZMuO8CRWFUIU2aNAgad++vV7ZnDlzBIDcu3dPRES0Wq0MHTpUqlevLlZWVlKtWjUZP368pKen6+aZNGmS+Pn5ycaNGyUgIECsra0lJCREzp8/r7fsNWvWiJ+fn1haWkrz5s3l119/FQCyd+9e3TT//POPtG7dWqysrMTBwUH69+8vt2/fzrWuNWvWSI0aNUSj0UiPHj3k3r17sm7dOvH39xdbW1t5/vnnJSkpKdd8OQAY/Lt8+bKIiCQnJ8uoUaPE09NTNBqNNGzYUNatW6e3PREREdK8eXOxsLCQGjVqyJo1a8TX11emTJmS53u+c+dOASDXr1/Pd3/s3LlTVCqVXLt2TW+aH3/8USpVqiQPHjyQy5cvCwBZvny5tGvXTrd/Vq1apTfPrVu3ZNCgQeLi4iK2trbSokUL2b17d66YNm3aJC1bthRLS0uZN2+eLFmyRNRqtWzbtk3q1KkjlpaW0qRJEzl+/Lhu3sTERBkwYID4+PiIlZWV+Pv7y1dffSVarTbXds2ZM0d8fX1FURRJTU2Vv/76S0JCQsTR0VEqVaokbdq0kUOHDunFDkDmzJkjffv2FWtra/Hx8ZG1a9dKUlKSvPTSS2JrayvVqlWTX375pdDbnPO+Pf4XEhKim3fVqlXSoEEDsbS0FF9fX3nnnXfkwYMHuvqQkBB59dVXZeLEieLu7i5ubm4G9/WsWbPExcXFYF1R9k9RjsHVq1dLQECAqNVqiYyMlOTkZBk9erR4e3uLhYWF+Pr6ymeffab3PqxZs0a6desmGo1GqlWrJkuWLMk33l9++UUA5Pqc5UhMTBQRkQkTJoizs7NenCKi+1zduHEjz3WEhITIkCFD9MreffddcXJy0israF/t3btXWrRoIba2tmJrayv169eXLVu26G3/4+cfERE/Pz+ZNGmS7vXjx3RISIjBc0ZGRoa888474uXlJRYWFuLu7i79+vXLc/tEREaPHi1hYWEG35u///5b6tWrJ1ZWVhISEiI3b96U3bt3S8OGDcXa2lrat2+v9/7lzPfk63379klgYKBoNBoJCgqSw4cP5xtTfs6dOycAZOvWrbqyxMREsbCwyPczk985Lz8zZszItb8LkrNPf/rpJ+nYsaNoNBoJCAiQXbt2yY0bN6RLly5ibW0ttWvXlj179ujmK+gY02q10rVrVwkODpaMjAwREcnOzpb27dtL69atJSsrq0hx5izT09NTxo8fr1ceHBwsgwYNynO+e/fuiZ2dnXz//fdFWl+LFi2ka9euBU7n4OAgs2fP1iv76KOPpGnTpkVaH+ljwl3BPZlw37x5U9q0aSNqtVp30crOzpYPPvhADh48KJcvX5Zff/1V3N3d5aOPPtLNN2nSJLG2tpZOnTpJeHi4RERESFBQkLRq1Uo3zbFjx0SlUsl///tfiYqKknXr1knVqlX1LnixsbFiZ2cn/fv3l5MnT8revXvlmWeekdatW+daV9euXeXEiROya9cucXFxkbCwMOnSpYtERETI3r17pXLlyjJ27Fi9+R5PuGNjY3V/MTEx0qFDB6ldu7akpqaKVquVtm3bSkhIiOzdu1cuXrwo8+fPF3Nzc9m+fbuIiKSmpoqnp6dunQcOHJDg4GDRaDTFknCLiAQEBMjkyZP1pmnVqpUMHz5cRP53cfHw8JAVK1ZIVFSUTJgwQVQqlRw7dkwXZ+3ataV3795y5MgRiY6Olk8//VQsLCwkMjJSL6aAgAD57bff5NKlS3L9+nVZsmSJKIoigYGBsmvXLjlx4oR069ZNPD09JTU1Vfc+Tp06VY4ePSqXLl2S5cuXi42Njfzwww9622VnZyc9e/aUiIgIOXnypGRlZcn69etlzZo1EhUVJadPn5YhQ4aIo6OjxMfH6+YFIG5ubrJ06VKJjo6WN954Q6ysrKRz586yZMkSiY6OlpEjR4q1tbVuvoK2OSsrS/dl7/DhwxIbGysJCQki8ihRcXBwkGXLlsnFixdl9+7d8swzz8jAgQN1MYWEhIitra0MGzZMzpw5IydPnjS4r1evXi1qtVr+/PPPPD8Phdk/hT0GNRqNtGnTRg4ePCjnzp2T+/fvS0hIiFSrVk02bNig254FCxbofX6qVasma9askejoaBk/fryo1Wo5d+5cnjH36NFDatSokWd9jsuXL4tKpZKVK1fqlbdo0UKee+65fOd9MuGOjo6WWrVqibu7u66soH2VmZkpjo6O8s4778j58+fl/Pnzsn79el2i9TQJd0JCglStWlXGjBmjO39kZWXJjBkzxMvLS3bu3ClXr16Vw4cPy6xZs/LdxoYNG8qECRP0ynKOuZCQEDl48KAcPXpUatSoIa1atZKQkBD5559/5Pjx4xIQECB9+/bVm+/JhFtRFGndurXs2bNHzp49K507d5aqVatKZmambjobG5sC/3L88MMPYm5uniu5bNWqVa4vR4/LOb/4+vqKq6urNG/eXJYuXar3pdyQDz/8UHx8fPKd5kk5+7R69eqyYcMGOXfunPTs2VPc3d2lffv2sn79ejl37pw8//zz4u3trZc8F3SMxcXFiYeHh4wZM0ZERD799FNxcnLSaxTp3Llzge9nzufv0qVLAkDvy7WIyMSJE/WuVU9au3atAJAff/xRGjVqJJUrV5aQkBC9LxBPOnnypACQX3/9Nc9pMjMzZdmyZWJmZiZHjx7Vq/vjjz9ErVbL/fv385yf8seEu4IbNGiQqNVqsbGxEY1Go2uxyTmh5GXmzJl6F9xJkyaJWq2WuLg4Xdnq1atFURRJS0sTEZEBAwZIixYt9JYzd+5cvQvexIkTxcvLSx4+fKibJiIiQu+klLOuO3fu6KYZMWKEqFQqvfWPGjVKGjVqpBdjXiexDz74QCpXriyXLl0SkUcXCEtLS70WchGR//znP9KjRw8REVm4cKHY2NjoWvNERE6dOiUACpVwW1tb5zoRm5mZ6SXcM2bMkCpVqkh2draIiJw9e1YA6JLpnIvLxIkT9dbRvHlzXdKxZMkS8fLy0rvIioiEhobK6NGj9WJatmyZ3jRLliwRALovGSKPWrRsbGxk0aJFeW7jqFGjpEOHDrrXgwYNEnt7e0lOTs5zHpFHFz0HBwdZsWKFrgyALk6RRxc9ADJy5Ei9mADI77//Xuht3rt3r94vGjl8fX3lu+++0yvbvXu3ANDt65CQEKlZs6Zuv+S3PUOGDBFFUcTJyUk6deok06ZN07tAFyZWQwwdg4qiyNWrV3Vl27dvFwBy5MgRg8vI+fzMmDFDV5aVlSW2trb5tp7Vrl1bunfvnveGP6Zz584SGhqqex0ZGan7NSU/ISEhYmZmJjY2NmJpaak7N82ZM0c3TUH7KudzsXPnToPreJqE21C9yKPPfGhoaIFJ5OPs7e1l3rx5emU5x9zjvyJNnz5dAEh4eLiubObMmeLs7Kw335MJNwC9xOngwYMCQKKionRl0dHRBf7l+Oyzz8TDwyPXdvTp0yffltOoqCj59ttv5dChQ3LkyBH55JNPxMLCItd563GRkZFiZ2cnc+fOzXMaQ3L26eNfdg4fPiwA5KuvvtKVHTt2TADIqVOn8lzWk8eYiMjff/8tarVaJk+eLGZmZrJhwwa9+hs3bhT4fuY0Vuzfv18A5Ppy+80334i1tXWecU2bNk0AiJeXl6xatUqOHj0qI0eOFHNzczlz5ozBed58803x8vIy2BL/+++/i42NjahUKnF0dDR4bJ44cUIAyOnTp/OMi/LHW5oJTZs2xY8//oj09HT8/PPP2L59e6478hcuXIhFixbhypUrSElJQVZWVq6bnTw9PeHq6qr3WkQQFxeHKlWqIDIyEu3bt9ebp1WrVnqvz5w5g2bNmsHCwkJX1qBBA9jb2+PMmTNo06YNAMDLy0uvP7a7uzvc3d311u/u7o64uLgCt3/58uWYOXMmdu7ciWrVqgF41LcyIyMDXl5eetNmZGSgZs2aAIDIyEjUrl0bjo6Ouvp69erB3t6+wHUCwNatW+Hu7q5XNm7cONy7d0/3etCgQZgwYQK2bt2KLl26YNGiRWjUqBECAwP15mvevLne65YtW2LHjh26bbl16xYcHBz0pnn48CE0Go1eWZMmTQzG+vjyHR0dUbt2bZw5cwbAo77C06dPx+rVq3Hjxg2kp6cjMzMTvr6+esuoXbs2bG1t9couX76Mjz76CP/88w/i4uKg1WqRmpqa64bCBg0a6P53dXWFWq1G/fr19WKysLDQ7e+ibPPj7ty5g6tXr+Ldd9/Fe++9pysXEQDAhQsX0LhxYwBAo0aN8u1/DAAqlQqLFi3Cp59+ip07d+LIkSOYP38+pkyZgk2bNqFt27aFjrUwx6CbmxuqVKmie3306FE4OjoiODg43zgbNmyo+1+tVqNy5cq4fft2ntPnvB+F8frrr+P555/HhQsXUKNGDSxcuBBVqlRBly5dCpy3V69e+Pzzz5GSkoJvv/0WCQkJePPNNwEUfl8NHToUnTp1Qrt27RASEoJevXohICCg0PEX1n/+8x+EhYWhRo0aCAsL0/XFffxc9qS0tDRYWVnlKlcUBc8884zudc554vHPvLu7OxISEpCdna3rt2toOY8fO56engCA27dv696Dkhi5KSAgQO89Dw4ORlZWFmbMmIGPPvoI5ubmetNHR0ejY8eOePHFFzFy5MinWufj253X+wdA7xpRmGMsNDQUY8aMweTJkzF8+HD07NlTr/7Ja4Yx5MQ0fvx4vPjiiwCAoKAg7Nq1C99//z3mzJmjN31qaipWrFiBt99+2+BnJTQ0FBEREbh79y7Wrl2Ll19+Gdu3b0dQUJBumpzPaWH66pNhTLgJGo1Gd9KtV68eLl68iLfeekt3s9PatWvx5ptvYtq0aQgJCUGlSpWwdu1aTJgwQW85T15YFEUBgDxHIfg3njxB54xk8GRZQevet28fXn/9dfz4449o1qyZrlyr1cLe3h5HjhzJNU9+F9CiqFq1Kry9vfXK7Ozs9BJuZ2dn9OnTBwsXLkT79u2xbNmyIg9PptVqUbt2bWzYsCFXnbW1td7rpxkpYcaMGZg6dSpmzZqFwMBA2NnZYdasWbnudDe07GeffRYuLi749ttv4ePjAwsLC7Rq1SrXTYhP7ltDZY/v76Js8+Ny5v/6668RGhqaq/7x/VWU98rd3R39+/dH//79MW3aNAQGBuLjjz9G27ZtCxVrYY/Bpx3pwtCxm9+xExAQoPvCVZDu3bvD3d0dCxcuxJQpU7Bs2TKMGjWqwC8rAFCpUiXduWnBggVo1aoVpk6digkTJhR6Xy1cuBCjR4/GX3/9hW3btuHDDz/EN998g2HDhuliePILxNPc1NuwYUNcvnwZ27Ztw86dOzF69Gh8+OGHOHjwICpVqmRwHldXVyQmJuYqV6lUeolRzrn08c98Tll+X37yWs7j+/bJL8GG5Ix84eHhgfj4+FxJ/u3bt+Hv71/gch7XokULfPLJJ7hz547uiwAAnD59GmFhYejRowe+++67Ii3zcYbeK0NlOe9FYY+x7Oxs7N+/H2q1GhcvXoSI6JYFAF26dMHevXvzjW3z5s1o3bo1PDw8AAC3bt3Se/9u376tqzMkp65u3bp65XXq1DE4+tGqVavw4MEDDB061ODybGxsdMdZ48aNceLECV0jSo6cz+njjVpUNEy4KZfJkyejdu3aGDZsGIKDg7Fnzx4EBgbi3Xff1U3zNEOp1alTBwcOHNAr279/v97runXrYsmSJcjIyNAlASdOnMC9e/dQr169om9MPi5duoRevXph4sSJendtA49aYJKSkpCenp7neuvUqYMFCxYgKSlJ1zp55swZvYS5OAwbNgyhoaGYP38+0tLS0L9//1zTHDx4EF27dtW9PnDgAOrUqaPblmXLlqFSpUqoXLnyU8Vw8OBBtGvXDgCQlJSEs2fPYtiwYQCAPXv2oHPnznj11Vd100dHRxe4zISEBERGRuLPP/9Ep06dAAA3btwo1K8SBSnMNud8vh4fycPNzQ0+Pj44d+4cXnvttX8dR17rrV69Oi5dulToWJ/2GGzUqBHu3r2L8PDwAlu5i2LgwIF44YUXsHr1al0L2+Pu3r2r++XHzMwMr776KhYuXIhnnnkGSUlJGDJkyFOt9+OPP0b37t0xePBgeHl5FXpf1atXD/Xq1cO7776L4cOHY8GCBRg2bJgueYiJidFNGxcXV+DwehYWFgZHgLG1tUWvXr3Qq1cvfPDBB/Dw8MDu3bvRvXt3g8sJCgoq9BcXY4mIiCj0tC1btkRmZib+/vtvhIWFAXh0Pjh06JDe8V8Yx44dg0aj0ful8siRI+jcuTMGDhyI2bNn6yWyxlbYY2zy5Mm4cOEC9u/fj06dOmH69OkYN26crn7RokUFtgLntIJXrVoVnp6e2Lp1q+7XWwDYsmVLrl9/H9e6dWsAQFRUFNq2basrP3fuHEJCQnJNP3/+fHTr1i1XA09etFot0tPT9cpOnTqFypUr6/2CRkXDhJtyqVmzJrp3767ryhAQEIDFixfj119/Rb169bBp0yasX7++yMt955130LhxY0yYMAGDBg3CmTNnMGPGDL1pRo4cia+//hqDBw/GBx98gKSkJIwYMQKtW7fWnWSKQ1paGp599lk0b94cQ4YMwa1bt3R1rq6uaNeuHTp06IDevXtj+vTpqF+/Pu7evYsDBw7AysoKr732Gl566SV8+OGHGDhwID777DOkpaVh9OjR+XZZeBqtWrVCQEAA3nvvPbzyyiuws7PLNc3ixYtRq1YtBAcHY8WKFfjnn390DyoYMGAAZs2ahW7duuGzzz6Dv78/bt++jb///hu1a9fO9ZPokxRFwdixYzFz5kw4OjpiwoQJsLOzw0svvQTgUWvn8uXLsXPnTt3QUYcOHdLramOIo6MjXF1dsXDhQvj5+SEhIQFjx44tlvevMNvs6+sLlUqFP//8E/369YOlpSXs7e3x2WefYciQIXB0dESPHj1gbm6Os2fPYvPmzZg/f36R4pg/fz6OHTuG3r17w8/PD5mZmfjtt9+wefNm/Pe//y10rE97DLZr1w6tW7dGv379MHPmTNSvXx8xMTE4e/Zsnq1dhdGnTx+88soruuO4a9eu8PLywuXLl7F06VI4Ojpi5syZuumHDh2KqVOnYtSoUejWrdtT/+zevn171KpVC5988gnmz59f4L66cOECFi5ciO7du8PHxwcxMTHYu3ev7qdyjUaDli1bYvr06ahVqxaysrIwYcIEWFpa5htHtWrVsH//fly7dg3W1tZwcnLCjBkz4OnpiYYNG8La2hqrVq2CWq3Ot+W3a9eu+Oqrr57qvSguRelS4u/vjx49euCNN97A4sWLYW9vjw8++ABeXl7o16+fbrpXXnkFAHTDyM2aNQtVqlRB3bp1oSgKtm7diilTpuDNN9/UffHds2cPnn32WfTp0wfjx4/X69L0ZNc7YyjMMbZ7925MmzYNmzZtQtOmTbFgwQIMHDgQoaGhuu54RflsK4qC999/Hx988AFq166N4OBgLF26FCdOnNAbTvObb77BN998g6ioKACAn58f+vbti48//hg+Pj7w9/fHDz/8gKioKL1WaQA4fvw4jhw5kusXR+BRS/q8efPQtWtXuLu7IykpCatWrcKOHTuwbt06vWl37dqFLl26lOiXoHLHhP3HqRQwNCygyP9u5ti5c6dkZGTI66+/Lo6OjroRRHJudsxh6IZEQzelrVq1SqpXry4WFhbSpEkT2bhxY77DAtrb2+c5LODjpkyZIr6+vnplU6dOFS8vL4PzGRoWLucvJ97U1FQZN26cVK1aVczNzcXNzU06deokO3bs0C3z2LFj0qxZM7GwsJDq1avLqlWrim1YwMfNnj1bN6LG43K2Y9myZRISEiKWlpZStWpV+emnn/Smi4+Pl+HDh4unp6eYm5uLp6en9OzZU3fzZV4x5dyItXXrVqlVq5ZYWFhI48aN9W7ESkpKkhdeeEHs7OzEyclJRowYIRMnTtTbH3lt165du6R+/fpiaWkp/v7+8ssvv+S6IQ3/P+zh49Rqda5hyCwtLWXhwoWF3mYRkS+++EI8PT1FpVLpDQu4YcMGadasmWg0GrGzs5MGDRrIxx9/rKs3NGSdIceOHZNBgwaJn5+faDQacXBwkKCgIJk7d67eDZcFxfq0x6CIyP3792XkyJHi7u4u5ubmUrVqVZk6daqIFP6mwbwsXbpUWrVqJXZ2dmJtbS1169aVcePGSUxMTK5pO3fuXKibJXPk9R7/9NNPYmZmpruZL799FRMTI7169dIN1efh4SFDhw7Vuxn63Llz0qZNG7G2tpYaNWrIunXrCrxp8siRIxIYGChWVla6c8b3338vQUFBYmdnJzY2NhIcHCwbN27Mdxvv378vdnZ2sn//fl3Zkzc/iogsX75cnrxcr1q1SgDobrbNa1jAx12/fj3fm0gL4/79+zJ06FBxdHQUjUYjnTp10ruxUuTRvnv8eJo+fbr4+/uLRqORSpUqSVBQkCxYsEDvGBg0aFCe5+TH+fr65jtknqHPtKHtjo2NFQCybds2ESn4GEtISBBvb+9cAwq89tprUr169X81ese0adPEx8dHLCwspEGDBrphK3NMmjQp1/uQkpIib775pri6uoqtra20atVK9u3bl2vZw4YN07vx/nGJiYnSo0cP8fDw0F3jOnToIJs3b9abLjk5WWxsbOTAgQNPvY0koogU4e4XIjKJsWPHYtu2bTh+/Lhe+ZUrV1CtWjXs3bs3358gn9bSpUsxdOhQZGVlFfuyiejRU/yOHj2KjRs3mjqUUi81NRXOzs744YcfDHatI+OYPn06du7cic2bN5s6lDKNT5okKsXu3buHI0eOYMGCBXjnnXdMHQ4RFbP3338fjRo1QkpKiqlDKfW2b9+Opk2bMtkuYRqNRtdFkZ4eW7iJSrG2bdvi0KFDePHFF7F48eJcIzuwhZuIiKj0Y8JNRERERGRE7FJCRERERGRETLiJiIiIiIyICTcRERERkRFViAffPP4UscJycXFBfHy8EaIhorKA5wCiiovHPz0NT0/PPOvYwk1EREREZERMuImIiIiIjIgJNxERERGRETHhJiIiIiIyIibcRERERERGxISbiIiIiMiImHATERERERkRE24iIiIiIiNiwk1EREREZERMuImIiIiIjIgJNxERERGRETHhJiIiIiIyIibcRERERERGxISbiIiIiMiImHATERERERkRE24iIiIiIiNiwk1EREREZERMuImIiIiIjIgJNxERERGRETHhJiIiIiIyIibcRERERERGxISbiIiIiMiIym3CHR4ejvnz55s6DCIiIiKq4MxMHYCxBAcHIzg42NRhlCtarRY7d/6JU2f+gJlZBiBO6Bj2Kvz9a5s6NCIiIqJSq9wm3FS8tFot5nwzDkFNj2HICDMoioKMjOv4fcM7uHL1NXQMe97UIRIRERGVSuW2SwkVr927t6Bh46MICjaHoigAAAsLFZ7vB0Se+xEpKSkmjpCIiIiodGLCTYVy4tQmNGpsbrAurMsDbN+xsYQjIiIiIiobmHBToZiZZehatp/k7KLG3buxJRwRERERUdnAhJsKRVFc8Fi67EIAACAASURBVDBda7Au8rQgwL9xCUdEREREVDYw4aZC6dxxKDasVecqz8wUHNjtiqZNW5sgKiIiIqLSjwk3FYqfXw1U930DC761xMXoDCTfz8bBA5mYN8sZ/xn0FVQqfpSIiIiIDFFEREwdhLHFxMQUeR4XFxfEx8cbIZqyLS0tDX/v/B2JiTHwrxmMJk1a5tm3m6gs4zmAqOLi8U9Pw9PTM886jsNNRaLRaNCta19Th0FERERUZrAfABERERGRETHhJiIiIiIyIibcRERERERGxISbiIiIiMiImHATERERERkRE24iIiIiIiNiwk1EREREZEQch5uITCYjIwM//7IAMXcOw8w8A5npldCiSR+0btXR1KEREREVGybcRGQSmZmZmD5zJDr3vY5QH3MAgEgK/tk5G6vXXsKLLww3cYRERETFg11KiMgktmxdhzbPXoPH/yfbAKAoClq0M8PtpD9x9+5dE0ZHRERUfJhwE5FJRF/aA78AC4N1rcIysP3vDSUcERERkXEw4SYik1CZZeVZZ1tJjZTUpBKMhoiIyHiYcBORSViaeeFBcrbBuhOHtQis37ZkAyIiIjISJtxEZBI9u7+O31eaQUT0yh8kZ+NchCfq1w80UWRERETFi6OUEJFJeHh4oEPriVg6eybqBifCubIW0ZEWiL9RFaPe+ByKopg6RCIiomLBhJuITKZhg8ZoUH8lTpw4joS42whrVhdVqlQxdVhERETFigk3EZmUoiho2DDI1GEQEREZDftwExEREREZERNuIiIiIiIjYsJNRERERGRETLiJiIiIiIyICTcRERERkREx4SYiIiIiMiIm3ERERERERsSEm4iIiIjIiJhwExEREREZERNuIiIiIiIjYsJNRERERGRETLiJiIiIiIyo3Cbc4eHhmD9/vqnDICIiIqIKzszUARhLcHAwgoODTR0GERERlYDU1FQoigKNRmPqUIhyKbcJNxEREZV/O/fvw/K//kS8WgCtwF0xw/BeLyCofgNTh0akw4SbiIiIyqQtO3dg7pG9UIc20pXFimDShlX4GGDSTaVGue3DTUREROWXiGDF339B3eQZvXJFUYA2wZi/Ya2JIiPKjQk3ERERlTk3b95EYiVrg3WKoiBWMpGenl7CUREZxoSbiIiIyhytVgtRKXlPoKggIiUXEFE+mHATERFRmePt7Q2Huyl51rtqVRyxhEoNJtxERERU5qhUKvRq1hLZp87nqss+dBIvd+pqgqiIDOMoJURERFQm9X32OWATsHHHfiQ5WEPRAs7JaRjYvjPatmhp6vCIdJhwExERUZnV99nn0Kfrs7h58yZUKhU8PT0fjVRCVIow4SYiIqIyTaVSwcfHx9RhEOWJfbiJiIiIiIyICTcRERERkREx4SYiIiIiMiL24SYiohKRmJiIH9fMRdLDy1DMtFA9dMCz7QYiKLCJqUMjIjIqJtxERGR0iYmJ+OK7UWg71AzWduYAAK02Fdt/m4mEpJcRFtrNxBESERkPu5QQEZHR/bhmrl6yDQAqlYKmPe2w+9gaZGdnmzA6IiLjYsJNRERGl/Twsl6y/TivBmk4efJECUdERFRymHATEZHRqcy0edZZ2gKpqSklGA0RUcliwk1EREanZDhAqxWDdTdOmKNevfolHBERUclhwk1EREb3bLuBOPxrcq7yuKvpcFDqwt7e3gRRUVkjYvhLG1Fpx1FKiIjI6IIaNsHde4Ox7bvV8KyfAktbBTdPmMNBVRcjXh1n6vCoFEtLS8PspQtx+s41pKu0sNOaoW3tQAzq8yIURTF1eESFokgF+LoYExNT5HlcXFwQHx9vhGiIqCzgOcA4srOzcerUKaSkPkC9us+wZZvylZmZiTc+GY+Edn6wcLTTlT+8FIugmyp89NYYo6yXxz89DU9Pzzzr2MJNREQlRq1Wo2HDhqYOo1TIyMhAbGwsbG1t4ezsbOpwSqWNW/7AnWAPWD2WbAOAZXUPHLt+BteuXUOVKlVMFB1R4THhJiIiKkFarRbfLZ+HyDtnYOapQnZyNjT3bDC8zwj4VfczdXilyt6zEbDqWMNgnbqxH9Zu3YQxr40o4aiIio4JNxERUQn68vvpSA68i2qdfHRl2mwtpi+fio8Hfwp3d3cTRle6SD5dtFUW5kh/mPtGXKLSiKOUEBERlZA7d+7gmnIFDtX0+66r1Cr4vuCNH9cvNU1gpZS/qxcyEu8brMs4eQVdWrUt9LLu3buHAwf/wcmTJ6HV5j0uPJExsIWbiIiohOw5uBuOwZUM1lnYWCAm/VYJR1S6vdKrL/Z8+SG0PRtBZabWlWcmp8LtagoC/1Pw/QCZmZn47Lu5OH7vDpK9nKB+mAmXtcvxnw5d0TEk1JjhE+kw4SYiIioharUZtNl5Dw6mgMPcPc7e3h7TX3sXU3/8DnEOamQ4amB1Kxl+sMOk9z8q1LCAn86bg8M+tjAP9IHt/5el1APm7NsOV0dnBNbnQ5fI+JhwExERlZC2Ldrir+Vb4FTVMVdd+v10eNv5GJirYqvmWxULPvoCN27cQEJCAny6+cDJyalQ8yYmJiIiOR7mrrlHMlFa1Mfi39bhGybcVALYh5uIiKiEODg4oLZtXcSfSdQrz8rIxvU1sRj0/GDTBFYGeHt7o0GDBoVOtgHg2IkTSKlS2WCdolIhXptRXOER5Yst3ERERCVo5OCRWLn+Jxxc+g+09tnQpguctM6YPPSTIiWTVDAbjQbIyMyzXqUt98/+o1KCCTcREVEJUhQFA54fiJdkAB48eABLS0tYWFiYOqxyKbhRIzj9sQ7pAdVy1WWnpiHAyc0EUVFFxC4lREREJqAoCuzs7JhsG5G5uTlebN4W2YdPQ+R/rdnZqemw2Xkcbw0cZMLoqCJhCzcREVVIOQlYYUa6oLKrd9duqOzsjBVb/0C8ZMBMC/g7uuLtsR+yCw+VGCbcRERUoUSdP4uffv8BKaoEQBFYZznihc6voEG9gsd0prKpVdNmaNW0manDoAqMCTcREVUYkVFnsGjrdDQc5AaV+tHoFSKCFT/PRvrDYWjaqLmJIySi8oh9uImIqML4adMiBL7sDpX6f5c/RVFQv68b1u9YYcLIiKg8Yws3ERHpuX//PtZvWolbdy8CWjVCmjyLZk1alvm+zmlpaciwToKi5B6ZQlEUKG6piIuLQ+XKhsdtJiJ6WmzhJiIinfPRUfj0u+GwafoPGg9ORqPBd3Hs/rf4fNZ/kZ2dberw/pWsrCwo+TQzmVkqyMjgg1CIqPgx4SYiIgCP+jIv+WU6wkbYwcldAwBQqRTUamEP79AYrP9tpYkj/HdsbW2Be5o869Ovm8HT07MEIyKiioIJNxERAQBOnT4J9/qpUKlydx3x9rfBmSsHTBBV8VEUBR2Cu+PCroRcdVcPJaJpQChUKl4Wiaj4sQ83EREBAGJv34CjtzrvCcwfllwwRtIxtAvSt6Rhz+ItsKmZBZVawf0oBY392uKFXv1NHR4RlVNMuImICABQ3bcmTp/SwqtGHhM8zLs7RlnyXOfe6BbWA9HR0cjOzoZ/J3+Ym5ubOiwiKseYcBMREQCgZk1/3F1vj8zQbJhb6Ld0XziSjCb1+5oosuKnVqtRq1YtU4dBRBUEO6sREZHOyEGT8fe8TFw5lQwRwcPULBzemISsiw3QpcNzpg6PiKhMYgs3ERHpuLu74/Nxi/D37q048eNhWFna4KWwfvD19TV1aEREZRYTbiIi0mNmZoaO7buhY/tupg6FiKhcYJcSIiIiokISEVy7dg3nzp3Dw4dlf+QeKhls4SYiIiIqhINHw/HdL+sQb2uNLHNz2N29ixbV/PD20KEcw53yxYSbiIiIqABnz0Xh83XrgOZNYKYoMAOQCWB7zC1kzv8e494YYeoQqRTj1zEiIiKiAsz/+WegSTAURf9JrOae7jh4/TqSk5NNFBmVBUy4iYiIiApw62E6FLXhJ7Eme7jjWERECUdEZQkTbiIiIqICqCTvOiU7GxZ8Winlg324iUxARHDmzElcuRKJypV90KhRc6jzaDkhIiLTq+bggBMZGVBbWOSqc7gdh0ZBQSaIisoKtnATlbBbt2Iw/YtBuBXzPgLrL4KinYSZM17EqVPhpg6NiIjy8NbLr8DiwEFos7L0yrOjzuG5Ro1gYSARJ8rBFm6iEpSdnY0lS97FuDF3YWGhBqCGbxWgWdNkfD33Y3h4LIGLi4upwyQioie4u7tj7rtjMGPpEly5fx/ZKhWcVCo8H9IWz3bsaOrwqJRTRCSfXknlQ0xMTJHncXFxQXx8vBGioYpsz56tqGQzHcGNcreEJCRmYcNvYRg8eKwJIqMn8RxAVHEVdPxrtVpotVqYmbHdkv7H09Mzzzp2KSEqQWcj9yMo0PCNNc5OZkhPv1rCERERUVGpVCom21QkTLiJSpDG2gH37mUbrNNqBVlZPIETERGVN7y6E5WgTp0G4Nfft2HwK7nrDvyThUaNepZ8UEREeDR60qqNa7H7bDjS1dmwylajVUAQBvTqy8eWE/1LPIKISpCbmxvMLbvhr23ZePz2iZOnMnE4vCGaNWtruuCIqEKb/PU0/G4WjezeATDvUQfZvQOwWXMZE2d9hgpwuxeRUbGFm6iE9es3EgcP1sWsOT/D0vI+MjI0qFa9PUa+1S/XI4OJiErCqTOnEVXpPuxq1tArt65eGRfuXMLxExEIahhoouiIyr4ylXDfvn0b69evR2pqKsaMGWPqcIieWrNmoWjWLNTUYRARAQDW7dgEm3bVDNbZBvtiw7YtTLiJ/oUS61Iyb948DB06NFeiHBERgdGjR+Ott97Cxo0b812Gm5sb3njjDWOGSUREVOFkarOhMjP8tFuVWo1MMXyzNxEVTom1cLdt2xadO3fGt99+qyvTarVYvHgxJk6cCGdnZ4wfPx7BwcHQarVYuXKl3vxvvPEG7O3tSypcIiKiCqOhXx1suBIF66qVc9WlXI9HqK+/CaIiKj9KLOGuU6cO4uLi9MouXLgAd3d3uLm5AQBatGiBI0eOoFevXvjvf/9bUqERERFVaD06dcOvn+yA1ssJKvP/pQbarGyo9lxH7w9GmTA6orLPpH24ExMT4ezsrHvt7OyM6OjoPKdPTk7GqlWrcOXKFWzYsAG9evUyON327duxfft2AMC0adOe6lHZZmZmfMQ2UQXGcwBVNAsmTMe42Z/ijhsAd1sot1PgfEuL2WOnwsfHx9ThlSge/1TcytRNk3Z2dnj99dcLnK5Dhw7o0KGD7vXTPJ6Zj3Umqth4DqCKxlpjjbnjP8eFCxdw5cY1VGnpDX//R11JKtqxwOOfnkZ+j3Y3acLt5OSEhIQE3euEhAQ4OTmZMCIiIqKKrUaNGqhRo0bBExJRoZn0wTd+fn6IjY1FXFwcsrKycODAAQQHB5syJCIiIiKiYlViLdyzZ89GZGQkkpOTMXz4cPTt2xft2rXDq6++is8++wxarRahoaEVrp8YEREREZVvilSA57XGxMQUeR723yKq2HgOIKq4ePzT08ivD7dJu5QQEREREZV3TLiJiIiIiIyICTcRERERkREx4SYiIiIiMqJym3CHh4dj/vz5pg6DiIiIiCq4MvWkyaIIDg7mmN5EREREZHLltoWbiIiIiKg0KLct3EREROXNzn07sfmfLcgwy4R5ljk6Nu6ADiEdoCiKqUMjonww4SYiIioD5iyZi2iHy6jc3x2KokBEsOn4FpxYcBLvDRtj6vCIKB/sUkJERFTKXbx0EWe0UXBr4qFrzVYUBa5B7rhofQVnIs+YOEIiyg8TbiIiolLul63r4N7Wy2Cde2svbPh7YwlHRERFwYSbiIiolEvPSoe5lbnBOrW5GhnajBKOiIiKggk3ERFRKVfTqybuXU8yWJccex9VnKuUcEREVBRMuImIiEq5Xl164u5fd6DN1uqVi1YQv+U2+j3X10SREVFhMOEmIiIq5TQaDcYNeB83l1xB3NFYPIh7gDsRt3D9h0sY0+dt2NnZmTpEIspHuR0WMDw8HEePHsWwYcNKfN0PHjxAWloanJycoFarS3z9RERU/tT0q4nvPvwWh44cwsVLl1DV0xctPmwBlYptZ0SlnSIiYuogjC0mJqbI87i4uCA+Pr5I81y/fgW/rvsKLvY3YW+XjasxNnD1aIvefV7nQwmIypinOQcQUfnA45+ehqenZ5515baFu6TFxd3Grz+PwcTRWpibq/Cot04Gjp3chBU/3sPLg8eaOkQiIqJSKy0tDVlZWbC1tWUjFZU7TLiLye8bv8eYYVkwN9d/S4PqW2B/+EEkJSXBwcHBRNERERGVTmfPRWHuLz8hVnkIrZkKjumCnk3bomenLqYOjajYMOEuJpJ1GZXsDL+dHVqn4/DhXejYsWcJR0VERFR6Xbh4EeNXL4CqSyOoVCqoACQDWHw8HCkbUzCgZx9Th0hULHinRYkp913liYiIiuSbn5dD1TkIyhM3floE1sDvJw4iMzPTRJERFS8m3MVF7YvkB9kGq7bvtUSTJqElHBAREVHpFpP5AEoeo3kledsjKiqqhCMiMg4m3MXkuV4jMGO+CllZ+i3ZEaczkak0Y/9tIiKiJ+T326+oFGi12nymICo72Ie7mFSu7Ibufb7Cp3NnwNUxBvaVsnH5ug1c3Dtg4KDhpg6PiIio1HE3s8bNbC0Ude72P4drd1F7QG0TREVU/JhwF6MqVarjzbe/RXJyMlJTU9He2RlmZnyLiYiIDHmtZz98uHEp1GGBekMBZkRdRSf/hrCwsDBhdETFh9mgEdjZ2fExu0RERAWoX6cuPkh/EQs2rcUdGwVaS3NUSkjDc3WDMahPP1OHR1RsmHATERGRyTQNaoSmQY1w584dpKenw9PTE+o8bqQkKquYcBMREZHJubq6mjoEIqPhKCVEREREREZUbhPu8PBwzJ8/39RhEBEREVEFV267lAQHByM4ONjUYRARERFRBVduE24iotLk3r17+P3PFUi4ewVmaht07vAy/Pz8TB0WERGVACbcRERGdjziEP78exo6vpABVzcLPEzXYsef4ThwqBNefuktU4dHRERGVm77cBMRlQYZGRn47a8v8dKbAle3Rw/xsLRSoWNvc4jdFhw7ftjEERIRkbEx4SYiMqK/d/2BVp1S9J6il6NlB3Ps2rfaBFEREVFJYsJNRGREN25egFdVc4N1arUCRZ1SwhEREVFJY8JNRGREVXwCcP1ylsG6rCyBaG1LOCIiIippTLiJiIwoNKQL9m+xhojkqtv3Vybat37JBFEREVFJ4iglRERGZG5ujt7dxmPF3M8Q1jsd7t6WSHmQjd1/auFo0Q0NGjQydYhEeg4fO4JV29YhSUmFShR4W7nijX5D4e7uburQiMosRQw1u5QzMTExRZ7HxcUF8fHxRoiGiMqC4j4HJCcnY9PmlbgTfxEWFpXQteMrqFKlSrEtn6g4bNn5F1ae3wznMD/djb5ZDzORtDoK04dPrjBJN3MAehqenp551jHhzgMPNqKKjecAMqWEhASs+HU5Yu/fhCIK6no/g+ef7QONRmO0dWZnZ2PYF++iUn//XHVZDzPhsCUZn7z9odHWX5rw+KenkV/CzT7cREREpciFixfwwfyxeNAyHpX728P1pUqIrn4K708fgwcPHhhtvWfPnkWmn6XBOjNLc9xIv2O0dROVd0y4iYiISpF5P89FzcG+0DhY6crsvSvBo78Tvl3+jdHW+/DhQ4hl3mmBMGMgemo8fIiIiEqJGzduIMszAyp17suzxt4K1x9cMdq6a9WqBVV0qsE6EYF9tvG6sxCVd+U24Q4PD8f8+fNNHQYREVGh3b17F2ZO6jzrtWbZ0Gq1Rlm3jY0N6jvWQMqVhFx1idsvoV/H3kZZL1FFUG6HBQwODkZwcLCpwyAiIiq0KlWqIGN3FtDEcL1FphVUKuO1lb396kjM/uEbnDx6DlLDGsjQwvxCOl5s1g3NGzU12nqJyrtym3ATERGVNfb29nAXT6QkpMLG2VqvLj4yEc1qNjfq+lUqFd4dOgopKSmIjIyElZUV6jxfB2p13q3uRFSwctulhIiIStaDBw8QExODzMxMU4dSpo0Z+j5SN2Xj2o4YPEx+iJSEVFzaeB2uF7zRr2f/EonBxsYGjRs3xjPPPMNkm6gYsIWbiIj+lbi4OCz86QtorW/C2lFwP9YcHpUaYujLb8PMjJeZotJoNJg69gucOx+FHft2wMrSCsN6vY3KlSubOjQieko8ExIR0VNLTk7GjIXvouMIM1hY2ujK465FYMa3H2Lc6KkmjK5sC/CvhQD/WqYOg4iKAbuUEBHRU1v3+3K0eElgYanf7aByFUuo3S/h8uVLJoqMiKj0YMJNRERPLSbhLJzcrAzW1QuxxN/7/ijhiIiISh92KSEiIqMQrUBRFFOHQWXMvXv3sOLXtbhw5ybUAoQ1aokObUJ58yaVaWzhJiKip+blXBfxsWkG607veoj2rbuXcERUlkVfvIDXZ0zA3qopSOxcBXGdfbAg8SDemfohR7+hMo0JNxERPRWtVgtvz+pY8/kNbF91BfcTM3R1t6+kAwn+8PX1NV2AVOZMW/4dLPsEwtK5EgBAURTY1vLC7eauWLh6mdHWe/v2bXy9eCE+nj0TO/ftNdrTPKniYpcSIiIqsri4OHy9aBz8Wybjza98cOd2Erb/dAGp9y3h5uIDH6dgvDtilKnDpDIkOjoad70sYafO3RZo5e6A8IORRlnv3KU/YMu1C9A2qAV1FXscOH0Iy7f+iemjx8DFxcUo66SKhwk3EREV2Tc/TESXEZm6oQC9fV3Qf5QzDm9NRsPKQ9CqRVvTBkhlTsztWxAX6zzrH6qLv9V5y84d+PNBHMxaNdL95G/hXw13qvvgv1/PxKIpnxf7OqliYpcSIiIqkqioSLjXTsw1FCCgIDjMDrsPrjNJXFS2+VWtBvXN5DzrbbKLv41w/Z5dUNeukatcZWGBm/ZWiL5wodjXSRUTE24iIiqS8xdPw7uW4dFHVCoFsHxQwhFReeDt7Q33e2pkpT3MVZcWFYOw+s2KfZ0PoM1zJJ0sdxecOX++2NdJFRMTbiIiKpLKLl5Iisv7533JtCzBaKg8+eSN92D56zmknLkB0WqRlfYQD/4+i8A4G/R5tmexr89S8q5Tku7D282t2NdJFRMTbiIiKpLGwc1w/oAVRHJnK9fPp6JW1ZYmiIrKAycnJyz6eAbe9AyB384ENDiaiVk9RmL8G28bZUz31gF1kRFzO1e5iMDpxh00Cgoq9nVSxaSIoTNmORAeHo6jR49i2LBhiImJKfL8Li4uiI+PN0JkRFQW8ByQv6PHDmLT/q/Qpp8lbOzMICK4cCIFl/f7Yvw7X/IhJVQmZGVl4d3PpyDK3R4WflWgKAqyklOgCT+ND/sOROAz9U0dIpUhnp6eedaV24T7cUy4iaioeA4o2K1bt7Du9x/wICMW2iw1mtTvhLZtOjLZpjIlOzsb23btxJ+HDiBLAXwdnPH+sDegUrETABUNE24m3ERURDwHEFVcPP7paeSXcPPrGxERERGRETHhJiIiIiIyIibcRERERERGxISbiIiIiMiImHATERERERkRE24iIiIiIiNiwk1EREREZERMuImIiIiIjIgJNxERERGRETHhJiIiIiIyIibcRERERERGxISbiIiIiMiImHATERERERkRE24iIiIiIiNiwk1EREREZERmpg6AiIiI6Gldu3YNizasRtzDZKizgbb1GqFXl2dhZsYUh0oPtnATERFRmbTn4AGMXvE1Ipu44G5YAOI7B2B5RjTe/vwjZGZmmjo8Ih0m3ERERFTmZGVlYd4fP8OiSyDUVha6ck11D1wPdMXy9T+bMDoifUy4iYiIqNQSEcTHxyM5OVmv/J/Dh/CgVmWD81h5u+KfC2dKIjyiQim3HZzCw8Nx9OhRDBs2zNShEBGVCUePHcb2vasBsxRIpiVaBPdA65btoCiKqUOjCmrlxnXYcvIgkiuZQcnIhnumOd7q8zJqB9TCrYQ7UDna5DlvhkpKMFKi/JXbhDs4OBjBwcGmDoOIqExY+fN8JFtuQYeh1lCrFYg8wMkD3+L04sMYMXS8qcOjCmjRmhXYlHkVls81QE6HkXitFhNWf48vXx6F+rXqQNl2FPBwzjWvaLWwk3Kb4lAZxC4lREQVXExMDGJSt6JpJxuo1Y9asxVFQYOW1lC5HsbJUxFPtdzU1FSsXrsYX34zGl/OHY2Nv69CRkZGcYZO5VR6ejq2nT8Oy3q+euWKSgV1t0B8/8sKBNT0h8edTGSn5/5MPTwcjf4dupVUuEQFYsJNRFTBbdq6Ei26WRisC26nwfY9Rb/57M6dO/h89mtwafg7urx2G11evw2Lamsw5athufriEj3p5KlTeODnaLBOZabGjYz7AIDP3xqLSn9GIu34RWSlpiP9ViKyNh9H78p10bJJs5IMmShf/L2FiKiCS0lLgrWd4cuBmbkKojws8jIXr/gUvd7MgKWVla6sSk0rOA69j8XLv8DbIz596nip/NOKFsivC/b/31bg5OSExZ98iaMRx7H/+BE42buhx8jBqFSpUonESVRYTLiJiCq4aj71cO3CWVSpoclVdzc+Aw623kVa3r1792BufwOWVua56uzszfEg6zyysrL4YBLKU8P6DWD711qgbu46bVY2vM3/l1ArioLgwCAEBwaVYITll4jg2LHjiDp3Ab5VvNG8eVOo1WpTh1XmsUsJEVEF16VjLxz63RxarX6Toohg91otej07qEjLS0xMhL1rdp711pUykZaW9lSxUsVgZWWF0OrPIOPsdb1y0WqRvTkCw58fYKLIyrerV69i6GvvYebXW7B9VxK+X7gfrw55DxERJ00dWpnHhJuIqIKztLTE4Bc+xrrZQGR4Ku7fzcSFUylYP0eL50LHwsnJqUjLc3NzQ/yN3K3bOVLuamBjk/dwiQRQbwAAIABJREFUbkQAMPylQehl6QfzXyOQsfcsMrafhNOfZ/Hx80NR08/P1OGVO5mZmfho0mxYWDeBg5M/rK2dYO9YDTb2LfDlV0tx9+5dU4dYpvH3PCIiQs0aAfhk3DL8c3APLu+Kgqd7NXz0bnuYm+edOOfF2toaGtRB0p3TcHDVnz/2agY8nVpDpWJ7DxXsld59MbBnH8TFxcHKygoODg6mDqnc+uOPrYC6OlQq/e4jiqLAyrYeVvy0Fm+NfN1E0ZV9TLiJiAgAoFar0aplKFq1DP3Xyxr2n/H4cs578Kp3A0FtLKDVAke2Z+DeNX+8O/KtYoiWKgqVSgV3d3dTh1HuHY+IhK1ddYN1VlaVcP36uRKOqHxhwk1ERMXOysoKE9+fi1OnIrB7xSao1Wp0COkN/961TB0aVXBarRYA+CvLE+zsbBB7Jx3m5la56kS0MDPjE2f/DSbcRERkFIqioH79QNSvH2jqUIhwJuos5q1dhZuZaRAocFdbYMhzvdGEo5sAAPq/2BPvj5sHR5fcx+u9uxcw6KUwE0RVfjDhJiIionLtxJkzmLhmKRDaGMr/t2zHiOCTzevwfno6Qpq3MG2ApYCXlxdaNKuKg0fOo5JDTSjKoxbt+0lXUbO6Gk2aBJs4wrKNv6cQERFRuTbvl1VAuya6ZBt49AuMqmUgftjyuwkjK11GjnwNQwa3gqX6NLIeRkAl/9fenQdGVR56H/+dWbKRjSSsAYTgglAWYWQTkSWyKluVlupre3nrAuprudYKLfd6u3ilWqq3FXpjpVQRXIuiohaptS4IJCyKsm+yJyZhScg6M+f9wzYtJgGCeebM8v38N+eZc+YHZA4/Hp5zzse6YXI3PfDAj+oKOC4MM9wAACBqVVZW6qhqGy2MxUleHTt2jAsz/2748KEaPnyo0zGiDjPcAAAgagUCAdnuxuuO7XGrtrY2hIkQiyjcAAAgaiUnJyvzLH067USFsrOzQxcIMYnCDQAAotq3rsmVf9O2ettrt+7R9f0GcItAGMcabgAAENXGjhipqupqvbj6byrJSpbtstSy6JRu7HOlvjNpitPxEAMo3AAAIOpNHjtOE0eP0d69exUMBpWTkyOPhxqE0OAnDQAAxASXy6WLL77Y6RiIQSxaAgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMChqC3dBQYHy8vKcjgEAQEzYv3+/1q1bp8LCQqejAGEnah984/P55PP5nI4BAEBU2/f5fj301AIdb+OWPyNB3nWnlV2RoAfuuFfp6elOxwtLtm1rx44dOlpYqEu6dlWHDh2cjgTDorZwAwAQi3bv2a3FK55RSfCUZEsXtWin2741XZmZmc3+WWVlZZrz5COKn9pHyW73lxt7SMWnq/TDR3+m3//XfFmW1eyfG8m279yp/160SF+kp6k2OVnxf/2rLgoG9eCsWWrZsqXT8WBI1C4pAQAg1hRs3qCfvfyoqiekK/WGLkq9sYuKrrF0729/oqKiomb/vKUrXpSVe7Fc/yjbf+dpkaBTl6fpg7Vrmv0zI9nx48c1Jy9PJwYOUFz37mrRqZM8V/TRgR7dNeuhh2TbttMRYQiFGwCAKGDbthatfEZtvnmZXJ5/FmBvi3hlTLtUv136v83+mTsKDyihVVqDY0nfyNY7+R82+2dGssUvvqjqPr1luc6sX+6EBBW2baP3P/rIoWQwjcINAEAUOHDggKraWw0u4fDEe3WoqrDZZ1DdttXoMQPVfiXExTfr50W6vUVF8qamNjjm7dJF71C4oxZruAEAiALl5eWyUhr/az3o+XIW/HzXVNu2rbX567Rq7d9kWZYmDh+j3t/odcZ7RvQZqD/uzFeLy9rX279q3T59a9yMpv0iopzLthv9MwhUVys5KcmBVAgFZrgBAIgCOTk50v6qRseTaxPkcp3fX/sVFRW682f36fH9K3V0VJoO56bolxuf1X2//E/V1tbWvW/08Fy1+uSUqotOnrn/7kL1CmSpc+fOF/RriVajBgxQzcGDDY5Z27Zp2oQJIU6EUKFwAwAQBRITE/WN9ItVfuB4vbHj6w5pXP/c8z7WvCceU9W4Dkq9oqMst0suj1tpg7roi0HJevzpfz7jwu1269E5v9CAvYnSy1tVveJTuV/epuv9OZp71w+b5dcVTcaOHKmcwiLVFpecsd2/f7+GtG6j7Oxsh5LBNJaUAAAQJe75tzv1yBOPasemXfL2TFewOqDgllMa3nWgxueOPa9jlJeXa29tkVLSu9cbS2yXrs0fbFUwGKybLY+Li9M90+9o1l9HtHK73fqfBx5Q3pIlWrduvaolpbhcGjdwoKaMH+90PBhE4QYAIEq43W7NnvFDlZaWav2mfMUlxWnQ3QOVmJh43scoLCxUoHVCo+O1SS5VVFQoOTm5OSLHHK/Xq7umT9ddTgdBSFG4AQCIMhkZGRozcvQF7ZuVlSVXaU2j4+6KQJMKPADWcAMAgH+RlpamtjVJ8lfWL93VJyp0aWq23F950A2As6NwAwCAM/zk1n9X7Us7VP55saQvbxFYtqtQ3tc/173TWQwBNBVLSgAAwBkyMjKU95Nfafmbr2rja5/JJUvje1ypMXOvldfrdToeEHEo3ACAmGXbtoqLi+V2u5WRkeF0nLASHx+vaZNu1DTd6HQUIOJRuAEAMWnVX9/QOwWvKq51pYJBW8HiFF0/bJoGXTnE6WgAogyFGwAQc976y2sqOLFcV97WUtI/H6e9cvkTcrncGtBvkHPhAEQdLpoEAMQU27b17qbXdHluy3pjfSZn6rV3n3UgFYBoRuEGAMSUQ4cOKbFjdYNjlmUpkHRClZWVIU4FIJpRuAEAMci6wDEAaDoKNwAgpnTo0EGVB+MbHLNtW+7Taed8kuLJkye1f/9+ZsIBnBcumgQAxBTLsjS87wStX/WSuo86cx33pj+VaNKImY3uW1xcrN889bCqk4uVkCmdPmKrjaer7p7+QyUkJJiODiBCUbgBADFn9Ijxcr/r1uonVsjbqkLBgC0dT9WEYXfoyr4DG9ynsrJSv/jf+9VnerriElvVbS8rLtLPH/uxfnH/fFkWy1EA1EfhBgDEpNxhYzTymtE6fvy4XC6X0tPTz/r+l1e+qJzrExSXeOZfnSlZiYq7vFhbPv1EvXr2NhkZQIRiDTcAIGZZlqWMjIxzlm1J2nXkU2V1Sm5wLGdQht7+YGVzxwMQJSjcAACcD/ssQ7Ytl8sduiwAIgqFGwCA8/CNHJ8K95xqcGz330o1bvikECcCECko3AAAnIfrRk3UwbdsVZw886E5pYdOy3OorS679DKHkgEId1w0CQDAeYiPj9dP73lEC59+VNuq98ubaqv2hFsXZ/XSj/9f47cSBAAKNwA0QU1Njd56+xXt/vwTJcSn6Lprp6lTp05Ox0KIpKSk6P47/1O1tbWqqqpSUlKS3G7WbgM4Owo3AJyn/fv3Km/ZXPUbX6MhI1qostyvF95aryz3MH3vO3c7HQ8h5PV65fV6nY4BIEJQuAHgPNi2rSeW/VQT7nbL7WkhSUpM9mjoDcna/O67+vCjnrpq0DBnQyKslJaW6pW3XlLx8SJd3rWnxowcR0kHYhQXTQLAediwYb269i+X21P/tNn7mhZ6d+1yB1IhXC1f+aJ+/sy/q8K3Ta2/fVpb0/6sWfNu0649u5yOBsABFG4AOA97D2xXu5yG/1PQsiy54ipCnAjhatuObVpb9Ib63NxeKVmJsixLbS9LV78ZbfXbZ+fJ7/c7HRFAiFG4AeA8ZLftrJIjDRcl27Zl1yaEOBHC1fI/P6vLxrWut93lstT2aq/e/eCvDqQC4CQKNwCch4EDhmjb+wmy7fqPG9y5sUK+nmMdSIVwVGWVy+Nt+M4lrS5O1Y69n4Y4EQCnUbgB4Dy43W5Nm3CfXv9dlUqLvnzwScAf1Ma/lKt0S09dO2KcwwkRLtz+OAWDDT8H/uSx02rXumOIEwFwGncpAYDz1LNHH3XMfkKvrHxGn578XJbt1cghN6j3+CtkWZbT8RAmrh00Xqs+eko5V9VfVnLgL6d1593jHUgFwEkUbgBogvT0dH3vprucjoEwNnjAEOX//iPteneHcoa0ktvjUlV5jXa8WqLJg29WYmKi0xEBhFjUFu6CggJt2LBBt99+u9NRAAAxxLIs/eC2H2nDxny98dwKBawapca10r2TZyk7O9vpeAAcYNkNXQEUZY4cOdLkfbKyslRcXGwgDYBIwDkAiF18/3Eh2rdv3+gYF00CAAAABlG4AQAAAIMo3AAAAIBBUXvRJAAAABq3fccOfbgmX+lpKRo9aqSSk5OdjhS1KNwAAONqamq0fft2ud1udevWTW53w09iBGBeeXm5fvzAL1VYFqf41E7y1x7Tn974hcYM76tbbprqdLyoROEGABhj27aWvvQHbTn0oTIur1UwYOnpt7wa8o3rdP3oyU7HA2LSA7+Yr5Oebkpt20KSFK80Ka2N3nh/qzpftEZDhwx2OGH0oXADAC5YbW2t8gvWqrKyXL16+tSqVaszxp97+WkVt/pQA0en/XPj1dInq1co6W9JGnnN6BAnBmLb4cOHdag4oNT2LeqNJbe6XC++/BaF2wAKNwDggrz19nKt//QFdetfrsRMS0tWxslV0U0zv/+A4uLi5Pf7tWnf3zQoN63evt1zW+oveSso3ECIbfl0q6yEtg2OWZalsspAiBPFBu5SAgBosvyCNdp7YommzJS6+5LVpVsLjZrmVe8x2/S7RT+XJB04cEBpOf5GjxFMLlNVVVWoIgOQlJmZoaD/dKPjXpqhEfy2AgCabPX7S3X19XH1trfKjpM/fqtKS0u/nOWubvwYdq3FxZNAiPXre4USgkVq6EHjlaePq9flnUMfKgZQuAEATWbFHZdlWQ2O5fSq0mdbP1F2drYqDyY1+J5gIKiE2lbyer0mYwL4CpfLpdu++02VHV6ngL+mbntF2RdqUb1N359+s4PpoheFGwDQZMFA4zPTp0+5lNwiVZZlaeI1N6vgheIzZtMC/qDWLC7W/5l0eyiiAviKIVcN1Lz/uEMdEvbLc2qT4so2KbdPkn4z/+dKTEx0Ol5U4qJJqLq6WqdOnVJ6ejqzTQDOS3riZSo7uUkpafXPGXs3p2raPb0lSYP6D1FiYpKWP7lE1Z5S2UEp2WqjmZN+qq45F4c6NoC/69Kls372nz9yOkbMoHDHsLKyMi1d8qDiXDuVlVGjwuJEeRL66Kab71NcXP21mQDwDzdNvVuPLJipcdOrlNryy9IdCNj660s1GnrlHWesze7Ts6/69OzrVFQAcByFO0bV1tbqd4/fqR/dWaK0VLe+XF1UrcNHPtSC3x7VD/79t42uzwSAtLQ0/eiu3+m5l36n4vJtcrkDUm2mrr/239SjR2+n4wFAWKFwx6i//OUVTZtUpLTUM2eys9t7NKD3Hn366Wb17HmFQ+kARILU1FTdNv1+p2MAQNjjoskYtW/PB/rG5Q0vG8m9xqOPPnwlxIkAAACiE4U7RrnOslzEsiRL9e/PCQAAgKajcMeojhcN1NYdNQ2OvfN+rfoPmhDiRAAAANGJwh2jcq+doqXLs3SqLHDG9sIivz4oyFGvXv0cSgYAABBduGgyRsXFxen2mQu08KmfKyl+j9q2rtGhowmyXX11592zuUMJAABAM6Fwx7C0tDTNuOtXqqio0IkTJ3RNRoYSEhKcjgUAABBVKNxQUlKSkpKSnI4BAAAQlVjDDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYNA5C3cwGNSKFSv08MMPa9myZSovLz9j/KGHHjIWDgAAAIh05yzcy5Yt00cffaTu3bvr8OHDuu+++3To0KG68e3btxsNCAAAAESycxbuDz/8UPfff7+uu+463Xfffbrxxhv1s5/9THv37pUk2bZtPCQAAAAQqc75aPeKigqlpqbWvR4xYoSSk5P10EMP6d5775VlWUYDAgCA8BMIBPT8q8v1/vZNqnUHlRz06tvXXq+B/fo7HQ0IO+cs3O3atdOuXbvUrVu3um39+/dXXFycHnnkEdXU1BgNCAAAwksgENCPHv6pDvRMUtKESyRJpcGgfrX2FV2/b4++e8M0hxMC4eWcS0rGjh2rgwcP1tvep08fzZo164wiDgAAot9b77yt/ZfGKalLm7ptlsulFoMv0et78nXixAkH0wHh55yFu02bNiosLGxw7OOPP9a0afwrFgCAWLJq04dqcVn7Bsdc/TvqT2+9FuJEQHg7Z+F++eWX1b179wbHevTooeXLlzd7KAAAEL4CLjV6DZc3rYVKTzHDDfyrcxbu/fv3q0+fPg2O9ezZU/v27Wv2UAAAIHy1TkiTv6K6wbGqHUc1qFe/ECcCwts5C3dlZaX8fn+DY4FAQJWVlc0eCgAAhK/pk76t6tX1n8MRqKlVyrYTumrAIAdSAeHrnIU7OztbH3/8cYNjH3/8sbKzs5s9FAAACF8dOnTQPcOnqvaFzSrbdkhVRSdUvm6Pklbs1C/vmsMtg4GvOOdtAcePH68nnnhCwWBQV155pVwul4LBoPLz87Vo0SLdcsstocgJAADCyNUDB2uQr7/eW/OhjhQXqteAXPWa3tPpWEBYOmfhHjJkiE6cOKEFCxaotrZWqampOnXqlLxer6ZOnaohQ4aEIiciXCAQ0L59++RyudS5c2e5XOf8zxUAQJjzeDwaMfQap2MAYe+chVuSrrvuOo0YMUI7d+5UeXm5kpOTdemllyopKcl0PkSBla8/o127X9Xl3Url91tasSJLV/SZpmHDJzgdDQAAwLjzKtySlJSU1OjdSoDGvPnGMqWkPK0f3OPSP37cxuu4Vry6UB9+EK+rhox2NiAAAIBh/L8+jAkGg9qxc4WGDq3/YzZxgrQ+/1kHUgEAAIQWhRvGHD58WDk5xxsdb5n+hSoqKkKYCAAAIPQo3DDG7XbLX9v4j1itX1w8CQAAoh5tB8a0a9dOnx9o1eCYbdsqL89WQkJCiFMBAACEFoUbxliWpcGDpuv55y3Ztl23PRi09fsn3Ro9aqaD6QAAAELjvO9SAlyIAQOHy+uN12P/s1iJiUcl21JlVbbGjpmpbpf3cjoeAACAcRRuGNe332D17TdYtbW1sixLHg8/dgAAIHbQfBAyXq/X6QgAAAAhxxpuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMCgiHrS5Pr167Vx40ZVVlZqxIgR6t27t9ORAAAAgLMKWeFeuHChNm7cqLS0NM2fP79u++bNm7V48WIFg0GNHDlSkyZNavQY/fv3V//+/VVeXq4lS5ZQuAEAQEgFAgHt2rVLwWBQl1xyibxer9OREAFCVriHDRumMWPGaMGCBXXbgsGgFi1apLlz5yozM1Nz5syRz+dTMBjUsmXLzth/xowZSktLkyQtX75co0ePDlV0AAAAvfD6a/rTR++rtHWaLMtS+rMnNa5XP33vxqlOR0OYC1nh7t69u4qKis7Ytnv3brVt21Zt2rSRJA0ePFj5+fmaPHmyZs+eXe8Ytm1r6dKl6tOnj3JyckKSGwAA4LW3/6w/7vlE7twBSvj7tkpJz2/bo7hXlus7k6Y4GQ9hztE13KWlpcrMzKx7nZmZqV27djX6/jfffFNbtmxRRUWFjh07plGjRjX4vtWrV2v16tWSpHnz5ikrK6vJ2TwezwXtByA6cA4AYtdXv/+2bWvF2g/lHXpFvffG9bhEb727QXdN/75cLu5FgYZF1EWT48aN07hx4875vtzcXOXm5ta9Li4ubvJnZWVlXdB+AKKDk+eAPXt267W3n5E/UKbEuExNGvddZWdnO5IFiEVf/f6fOnVKx6yArGCwwfcXJ3m1ZcsWvqcxrn379o2OOVq4MzIyVFJSUve6pKREGRkZDiYCAGc9/6c/6GDl6xrwrSTFJ7hVUXZMT624R76cWzRq5ASn4wExyePxyBUIym5k3Kr1Ky4uLqSZEFkc/b+Prl276ujRoyoqKpLf79eaNWvk8/mcjAQAjtmzZ7cOVr6uod9MUXyCW5KUlOJR7s0ttHb7Eh0/ftzhhEBsSkpKUjt5ZNv1K7dt22pdHVCrVq0cSIZIEbLC/dhjj2nu3Lk6cuSI7rjjDr3zzjtyu92aPn26HnzwQc2aNUuDBg1Sx44dQxUJAMLKa6uWaMD4pAbHBk5w69U3lzU4BsC8mTd8W9Zf18n+l2Ultm1L72/Qrdc1fktjQArhkpIf/OAHDW7v27ev+vbtG6oYABC2/MHyupntr0rPitdnJ46FOBGAf+jdo4d+efP/1cIXn9OhqtOSZamdN0G3Tv62+vbiuSA4u4i6aBIAolliXKYqyo4pKaX+qfmLw5Vq26pz6EMBqNP9sm56fO5/1S0tsSzL4USIFNy/BgDCxKRx39WaFVUNjq1dIV0/9lshTgSgIZZlUbbRJBRuAAgT2dnZ6tflFr31h9M6UVwt6cuZ7dcWVuq6a+5RcnKywwkBABeCJSUAEEZG507UlX2v1qtvLtNnJwvVtlVn3X/7tyjbABDBorZwFxQUaMOGDbr99tudjgIATZKRkaHv3XSX0zEAAM0kagu3z+fjnt4AAABwHGu4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADCIwg0AAAAYROEGAAAADKJwAwAAAAZRuAEAAACDKNwAAACAQVFbuAsKCpSXl+d0DAAAAMQ4j9MBTPH5fPL5fE7HAAAAQIyL2hluAAAAIBxQuAEAAACDKNwAAACAQRRuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEFRW7gLCgqUl5fndAwAAADEOI/TAUzx+Xzy+XxOxwAAAECMi9oZbgAAACAcULgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAgKhQXV2t6upqp2PUE7X34QYAAEBs+OiDtVr6xHM6cahMkq2MTmm6ZeZN8vUPj2eyMMMNAACAiPXeX9/Xwh8/Kdenyco82V6ZJ7OlT1ro0fsWav3afKfjSaJwAwAAIII9+8QLyjjdTpZl1W2zLEuZZe319MKlDib7Jwo3AAAAItIXX3yhskOVDY5ZlqWTB8pUVlYW4lT1UbgBAAAQkQKBgCzbavwN9pfvcRoXTQIAEKOOHDmiNRvWKikhScOuGqqkpCSnIwFN0qZNGyW29Ur7Gh5Pbpeo9PT00IZqQNTOcBcUFCgvL8/pGAAAhJ2amhrN/fVPNWfFI1rVcqv+pI80c8FsLfnTMqejAU1iWZbGTxujE/Ff1Bs7kVCkybdMdCBVfVE7w+3z+eTzhcetYAAACCfz8uareHCcMttc/M+NF7fWOx99rDbvttaoYbnOhQOaaOI3JygYCGrlc2+p+mhAtqTE9h5NvWWiRo271ul4kqK4cAMAgPpOnDihvYFjymhzab2xloM66bXnV1G4EXEmT52kiTdM0MGDB+VyudShQ4cz7lriNAo3AAAxZOfOnQp2SWx0vNxdFcI0QPNxuVy66KKLnI7RoKhdww0AAOpLTU2VyvyNjrsD4TMrCEQLCjcAADHksssuU/y+Wtm2XW+spqxKOSkdHEgFRDcKNwAAMcSyLH1/3E0qXr5dgZp/znRXlZar4qW9uvPm2xxMB0Qn1nADABBjBvTrr6yWmfrjq8tU7D8pl23psszOmn7fPKWkpDgdD4g6FG4AAGJQ15yu+vkP/sPpGEBMYEkJAAAAYBCFGwAAADCIwg0AAAAYROEGAAAADKJwAwAAAAZRuAEAAACDKNwAAACAQRRuAAAAwCAKNwAAAGBQ1BbugoIC5eXlOR0DAAAAMS5qH+3u8/nk8/mcjgEAAIAYF7Uz3AAAAEA4iNoZbgAAYoFt29qwaYP2H96vrp26qk+vPrIsy+lYAP4FhRsAgAi1fdd2/c+zv5G3V7ySspP03p4P5F/xpH54y73K6ZzjdDwAf8eSEgAAIlB5ebl+9dx8dZh+kdr2b6fU7DS1Hdhe7b/XUQ89NU9VVVVORwTwdxRuAAAi0EsrX1KrsW1kuc5cPuLyuNTy2ky9+udXHUoG4Kso3AAARKC9hfuU0j61wbH0zi217cD2ECcC0BgKNwAAEchreRXwBxoc81f5Fe+OD3EiAI2hcAMAEIEmDp+gwjVHGxw79t5h3TD6myFOBKAxFG4AACJQr2/0UnZJO32x5Yu6bbZtq2jjMXWt6aqLu17sYDoA/4rbAgIAEKFmz5ytV996Te8tfU9+j19ev1dj+o7S6FtHOx0NwL+gcAMAEKEsy9LEsRM0cewEp6MAOAuWlAAAAAAGUbgBAAAAgyjcAAAAgEGs4QYAAPi7AwcP6qePP6bdpUWyZOnillm68zu3KDMz0+loiGDMcAMAAEj6bPs23ZX3mDZ0b6OTw67QiWF9tPbiDN3+y5/r2LFjTsdDBKNwAwAASJr/7NOyc/vLFRdXt83TIklVo/rr4cVPOJgMkY7CDQAAYt6xY8dUmOiW5apfjVxxXu2rLFMgEHAgGaIBhRsAAMS88vJyBZLiGx33e9yqra0NYSJEEwo3AACIeR07dlRySXmj42m1tuLjGy/kwNlEbeEuKChQXl6e0zEAAEAEiI+P14Dszqo5+kW9Mf+uAxrvGyDLshxIhmhg2bZtOx3CtCNHjjR5n6ysLBUXFxtIAyAScA4AYk8gENAvFv5Gm8tLdLpzW9nBgJJ3HdbILpfrru/+m9PxEObat2/f6BiFuxH8ZQvENs4BQOyybVuvvLFScV6vrhl8lZKTk52OhAhwtsLNg28AAAD+RatWrTR5/HVOx0AUido13AAAAEA4oHADAAAABlG4AQAAAIOND4ZaAAAOaElEQVQo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADCIwg0AAAAYROEGAAAADKJwAwAAAAZRuAEAAACDKNwAAACAQRRuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAABgUtYW7oKBAeXl5TscAAABAjPM4HcAUn88nn8/ndAwAAADEuKid4QYAAADCAYUbAAAAMIjCDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADCIwg0AAAAYROEGAAAADKJwAwAAAAZRuAEAAACDKNwAAACAQRRuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADCIwg0AAAAYROEGAAAADKJwAwAAAAZRuAEAAACDorZwFxQUKC8vz+kYAAAAiHEepwOY4vP55PP5nI4BAACAGBe1M9wAAABAOKBwAwAAAAZRuAEAAACDKNwAAACAQRRuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADCIwg0AAAAYROEGAAAADKJwAwAAAAZRuAEAAACDKNwAAACAQRRuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADDI43QAAAAiwYEDB/TK28tVWVWpq31DNaj/YFmW5XQsABGAGW4AAM7Ctm39Ku9h/fovD6pmRIkSptTo1ZLnNOvBu3Xy5Emn4wGIABRuAADO4oUVz+vkpUfVdXwHxbeIk8vtUravtTp8p6Ue/v1DTscDEAEo3AAAnMW6nWvUukdGve3xyXE63fKEjh075kAqAJGEwg0AwFnUeqsbHUvo5Nbnn+8PXRgAEYnCDQDAWbj9jd9foLowoNat24QwDYBIROEGAOAsLsnqplNHy+ttD/qD0oE4denSxYFUACIJhRsAgLO49abbVfpatYq2lsi2bUlS+Rente0PB3T3tHscTgcgEnAfbgAAziIuLk6/nP0rvf3uKq159gPZVlCdMjpr5t1zlJaW5nQ8ABGAwg0AwDl4PB6NzR2nsbnjnI4CIAKxpAQAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyLqLiWHDh3SG2+8obKyMvXs2VOjRo1yOhIAAABwViEr3AsXLtTGjRuVlpam+fPn123fvHmzFi9erGAwqJEjR2rSpEmNHqNDhw667bbbFAwG9fjjj1O4AQAAEPZCVriHDRumMWPGaMGCBXXbgsGgFi1apLlz5yozM1Nz5syRz+dTMBjUsmXLzth/xowZSktLU0FBgVatWqWhQ4eGKjoAAABwwUJWuLt3766ioqIztu3evVtt27ZVmzZtJEmDBw9Wfn6+Jk+erNmzZzd4HJ/PJ5/Pp4ceekhDhgwxnhsAAAD4Ohxdw11aWqrMzMy615mZmdq1a1ej7//ss8+0bt06+f1+XXHFFY2+b/Xq1Vq9erUkad68ecrKympyNo/Hc0H7AYgOnAOA2MX3H80toi6a7NGjh3r06HHO9+Xm5io3N7fudXFxcZM/Kysr64L2AxAdOAcAsYvvPy5E+/btGx1z9LaAGRkZKikpqXtdUlKijIwMBxMBAAAAzcvRwt21a1cdPXpURUVF8vv9WrNmjXw+n5ORAAAAgGYVsiUljz32mLZu3aqysjLdcccdmjp1qkaMGKHp06frwQcfVDAY1PDhw9WxY8dQRQIAAACMs2zbtp0OYdqRI0eavA/rt4DYxjkAiF18/3EhwnYNNwAAABDtKNwAAACAQRRuAAAAwCAKNwAAAGBQ1BbugoIC5eXlOR0DAAAAMS6injTZFD6fj3t6AwAAwHFRO8MNAAAAhAMKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMCgqC3cPNodAAAA4YBHuwMAAAAGRe0MNwAAABAOKNwAAACAQRRuAAAAwCAKNwAAAGAQhRsAAAAwiMINAAAAGEThBgAAAAyicAMAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMCgqC3cBQUFysvLczoGAAAAYpzH6QCm+Hw++Xw+p2MAABATjhw5osUvL1VR1Qm5gpaGXO7ThNHj5fV6nY4GOC5qZ7gBAEBorN9UoB8+9d/6fEic/BM7qmZyB63wfKJ75/1EtbW1TscDHEfhBgAAFywYDOp3rz6t9Bt6yNsivm57ysWtdWpoS/3xxWccTAeEBwo3AAC4YBs2bVTN5cmyLKveWIvsltpwYKsDqYDwQuEGAAAXrLC4SO6MxEbH/e5gCNMA4YnCDQAALliPSy9XYO/JBsds21ZSIC7EiYDwQ+EGAAAXrEuXLsr8wq3aiup6Y6fWHtDkq8c6kAoILxRuAADwtfx05my5lu/XyfwD8lfUqKLopE6s2KZh3m4aftVQp+MBjova+3ADAIDQaNmypX73wK+1YdNGfZC/VunJ7TVx+m1q2bKl09GAsEDhBgAAX5tlWfL17Sdf335ORwHCDktKAAAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADAoagt3QUGB8vLynI4BAACAGBe1twX0+Xzy+XxOxwAAAECMi9oZbgAAACAcULgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADCIwg0AAAAYFLWFu6CgQHl5eU7HAAAAQIzzOB3AFJ/PJ5/P53QMAAAAxDjLtm3b6RAAAABAtIraJSUNacoSk9mzZxtMEr0icRmP05lD8fnN/RnNcbyvc4wL2bep+3AOaDqnv0sXwunMsfr9/7rHMX0O4Pt/YZz+Pl2IUGWOqcLdr18/pyNEvUj8PXY6cyg+v7k/ozmO93WOcSH7Ov3nHAsi8ffY6cyx+v3/usfhHBCeIvH3OFSZWVLSiNmzZ2vevHlOxwDgEM4BQOzi+4/mFlMz3E2Rm5vrdAQADuIcAMQuvv9obsxwAwAAAAYxww0AAAAYROEGAAAADKJwAwAAAAZF7ZMmTVq/fr02btyoyspKjRgxQr1793Y6EoAQKiws1PLly1VRUaF7773X6TgADKuqqtKTTz4pj8ejHj166Oqrr3Y6EiJMzF00uXDhQm3cuFFpaWmaP39+3fbNmzdr8eLFCgaDGjlypCZNmnTOY5WXl2vJkiWaMWOGycgAmlFzngPmz59P4QYiVFPOBe+9956SkpLk8/n06KOPatasWQ4mRySKuRnuYcOGacyYMVqwYEHdtmAwqEWLFmnu3LnKzMzUnDlz5PP5FAwGtWzZsjP2nzFjhtLS0iRJy5cv1+jRo0OaH8DX05znAACRqynngpKSEnXq1EmS5HKxGhdNF3OFu3v37ioqKjpj2+7du9W2bVu1adNGkjR48GDl5+dr8uTJDT7e1bZtLV26VH369FFOTk5IcgNoHs1xDgAQ+ZpyLsjMzFRJSYk6d+6sGFsYgGbCP9MklZaWKjMzs+51ZmamSktLG33/m2++qS1btmjt2rVatWpVKCICMKip54CysjI98cQT2r9/v15++eVQRAQQAo2dC/r3769169bp97//fUQ+vhzOi7kZ7uYwbtw4jRs3zukYABySkpKi2267zekYAEIkISFBM2fOdDoGIhgz3JIyMjJUUlJS97qkpEQZGRkOJgIQSpwDAEicC2AOhVtS165ddfToURUVFcnv92vNmjXy+XxOxwIQIpwDAEicC2BOzN0W8LHHHtPWrVtVVlamtLQ0TZ06VSNGjNDGjRv11FNPKRgMavjw4ZoyZYrTUQEYwDkAgMS5AKEVc4UbAAAACCWWlAAAAAAGUbgBAAAAgyjcAAAAgEEUbgAAAMAgCjcAAABgEIUbAAAAMIjCDQAAABjkcToAAMA5H3zwgV5//XUdPnxYiYmJ6ty5s6ZMmaKkpCQtWbJEe/fuVVlZmV544QWnowJAxKJwA0CMev311/XKK6/o1ltvVe/eveXxeLR582bl5+dr5MiRGjRokEaNGqVHHnnE6agAENEo3AAQgyoqKvT8889r5syZGjBgQN12n88nn88nSWrfvr2OHTvmVEQAiBqs4QaAGLRz507V1taqf//+TkcBgKhH4QaAGFRWVqaUlBS53W6nowBA1KNwA0AMSklJUVlZmQKBgNNRACDqUbgBIAZdeuml8nq9ys/PdzoKAEQ9CjcAxKCkpCRNnTpVixYt0vr161VdXS2/369NmzbpmWeekW3bqqmpkd/vlyTV1NSotrbW4dQAEJks27Ztp0MAAJzx/vvva+XKlTp8+LASEhKUk5OjKVOmqGXLlrrrrrvOeG+rVq20YMECh5ICQOSicAMAAAAGsaQEAAAAMIjCDQAAABhE4QYAAAAMonADAAAABlG4AQAAAIMo3AAAAIBBFG4AAADAIAo3AAAAYBCFGwAAADDo/wNMkI0oIqp8KQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check best estimator on our test data"
      ],
      "metadata": {
        "id": "e7ZGAYSlnCWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crf = rs.best_estimator_\n",
        "y_pred = crf.predict(X_test)\n",
        "print(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98nLH_keZkFo",
        "outputId": "8e1dfb0e-ef4c-4ab6-a8da-17d9075a23da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B_LOC      0.854     0.817     0.835       301\n",
            "       I_LOC      0.724     0.344     0.467        61\n",
            "       B_ORG      0.748     0.504     0.602       242\n",
            "       I_ORG      0.558     0.444     0.494       250\n",
            "       B_PER      0.807     0.817     0.812       251\n",
            "       I_PER      0.817     0.921     0.866       189\n",
            "\n",
            "   micro avg      0.767     0.679     0.720      1294\n",
            "   macro avg      0.751     0.641     0.679      1294\n",
            "weighted avg      0.756     0.679     0.708      1294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPFaZLB9ZrkC",
        "outputId": "95ee39ef-9005-49a6-869b-06d5b34f0ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top likely transitions:\n",
            "I_ORG  -> I_ORG   4.646943\n",
            "B_PER  -> I_PER   4.446108\n",
            "I_LOC  -> I_LOC   4.309321\n",
            "B_LOC  -> I_LOC   3.960532\n",
            "B_ORG  -> I_ORG   3.942018\n",
            "O      -> O       2.589932\n",
            "I_PER  -> I_PER   2.281932\n",
            "O      -> B_LOC   1.757114\n",
            "O      -> B_ORG   1.736972\n",
            "O      -> B_PER   0.895809\n",
            "I_ORG  -> B_PER   0.362818\n",
            "B_LOC  -> B_PER   0.011154\n",
            "B_LOC  -> O       -0.077967\n",
            "I_PER  -> B_ORG   -0.142304\n",
            "I_LOC  -> B_PER   -0.174913\n",
            "B_PER  -> O       -0.241930\n",
            "I_LOC  -> B_ORG   -0.370130\n",
            "I_PER  -> O       -0.424477\n",
            "I_PER  -> I_LOC   -0.538541\n",
            "I_LOC  -> O       -0.560790\n",
            "\n",
            "Top unlikely transitions:\n",
            "I_ORG  -> O       -0.979075\n",
            "I_LOC  -> I_PER   -1.036123\n",
            "B_ORG  -> I_LOC   -1.040046\n",
            "B_PER  -> B_LOC   -1.066792\n",
            "B_PER  -> B_ORG   -1.088951\n",
            "I_ORG  -> I_PER   -1.132455\n",
            "I_PER  -> I_ORG   -1.134923\n",
            "B_ORG  -> I_PER   -1.195590\n",
            "I_ORG  -> I_LOC   -1.220115\n",
            "B_ORG  -> B_LOC   -1.386373\n",
            "B_PER  -> I_ORG   -1.437796\n",
            "I_ORG  -> B_LOC   -1.510096\n",
            "I_PER  -> B_PER   -1.539409\n",
            "B_LOC  -> I_PER   -1.887919\n",
            "B_LOC  -> I_ORG   -1.954085\n",
            "B_ORG  -> B_ORG   -2.016894\n",
            "B_PER  -> B_PER   -2.240923\n",
            "O      -> I_PER   -2.767871\n",
            "O      -> I_LOC   -3.507540\n",
            "O      -> I_ORG   -4.384552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top positive:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(30))\n",
        "\n",
        "print(\"\\nTop negative:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bEL4EBmZxmi",
        "outputId": "54b5c02d-daca-4fe5-a6ba-22a0eb797035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top positive:\n",
            "3.260244 O        -1:word.lower():»\n",
            "3.152593 B_PER    word.istitle()\n",
            "3.014604 B_ORG    word.isupper()\n",
            "2.941250 B_LOC    -1:word.lower():в\n",
            "2.909889 O        -1:word.lower():«\n",
            "2.613639 B_LOC    -1:word.lower():вашем\n",
            "2.524807 O        bias\n",
            "2.506439 I_PER    word.istitle()\n",
            "2.406698 B_LOC    word.istitle()\n",
            "2.360227 B_PER    word[-2:]:ин\n",
            "2.326501 B_ORG    -1:word.lower():глава\n",
            "2.305557 B_LOC    -1:word.lower():на\n",
            "2.292133 B_ORG    word[:-2]:сборн\n",
            "2.277558 B_ORG    word[-3:]:.ru\n",
            "2.277558 B_ORG    word[-2:]:ru\n",
            "2.258475 B_ORG    -1:word.lower():сообщает\n",
            "2.167237 O        BOS\n",
            "2.158794 O        +1:word.lemm:понедельник\n",
            "2.041944 B_LOC    word[-2:]:ии\n",
            "2.013699 O        word[:-2]:\n",
            "2.009933 O        EOS\n",
            "2.004950 B_ORG    +1:word.lower():заявляет\n",
            "1.994943 B_PER    +1:word.lower():сказал\n",
            "1.973869 O        word[:-1]:\n",
            "1.950167 I_PER    -1:word.istitle()\n",
            "1.914495 B_ORG    +1:word.lower():собирается\n",
            "1.910012 B_PER    word[-3:]:нко\n",
            "1.892117 B_ORG    +1:word.lower():пообещали\n",
            "1.889406 B_PER    word[-2:]:ов\n",
            "1.888221 B_LOC    -1:word.lower():из\n",
            "\n",
            "Top negative:\n",
            "-1.175912 B_PER    word[:-2]:\n",
            "-1.183650 I_ORG    word[-3:]:ния\n",
            "-1.208930 O        word[-2:]:ру\n",
            "-1.216561 O        -1:word.lower():у\n",
            "-1.217181 O        word.lower():правительство\n",
            "-1.220592 O        word[-2:]:ге\n",
            "-1.232956 O        word[-2:]:ба\n",
            "-1.235473 O        +1:word.lower():должен\n",
            "-1.238702 O        +1:word.lower():1\n",
            "-1.261013 O        +1:word.lower():и\n",
            "-1.262824 O        -1:word.lower():обсе\n",
            "-1.280123 O        word[-3:]:сия\n",
            "-1.294768 O        +1:word.lower():собирается\n",
            "-1.322206 O        +1:word.lower():утверждают\n",
            "-1.349388 O        +1:word.lower():сказал\n",
            "-1.363035 I_LOC    -1:word.isupper()\n",
            "-1.412597 O        -1:word.lower():но\n",
            "-1.428696 O        -1:word.lower():глава\n",
            "-1.446312 O        word[:-1]:Е\n",
            "-1.473258 O        +1:word.lower():сколково\n",
            "-1.585047 O        word[-3:]:кий\n",
            "-1.595510 O        +1:word.lower():считает\n",
            "-1.609437 O        +1:word.lower():отметил\n",
            "-1.648548 I_ORG    -1:word.isupper()\n",
            "-1.740287 I_PER    bias\n",
            "-1.797811 O        +1:word.lower():(\n",
            "-2.049652 B_ORG    word[:-2]:\n",
            "-2.480391 O        word[:-2]:сборн\n",
            "-4.818663 O        word.isupper()\n",
            "-6.265480 O        word.istitle()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3. Try your favorite ML algorithm.\n",
        "***\n",
        "1. Make submission to leaderboard and beat with your favorite ML algorithm (0.55 macro f1).\n",
        "2. Plot learning curves (if your algo is not rule-based).\n",
        "3. Describe your solution (or one of your solutions) and results. Also here your can do many experiments."
      ],
      "metadata": {
        "id": "TRl-b0BHIreg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  \n",
        "I've decided to use BertForTokenClassification. Model has BERT as its base architecture, with a token classification head on top. NER is typically treated as a token classification problem."
      ],
      "metadata": {
        "id": "CMMvrcr-msYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "XWiP2CZ_FnH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiTi5M9N5lPf",
        "outputId": "53908d6d-cb4b-482a-bdb3-b13f038cf5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "RV8KS_yQ10ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preprocess"
      ],
      "metadata": {
        "id": "fVlzbA51Fan3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our dataset.  \n",
        "I will use my preprocessed file from first part of the HW."
      ],
      "metadata": {
        "id": "6iaHmG9PnhM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/final_data_NER.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "ZZJ3_ZDm1M0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "XF2emM0R1SAk",
        "outputId": "9c9e4f05-e754-4cd3-c730-07ba6db75407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
              "0           0             0               0   \n",
              "1           1             1               1   \n",
              "2           2             2               2   \n",
              "3           3             3               3   \n",
              "4           4             4               4   \n",
              "\n",
              "                                              labels  \\\n",
              "0  O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...   \n",
              "1  O O O O O O O O O O O B_LOC B_PER I_PER O O O ...   \n",
              "2  O O O O O O O O O O O O O O O O O O O O B_PER ...   \n",
              "3                  O O O O O O O O O O O O O O O O O   \n",
              "4  O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...   \n",
              "\n",
              "                                                text    clf  \\\n",
              "0  В понедельник 28 июня у здания мэрии Москвы на...  False   \n",
              "1  Среди требований , выдвигаемых организаторами ...  False   \n",
              "2  Участникам акции предлагалось принести с собой...  False   \n",
              "3  Начало акции было намечено на 19 часов ; подчё...   True   \n",
              "4  Освещающие акцию блоггеры сообщили , что автоб...  False   \n",
              "\n",
              "                                             pos_str  \\\n",
              "0  ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...   \n",
              "1  ADP NOUN PUNCT VERB NOUN NOUN PUNCT PUNCT ADJ ...   \n",
              "2  NOUN NOUN VERB VERB ADP PRON NOUN NOUN CCONJ N...   \n",
              "3  NOUN NOUN AUX VERB ADP NUM NOUN PUNCT VERB PUN...   \n",
              "4  ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...   \n",
              "\n",
              "                                            lemm_srt  \n",
              "0  в понедельник 28 июнь у здание мэрия москва на...  \n",
              "1  среди требование , выдвигать организатор акция...  \n",
              "2  участник акция предлагаться принести с себя ли...  \n",
              "3  начало акция быть наметить на 19 час ; подчерк...  \n",
              "4  освещать акция блогер сообщить , что автобус с...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed82f764-6abb-4702-8b8b-2b87db214b8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>pos_str</th>\n",
              "      <th>lemm_srt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...</td>\n",
              "      <td>в понедельник 28 июнь у здание мэрия москва на...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>O O O O O O O O O O O B_LOC B_PER I_PER O O O ...</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN PUNCT VERB NOUN NOUN PUNCT PUNCT ADJ ...</td>\n",
              "      <td>среди требование , выдвигать организатор акция...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_PER ...</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>False</td>\n",
              "      <td>NOUN NOUN VERB VERB ADP PRON NOUN NOUN CCONJ N...</td>\n",
              "      <td>участник акция предлагаться принести с себя ли...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>True</td>\n",
              "      <td>NOUN NOUN AUX VERB ADP NUM NOUN PUNCT VERB PUN...</td>\n",
              "      <td>начало акция быть наметить на 19 час ; подчерк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...</td>\n",
              "      <td>освещать акция блогер сообщить , что автобус с...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed82f764-6abb-4702-8b8b-2b87db214b8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed82f764-6abb-4702-8b8b-2b87db214b8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed82f764-6abb-4702-8b8b-2b87db214b8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grNYxqAI18Xw",
        "outputId": "46f3748d-2d04-44c7-907e-7676defd6904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1519, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIw7MICI2DzF",
        "outputId": "e9e4d02a-939e-48ca-c957-bf2bfb08e86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'labels', 'text', 'clf',\n",
              "       'pos_str', 'lemm_srt'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is some legacy parts of code from first tries."
      ],
      "metadata": {
        "id": "CMTNMu8mplIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = data.text.str.split(expand=True).stack()\n",
        "labels = data.labels.str.split(expand=True).stack()\n",
        "pos = data.pos_str.str.split(expand=True).stack()\n",
        "lemm = data.lemm_srt.str.split(expand=True).stack()\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Sentence': words.index.get_level_values(0) + 1, \n",
        "    'Word': words.values,\n",
        "    'Label': labels.values,\n",
        "    'POS': pos.values,\n",
        "    'Lemm': lemm.values,\n",
        "})\n",
        "data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "XCVj4_Up2mso",
        "outputId": "9a686993-313f-4d67-d820-0e3cbba5b652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence         Word Label   POS         Lemm\n",
              "0         1            В     O   ADP            в\n",
              "1         1  понедельник     O  NOUN  понедельник\n",
              "2         1           28     O   ADJ           28"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e33a03eb-c708-47e1-9fec-eced97fdf2e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "      <th>POS</th>\n",
              "      <th>Lemm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В</td>\n",
              "      <td>O</td>\n",
              "      <td>ADP</td>\n",
              "      <td>в</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>понедельник</td>\n",
              "      <td>O</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>понедельник</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>O</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e33a03eb-c708-47e1-9fec-eced97fdf2e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e33a03eb-c708-47e1-9fec-eced97fdf2e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e33a03eb-c708-47e1-9fec-eced97fdf2e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create a new column called \"sentence\" which groups the words by sentence \n",
        "data['sentence'] = data[['Sentence','Word','Label']].groupby(['Sentence'])['Word'].transform(lambda x: ' '.join(x))\n",
        "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
        "data['word_labels'] = data[['Sentence','Word','Label']].groupby(['Sentence'])['Label'].transform(lambda x: ','.join(x))\n",
        "data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rHqWrKxF2pZE",
        "outputId": "20b5d8ec-a0c3-410d-cb93-94bad3cbdad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence         Word Label   POS         Lemm  \\\n",
              "0         1            В     O   ADP            в   \n",
              "1         1  понедельник     O  NOUN  понедельник   \n",
              "2         1           28     O   ADJ           28   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "2  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  \n",
              "1  O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  \n",
              "2  O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ebbac7b-0c6f-4070-bce7-08fd3cece410\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "      <th>POS</th>\n",
              "      <th>Lemm</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В</td>\n",
              "      <td>O</td>\n",
              "      <td>ADP</td>\n",
              "      <td>в</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>понедельник</td>\n",
              "      <td>O</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>понедельник</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>O</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>28</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ebbac7b-0c6f-4070-bce7-08fd3cece410')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ebbac7b-0c6f-4070-bce7-08fd3cece410 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ebbac7b-0c6f-4070-bce7-08fd3cece410');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's only keep the \"sentence\" and \"word_labels\" columns, and drop duplicates:"
      ],
      "metadata": {
        "id": "rs0brnI0v8CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"Sentence\", \"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7yuoHadfwJEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mM5RAZim27ww",
        "outputId": "ed97bdb3-3480-4ea7-8aa4-6b612bff4415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence                                           sentence  \\\n",
              "0         1  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1         2  Среди требований , выдвигаемых организаторами ...   \n",
              "2         3  Участникам акции предлагалось принести с собой...   \n",
              "3         4  Начало акции было намечено на 19 часов ; подчё...   \n",
              "4         5  Освещающие акцию блоггеры сообщили , что автоб...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...  \n",
              "3                  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "4  O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08aca8b7-32d2-48e3-b069-4c5d538a3341\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08aca8b7-32d2-48e3-b069-4c5d538a3341')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08aca8b7-32d2-48e3-b069-4c5d538a3341 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08aca8b7-32d2-48e3-b069-4c5d538a3341');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While examing Sklearn documentation, I've found some interesting for my Class for encoding labels.  \n",
        "Despite the fact that I already numerated my sentences, let's try this Class."
      ],
      "metadata": {
        "id": "5I-tGKJkqcyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "jUkveNfj35lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = data\n",
        "data_df[\"Sentence #\"] = LabelEncoder().fit_transform(data[\"Sentence\"])\n",
        "data_df"
      ],
      "metadata": {
        "id": "baJ4i_zp3ceO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "f3d753b0-d418-4cf4-8856-bb54fe3a40eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentence                                           sentence  \\\n",
              "0            1  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1            2  Среди требований , выдвигаемых организаторами ...   \n",
              "2            3  Участникам акции предлагалось принести с собой...   \n",
              "3            4  Начало акции было намечено на 19 часов ; подчё...   \n",
              "4            5  Освещающие акцию блоггеры сообщили , что автоб...   \n",
              "...        ...                                                ...   \n",
              "1514      1515  Сделка способствует укреплений растущих связей...   \n",
              "1515      1516  Председатель КНР Ху Цзиньтао и российский през...   \n",
              "1516      1517  Новые поставки нефти почти вдвое увеличат объе...   \n",
              "1517      1518  До сих пор доставка сырой нефти осуществлялись...   \n",
              "1518      1519  По договору между двумя странами о нефтепровод...   \n",
              "\n",
              "                                            word_labels  Sentence #  \n",
              "0     O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...           0  \n",
              "1     O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...           1  \n",
              "2     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...           2  \n",
              "3                     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O           3  \n",
              "4     O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...           4  \n",
              "...                                                 ...         ...  \n",
              "1514                                      O,O,O,O,O,O,O        1514  \n",
              "1515  O,B_LOC,B_PER,I_PER,O,O,O,B_PER,I_PER,O,O,O,O,...        1515  \n",
              "1516            O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,B_LOC        1516  \n",
              "1517            O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC        1517  \n",
              "1518  O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,O,O,O,O,O,O,O,O,...        1518  \n",
              "\n",
              "[1519 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3f11800-0ed6-4335-9c87-3c42fd011746\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "      <th>Sentence #</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>1515</td>\n",
              "      <td>Сделка способствует укреплений растущих связей...</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "      <td>1514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>1516</td>\n",
              "      <td>Председатель КНР Ху Цзиньтао и российский през...</td>\n",
              "      <td>O,B_LOC,B_PER,I_PER,O,O,O,B_PER,I_PER,O,O,O,O,...</td>\n",
              "      <td>1515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>1517</td>\n",
              "      <td>Новые поставки нефти почти вдвое увеличат объе...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,B_LOC</td>\n",
              "      <td>1516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1518</td>\n",
              "      <td>До сих пор доставка сырой нефти осуществлялись...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC</td>\n",
              "      <td>1517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>1519</td>\n",
              "      <td>По договору между двумя странами о нефтепровод...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,O,O,O,O,O,O,O,O,...</td>\n",
              "      <td>1518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1519 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3f11800-0ed6-4335-9c87-3c42fd011746')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3f11800-0ed6-4335-9c87-3c42fd011746 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3f11800-0ed6-4335-9c87-3c42fd011746');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = data_df[[\"Sentence #\", \"sentence\", \"word_labels\"]]\n",
        "data_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-gZCduVL37sG",
        "outputId": "e039fd5f-9b26-4eef-99d2-900c609ce41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence #                                           sentence  \\\n",
              "0           0  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1           1  Среди требований , выдвигаемых организаторами ...   \n",
              "2           2  Участникам акции предлагалось принести с собой...   \n",
              "3           3  Начало акции было намечено на 19 часов ; подчё...   \n",
              "4           4  Освещающие акцию блоггеры сообщили , что автоб...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...  \n",
              "3                  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "4  O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-565f2835-b8eb-4d9e-90d4-28d014887e96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-565f2835-b8eb-4d9e-90d4-28d014887e96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-565f2835-b8eb-4d9e-90d4-28d014887e96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-565f2835-b8eb-4d9e-90d4-28d014887e96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "y-NtDnfT8dcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are tring to add some data for LOC labels, using synonims."
      ],
      "metadata": {
        "id": "Q_Dmbuer8i6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/final_data_NER.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "SfRKN_o59svv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = train_df[train_df['labels'].str.contains(\"I_LOC\")]"
      ],
      "metadata": {
        "id": "_ZFv-sXrjUnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = s.text.str.split(expand=True).stack()\n",
        "labels = s.labels.str.split(expand=True).stack()\n",
        "\n",
        "train_words_df = pd.DataFrame({\n",
        "    'Sentence': words.index.get_level_values(0) + 1, \n",
        "    'Word': words.values,\n",
        "    'Label': labels.values,\n",
        "})"
      ],
      "metadata": {
        "id": "MqnKWWhG9svw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_words_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "b28b62f7-067e-4234-b5f2-fe0a3d746bf4",
        "id": "aV_Y4Xv69svw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentence           Word  Label\n",
              "0            1              В      O\n",
              "1            1    понедельник      O\n",
              "2            1             28      O\n",
              "3            1           июня      O\n",
              "4            1              у      O\n",
              "...        ...            ...    ...\n",
              "2710      1518         дороге      O\n",
              "2711      1518              в      O\n",
              "2712      1518  тихоокеанский  B_LOC\n",
              "2713      1518           порт  I_LOC\n",
              "2714      1518       Козьмино  I_LOC\n",
              "\n",
              "[2715 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afb1e778-5c01-4a7a-9503-c3391a42b84c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>понедельник</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>июня</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>у</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>1518</td>\n",
              "      <td>дороге</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>1518</td>\n",
              "      <td>в</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>1518</td>\n",
              "      <td>тихоокеанский</td>\n",
              "      <td>B_LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>1518</td>\n",
              "      <td>порт</td>\n",
              "      <td>I_LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2714</th>\n",
              "      <td>1518</td>\n",
              "      <td>Козьмино</td>\n",
              "      <td>I_LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2715 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afb1e778-5c01-4a7a-9503-c3391a42b84c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afb1e778-5c01-4a7a-9503-c3391a42b84c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afb1e778-5c01-4a7a-9503-c3391a42b84c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"], s[\"Label\"])] #, train_words_df[\"POS\"].values.tolist(), train_words_df[\"Lemm\"].values.tolist()"
      ],
      "metadata": {
        "id": "lEuCVVwK9svw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = train_words_df.groupby(\"Sentence\").apply(agg_func)\n"
      ],
      "metadata": {
        "id": "L1R_8ICe9svw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318e93c0-9313-4c6e-edb8-0150dab9a03e",
        "id": "MX-TW20T9svw"
      },
      "source": [
        "import re\n",
        "import gensim\n",
        "import logging\n",
        "import nltk.data \n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada3d7ea-6623-4bee-82c1-bc61114a8882",
        "id": "__S-GRtc9svw"
      },
      "source": [
        "urllib.request.urlretrieve(\n",
        "    \"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \n",
        "    \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
              " <http.client.HTTPMessage at 0x7f1178060490>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXJ9m6569svx"
      },
      "source": [
        "model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
        "\n",
        "model_ru = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2\n",
        "!pip install pymorphy2-dicts\n",
        "!pip install DAWG-Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48da309-2a3b-46a8-a6ee-bf78ca09a6a1",
        "id": "TGCFD3eh9svx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Collecting pymorphy2-dicts\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts\n",
            "Successfully installed pymorphy2-dicts-2.4.393442.3710985\n",
            "Requirement already satisfied: DAWG-Python in /usr/local/lib/python3.7/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "LH6A-4b_9svx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sents = []"
      ],
      "metadata": {
        "id": "YtHxeS-o9svx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i in grouped:\n",
        "    print(i)\n",
        "    err = 0\n",
        "    for n, item in enumerate(i):\n",
        "        if item[1] == 'I_LOC': # моджно поменять на B_loc\n",
        "            print(item[0])\n",
        "            #print(n)\n",
        "            p = morph.parse(item[0])[0]\n",
        "            pos = p.tag.POS\n",
        "            if pos:    \n",
        "                if pos == \"ADJF\": # в локах бывают \"\", союзы и английские слова, с этим траблы\n",
        "                      pos = \"_A\"\n",
        "                else:\n",
        "                      pos = \"_S\"\n",
        "                case = p.tag.case\n",
        "                try:\n",
        "                    syn_ten = model_ru.most_similar(positive=[f'{p.normal_form}{pos}'], topn=10)\n",
        "                except KeyError:\n",
        "                    err = 1\n",
        "                #print(err)\n",
        "                if not err:\n",
        "                    syn = []\n",
        "                    for w, fr in syn_ten:\n",
        "                        syn.append(w[:-2])\n",
        "                    print(syn)\n",
        "                    comp = []\n",
        "                    for s in syn:\n",
        "                        p_s = morph.parse(s)[0]\n",
        "                        #print(p_s[0])\n",
        "                        try:\n",
        "                            c_s = p_s.inflect({\"loct\"})[0] # тут тоже ошибка если не в словаре слово\n",
        "                        except: TypeError\n",
        "                        comp.append((c_s, item[1]))\n",
        "                    #print(comp)\n",
        "                    if comp:\n",
        "                        #for c in comp:\n",
        "                        n_i = i\n",
        "                        n_i[n] = random.choice(comp)\n",
        "                        #print(n_i)\n",
        "                        #new_sents.append(n_i)\n",
        "                        #n_i = i\n",
        "            \n",
        "                pass\n",
        "    new_sents.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37597e75-df67-4e43-a0c0-e110e0c5747a",
        "id": "QAvu-lJutour"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('В', 'O'), ('понедельник', 'O'), ('28', 'O'), ('июня', 'O'), ('у', 'O'), ('здания', 'O'), ('мэрии', 'B_ORG'), ('Москвы', 'I_ORG'), ('на', 'O'), ('Тверской', 'B_LOC'), ('площади', 'I_LOC'), ('состоялась', 'O'), ('очередная', 'O'), ('несанкционированная', 'O'), ('акция', 'O'), ('протеста', 'O'), ('«', 'O'), ('День', 'O'), ('гнева', 'O'), ('»', 'O'), (',', 'O'), ('в', 'O'), ('этот', 'O'), ('раз', 'O'), ('направленная', 'O'), (',', 'O'), ('главным', 'O'), ('образом', 'O'), (',', 'O'), ('против', 'O'), ('политики', 'O'), ('московских', 'O'), ('и', 'O'), ('подмосковных', 'O'), ('властей', 'O')]\n",
            "площади\n",
            "['сквер', 'улица', 'бульвар', 'переулок', 'парк', 'пресня', 'набережная', 'проспект', 'здание', 'пустырь']\n",
            "[('Освещающие', 'O'), ('акцию', 'O'), ('блоггеры', 'O'), ('сообщили', 'O'), (',', 'O'), ('что', 'O'), ('автобусы', 'O'), ('с', 'O'), ('милицией', 'O'), ('стали', 'O'), ('занимать', 'O'), ('площадь', 'O'), ('у', 'O'), ('памятника', 'B_LOC'), ('Юрию', 'I_LOC'), ('Долгорукому', 'I_LOC'), ('ещё', 'O'), ('с', 'O'), ('15', 'O'), ('часов', 'O'), ('дня', 'O'), (',', 'O'), ('центральная', 'O'), ('часть', 'O'), ('площади', 'O'), ('была', 'O'), ('огорожена', 'O')]\n",
            "Юрию\n",
            "['сергей', 'алексей', 'виктор', 'владимир', 'анатолий', 'виталий', 'василий', 'игорь', 'валерий', 'николай']\n",
            "Долгорукому\n",
            "['долгоруков', 'червак', 'гуллер', 'кобаладзе', 'нечетов', 'дудь', 'голицын', 'ширманкин', 'присекин', 'рытхэу']\n",
            "[('Барак', 'B_PER'), ('Обама', 'I_PER'), ('принимает', 'O'), ('в', 'O'), ('Белом', 'B_LOC'), ('доме', 'I_LOC'), ('своего', 'O'), ('французского', 'O'), ('коллегу', 'O'), ('Николя', 'B_PER'), ('Саркози', 'I_PER')]\n",
            "доме\n",
            "['особняк', 'квартира', 'флигель', 'домик', 'коттедж', 'усадьба', 'дача', 'особнячок', 'хата', 'изба']\n",
            "[('В', 'O'), ('частности', 'O'), (',', 'O'), ('лидеры', 'O'), ('намерены', 'O'), ('обменяться', 'O'), ('мнениями', 'O'), ('о', 'O'), ('перспективах', 'O'), ('военных', 'O'), ('действий', 'O'), ('НАТО', 'B_ORG'), ('в', 'O'), ('Афганистане', 'B_LOC'), (',', 'O'), ('волнениях', 'O'), ('в', 'O'), ('Пакистане', 'B_LOC'), ('и', 'O'), ('угрозах', 'O'), ('экстремистов', 'O'), ('в', 'O'), ('Северной', 'B_LOC'), ('Африке', 'I_LOC')]\n",
            "Африке\n",
            "['америка', 'индия', 'юго-восточный', 'кавказ', 'европа', 'австралия', 'дакота', 'корея', 'юговосточный', 'океания']\n",
            "[('В', 'O'), ('понедельник', 'O'), ('Джаред', 'B_PER'), ('Лофнер', 'I_PER'), ('в', 'O'), ('наручниках', 'O'), ('и', 'O'), ('в', 'O'), ('сопровождении', 'O'), ('нескольких', 'O'), ('охранников', 'O'), ('доставлен', 'O'), ('в', 'O'), ('суд', 'O'), ('в', 'O'), ('города', 'B_LOC'), ('Феникс', 'I_LOC')]\n",
            "Феникс\n",
            "['перелетный', 'гамаюн', 'нелетающий', 'алконост', 'роз', 'гнездувать', 'браконьерять', 'жар-птица', 'дракон', 'марабу']\n",
            "[('Тогда', 'O'), ('были', 'O'), ('убиты', 'O'), ('шесть', 'O'), ('человек', 'O'), (',', 'O'), ('а', 'O'), ('член', 'O'), ('Палаты', 'B_ORG'), ('представителей', 'I_ORG'), ('Конгресса', 'I_ORG'), ('США', 'I_ORG'), ('от', 'O'), ('штата', 'B_LOC'), ('Аризона', 'I_LOC'), ('Гэбриэль', 'B_PER'), ('Гиффордс', 'I_PER'), ('получила', 'O'), ('ранение', 'O'), ('и', 'O'), ('в', 'O'), ('настоящее', 'O'), ('время', 'O'), ('находится', 'O'), ('в', 'O'), ('критическом', 'O'), ('состоянии', 'O')]\n",
            "Аризона\n",
            "['нью-мексико', 'вайоминг', 'флорида', 'орегон', 'колорадо', 'джорджия', 'миннесота', 'айдахо', 'кентукки', 'техас']\n",
            "[('Обама', 'B_PER'), ('выступал', 'O'), ('в', 'O'), ('Белом', 'B_LOC'), ('доме', 'I_LOC'), ('через', 'O'), ('несколько', 'O'), ('часов', 'O'), ('после', 'O'), ('того', 'O'), (',', 'O'), ('как', 'O'), ('по', 'O'), ('всей', 'O'), ('стране', 'O'), ('прошла', 'O'), ('минута', 'O'), ('молчания', 'O'), ('в', 'O'), ('память', 'O'), ('о', 'O'), ('жертвах', 'O'), ('этого', 'O'), ('преступления', 'O')]\n",
            "доме\n",
            "['особняк', 'квартира', 'флигель', 'домик', 'коттедж', 'усадьба', 'дача', 'особнячок', 'хата', 'изба']\n",
            "[('Президент', 'O'), ('и', 'O'), ('первая', 'O'), ('леди', 'O'), ('Мишель', 'B_PER'), ('Обама', 'I_PER'), ('задержались', 'O'), ('в', 'O'), ('Белом', 'B_LOC'), ('доме', 'I_LOC'), (',', 'O'), ('а', 'O'), ('персонал', 'O'), ('и', 'O'), ('посетители', 'O'), ('собрались', 'O'), ('на', 'O'), ('ступенях', 'O'), ('Капитолия', 'B_LOC')]\n",
            "доме\n",
            "['особняк', 'квартира', 'флигель', 'домик', 'коттедж', 'усадьба', 'дача', 'особнячок', 'хата', 'изба']\n",
            "[('В', 'O'), ('тот', 'O'), ('же', 'O'), ('день', 'O'), ('Южная', 'B_LOC'), ('Корея', 'I_LOC'), ('заявила', 'O'), (',', 'O'), ('что', 'O'), ('вся', 'O'), ('импортируемая', 'O'), ('из', 'O'), ('Германии', 'B_LOC'), ('свинина', 'O'), ('и', 'O'), ('мясо', 'O'), ('птицы', 'O'), ('будут', 'O'), ('помещены', 'O'), ('в', 'O'), ('карантин', 'O'), ('для', 'O'), ('проведения', 'O'), ('соответствующей', 'O'), ('проверки', 'O')]\n",
            "Корея\n",
            "['вьетнам', 'китай', 'осетия', 'африка', 'индия', 'дакота', 'кавказ', 'иран', 'япония', 'америка']\n",
            "[('До', 'O'), ('сих', 'O'), ('пор', 'O'), ('среди', 'O'), ('главных', 'O'), ('стратегических', 'O'), ('партнёров', 'O'), ('официального', 'O'), ('Киева', 'B_LOC'), ('назывались', 'O'), ('страны', 'O'), (',', 'O'), ('формирующие', 'O'), ('мировую', 'O'), ('повестку', 'O'), ('дня', 'O'), (':', 'O'), ('Соединённые', 'B_LOC'), ('Штаты', 'I_LOC'), (',', 'O'), ('Евросоюз', 'B_ORG'), (',', 'O'), ('Китай', 'B_LOC'), ('и', 'O'), ('Россия', 'B_LOC')]\n",
            "Штаты\n",
            "['королевство', 'калифорния', 'шатат', 'главуголь', 'америка', 'довольствие', 'австралия', 'хафизулла', 'канада', 'айова']\n",
            "[('Турция', 'B_LOC'), ('поможет', 'O'), ('крымским', 'O'), ('татарам', 'O'), ('По', 'O'), ('итогам', 'O'), ('встреч', 'O'), ('на', 'O'), ('высшем', 'O'), ('уровне', 'O'), ('в', 'O'), ('Киеве', 'B_LOC'), ('не', 'O'), ('объявлялось', 'O'), (',', 'O'), ('как', 'O'), ('видится', 'O'), ('будущее', 'O'), ('крымско-татарского', 'O'), ('населения', 'O'), ('автономной', 'B_LOC'), ('республики', 'I_LOC'), ('Крым', 'I_LOC'), ('в', 'O'), ('украинско-турецких', 'O'), ('отношениях', 'O')]\n",
            "республики\n",
            "['государство', 'азербайджан', 'украина', 'башкирия', 'грузия', 'территория', 'армения', 'казахстан', 'ичкерия', 'татарстан']\n",
            "Крым\n",
            "['одесса', 'киев', 'ялта', 'севастополь', 'москва', 'кисловодск', 'архангельск', 'кавказ', 'прибалтика', 'смоленск']\n",
            "[('Почему', 'O'), ('?', 'O'), ('Мусульманский', 'O'), ('мир', 'O'), ('довольно', 'O'), ('обширен', 'O'), ('…', 'O'), ('Мустафа', 'B_PER'), ('Джемилев', 'I_PER'), (':', 'O'), ('Во', 'O'), ('времена', 'O'), ('могущества', 'O'), ('Османской', 'B_LOC'), ('империи', 'I_LOC'), ('в', 'O'), ('регионе', 'O'), ('мы', 'O'), ('и', 'O'), ('турецкая', 'O'), ('сторона', 'O'), ('длительное', 'O'), ('время', 'O'), ('были', 'O'), ('союзниками', 'O')]\n",
            "империи\n",
            "['государственность', 'государство', 'держава', 'монархия', 'владычество', 'столица', 'федерация', 'цивилизация', 'унитарность', 'подданный']\n",
            "[('Кроме', 'O'), ('того', 'O'), (',', 'O'), ('после', 'O'), ('завоевания', 'O'), ('Крыма', 'B_LOC'), ('Россией', 'B_LOC'), (',', 'O'), ('огромное', 'O'), ('количество', 'O'), ('крымских', 'O'), ('татар', 'O'), ('вынуждены', 'O'), ('были', 'O'), ('переселиться', 'O'), ('на', 'O'), ('территорию', 'O'), ('Османской', 'B_LOC'), ('империи', 'I_LOC')]\n",
            "империи\n",
            "['государственность', 'государство', 'держава', 'монархия', 'владычество', 'столица', 'федерация', 'цивилизация', 'унитарность', 'подданный']\n",
            "[('Голос', 'B_ORG'), ('Америки', 'I_ORG'), (':', 'O'), ('Достаточно', 'O'), ('ли', 'O'), ('сегодня', 'O'), ('у', 'O'), ('Крыма', 'B_LOC'), ('полномочий', 'O'), ('для', 'O'), ('решения', 'O'), ('своих', 'O'), ('внутренних', 'O'), ('проблем', 'O'), ('?', 'O'), ('Мустафа', 'B_PER'), ('Джемилев', 'I_PER'), (':', 'O'), ('Особых', 'O'), ('полномочий', 'O'), ('у', 'O'), ('крымской', 'B_LOC'), ('автономии', 'I_LOC'), ('нет', 'O')]\n",
            "автономии\n",
            "['независимость', 'самостоятельность', 'суверенитет', 'самобытность', 'самоопределение', 'свобода', 'суверенность', 'самостийность', 'автокефалия', 'равноправие']\n",
            "[('Голос', 'B_ORG'), ('Америки', 'I_ORG'), (':', 'O'), ('Спасибо', 'O'), ('за', 'O'), ('интервью', 'O'), ('!', 'O'), ('Гагаузы', 'O'), ('тоже', 'O'), ('не', 'O'), ('прочь', 'O'), ('дружить', 'O'), ('с', 'O'), ('Турцией', 'B_LOC'), ('По', 'O'), ('словам', 'O'), ('приднестровского', 'O'), ('аналитика', 'O'), ('Романа', 'B_PER'), ('Коноплева', 'I_PER'), (',', 'O'), ('Крым', 'B_LOC'), ('не', 'O'), ('единственный', 'O'), ('объект', 'O'), ('пристального', 'O'), ('интереса', 'O'), ('Анкары', 'B_LOC'), ('на', 'O'), ('постсоветском', 'O'), ('пространстве', 'O'), (':', 'O'), ('«', 'O'), ('Турция', 'B_LOC'), ('наравне', 'O'), ('с', 'O'), ('Россией', 'B_LOC'), ('является', 'O'), ('стратегическим', 'O'), ('партнером', 'O'), ('Гагаузской', 'B_LOC'), ('автономии', 'I_LOC'), ('Молдавской', 'I_LOC'), ('республики', 'I_LOC')]\n",
            "автономии\n",
            "['независимость', 'самостоятельность', 'суверенитет', 'самобытность', 'самоопределение', 'свобода', 'суверенность', 'самостийность', 'автокефалия', 'равноправие']\n",
            "Молдавской\n",
            "['грузинский', 'армянский', 'азербайджанский', 'узбекский', 'украинский', 'эстонский', 'абхазский', 'латвийский', 'казахский', 'таджикский']\n",
            "республики\n",
            "['государство', 'азербайджан', 'украина', 'башкирия', 'грузия', 'территория', 'армения', 'казахстан', 'ичкерия', 'татарстан']\n",
            "[('В', 'O'), ('условиях', 'O'), ('политической', 'O'), ('нестабильности', 'O'), ('и', 'O'), ('дезинтеграционных', 'O'), ('процессов', 'O'), ('в', 'O'), ('Молдове', 'B_LOC'), (',', 'O'), ('гагаузы', 'O'), ('явно', 'O'), ('заинтересованы', 'O'), ('в', 'O'), ('укреплении', 'O'), ('связей', 'O'), ('с', 'O'), ('родиной', 'O'), ('предков', 'O'), ('—', 'O'), ('относительно', 'O'), ('стабильной', 'O'), ('и', 'O'), ('экономически', 'O'), ('развитой', 'O'), ('Турецкой', 'B_LOC'), ('республикой', 'I_LOC'), ('»', 'O'), (',', 'O'), ('—', 'O'), ('сказал', 'O'), ('Роман', 'B_PER'), ('Коноплев', 'I_PER'), ('Русской', 'B_ORG'), ('службе', 'I_ORG'), ('«', 'I_ORG'), ('Голоса', 'I_ORG'), ('Америки', 'I_ORG'), ('»', 'I_ORG')]\n",
            "республикой\n",
            "['государство', 'азербайджан', 'украина', 'башкирия', 'грузия', 'территория', 'армения', 'казахстан', 'ичкерия', 'татарстан']\n",
            "[('В', 'O'), ('конце', 'O'), ('субботней', 'O'), ('классификации', 'O'), ('Михаэль', 'B_PER'), ('Шумахер', 'I_PER'), ('допустил', 'O'), ('ошибку', 'O'), ('в', 'O'), ('повороте', 'O'), ('Раскассэ', 'B_LOC'), ('(', 'O'), ('La', 'B_LOC'), ('Rascasse', 'I_LOC'), (')', 'O'), (',', 'O'), ('заблокировав', 'O'), ('свои', 'O'), ('колёса', 'O'), ('и', 'O'), ('остановившись', 'O'), ('менее', 'O'), ('чем', 'O'), ('в', 'O'), ('метре', 'O'), ('от', 'O'), ('отбойников', 'O')]\n",
            "Rascasse\n",
            "[('В', 'O'), ('августе', 'O'), ('2004', 'O'), ('года', 'O'), ('\"', 'O'), ('продуктопровод', 'O'), ('\"', 'O'), (',', 'O'), ('проложенный', 'O'), ('нелегально', 'O'), ('через', 'O'), ('пограничную', 'O'), ('реку', 'B_LOC'), ('Нарву', 'I_LOC'), ('и', 'O'), ('имеющий', 'O'), ('общую', 'O'), ('протяжённость', 'O'), ('около', 'O'), ('двух', 'O'), ('километров', 'O'), (',', 'O'), ('был', 'O'), ('испытан', 'O'), ('и', 'O'), ('начал', 'O'), ('функционировать', 'O')]\n",
            "Нарву\n",
            "['смоленск', 'псков', 'двинск', 'копорье', 'варшава', 'ржев', 'рига', 'ковна', 'чернигов', 'кексгольм']\n",
            "[('К', 'O'), ('Кронштадтскому', 'B_LOC'), ('бульвару', 'I_LOC'), (',', 'O'), ('где', 'O'), ('болельщика', 'O'), ('«', 'O'), ('Спартака', 'B_ORG'), ('»', 'O'), ('Егора', 'B_PER'), ('Свиридова', 'I_PER'), ('убили', 'O'), ('в', 'O'), ('драке', 'O'), ('между', 'O'), ('славянами', 'O'), ('и', 'O'), ('кавказцами', 'O'), (',', 'O'), ('пришли', 'O'), ('возложить', 'O'), ('цветы', 'O'), ('десятки', 'O'), ('людей', 'O'), (',', 'O'), ('особенно', 'O'), ('молодых', 'O'), (',', 'O'), ('–', 'O'), ('преимущественно', 'O'), ('ультраправые', 'O'), ('и', 'O'), ('футбольные', 'O'), ('болельщики', 'O')]\n",
            "бульвару\n",
            "['улица', 'сквер', 'бульва', 'набережная', 'переулок', 'парк', 'площадь', 'аллея', 'проспект', 'шоссе']\n",
            "[('Впрочем', 'O'), (',', 'O'), ('показательно', 'O'), (',', 'O'), ('что', 'O'), ('на', 'O'), ('Манежной', 'B_LOC'), ('площади', 'I_LOC'), ('в', 'O'), ('этот', 'O'), ('день', 'O'), ('дежурило', 'O'), ('множество', 'O'), ('милиционеров', 'O')]\n",
            "площади\n",
            "['сквер', 'улица', 'бульвар', 'переулок', 'парк', 'пресня', 'набережная', 'проспект', 'здание', 'пустырь']\n",
            "[('Сегодня', 'O'), ('на', 'O'), ('Кронштадтском', 'B_LOC'), ('бульваре', 'I_LOC'), ('не', 'O'), ('было', 'O'), ('почти', 'O'), ('никакой', 'O'), ('символики', 'O')]\n",
            "бульваре\n",
            "['улица', 'сквер', 'бульва', 'набережная', 'переулок', 'парк', 'площадь', 'аллея', 'проспект', 'шоссе']\n",
            "[('\"', 'O'), ('Эх', 'O'), (',', 'O'), ('яблочко', 'O'), ('\"', 'O'), ('...', 'O'), ('Кроме', 'O'), ('сторонников', 'O'), ('ДПНИ', 'B_ORG'), (',', 'O'), ('к', 'O'), ('Кронштадтскому', 'B_LOC'), ('бульвару', 'I_LOC'), ('хотели', 'O'), ('прийти', 'O'), ('представители', 'O'), ('партии', 'B_ORG'), ('«', 'I_ORG'), ('Яблоко', 'I_ORG'), ('»', 'I_ORG'), (',', 'O'), ('чтобы', 'O'), ('принять', 'O'), ('участие', 'O'), ('в', 'O'), ('поминовении', 'O'), ('Егора', 'B_PER'), ('Свиридова', 'I_PER')]\n",
            "бульвару\n",
            "['улица', 'сквер', 'бульва', 'набережная', 'переулок', 'парк', 'площадь', 'аллея', 'проспект', 'шоссе']\n",
            "[('Вот', 'O'), ('как', 'O'), ('эту', 'O'), ('панихиду', 'O'), ('прокомментировал', 'O'), ('писатель', 'O'), ('и', 'O'), ('журналист', 'O'), ('Виктор', 'B_PER'), ('Шендерович', 'I_PER'), (',', 'O'), ('который', 'O'), ('26', 'O'), ('декабря', 'O'), ('провел', 'O'), ('антифашистский', 'O'), ('митинг', 'O'), ('против', 'O'), ('тех', 'O'), (',', 'O'), ('кто', 'O'), ('вышел', 'O'), ('на', 'O'), ('Манежную', 'B_LOC'), ('площадь', 'I_LOC'), (':', 'O'), ('«', 'O'), ('К', 'O'), ('сожалению', 'O'), (',', 'O'), ('Русская', 'B_ORG'), ('Православная', 'I_ORG'), ('Церковь', 'I_ORG'), ('–', 'O'), ('как', 'O'), ('институт', 'O'), (',', 'O'), ('а', 'O'), ('не', 'O'), ('как', 'O'), ('вера', 'O'), ('частных', 'O'), ('людей', 'O'), ('–', 'O'), ('уже', 'O'), ('давно', 'O'), ('и', 'O'), ('глубоко', 'O'), ('увязла', 'O'), ('в', 'O'), ('политике', 'O'), (',', 'O'), ('и', 'O'), ('ее', 'O'), ('участие', 'O'), ('в', 'O'), ('таком', 'O'), ('контексте', 'O'), (',', 'O'), ('заодно', 'O'), ('с', 'O'), ('ДПНИ', 'B_ORG'), (',', 'O'), ('–', 'O'), ('это', 'O'), ('для', 'O'), ('меня', 'O'), ('лишнее', 'O'), ('подтверждение', 'O'), ('того', 'O'), (',', 'O'), ('что', 'O'), ('это', 'O'), ('не', 'O'), ('институт', 'O'), ('веры', 'O'), (',', 'O'), ('а', 'O'), ('институт', 'O'), ('политического', 'O'), ('влияния', 'O'), ('»', 'O')]\n",
            "площадь\n",
            "['сквер', 'улица', 'бульвар', 'переулок', 'парк', 'пресня', 'набережная', 'проспект', 'здание', 'пустырь']\n",
            "[('Продолжает', 'O'), ('отбывать', 'O'), ('10-и', 'O'), ('летний', 'O'), ('срок', 'O'), ('заключения', 'O'), ('известный', 'O'), ('журналист', 'O'), ('Ши', 'B_PER'), ('Тао', 'I_PER'), ('(', 'O'), ('Shi', 'B_PER'), ('Tao', 'I_PER'), (')', 'O'), (',', 'O'), ('которые', 'O'), ('опубликовал', 'O'), ('в', 'O'), ('Интернете', 'B_ORG'), ('инструкции', 'O'), ('отдела', 'O'), ('пропаганды', 'O'), ('по', 'O'), ('поводу', 'O'), ('очередной', 'O'), ('годовщины', 'O'), ('событий', 'O'), ('на', 'O'), ('площади', 'B_LOC'), ('Тяньаньмынь', 'I_LOC')]\n",
            "Тяньаньмынь\n",
            "['вацлавская', 'староместский', 'тяньаньмэнь', 'аренго', 'гревский', 'ратушный', 'бролетто', 'карронада', 'манежный', 'тевелев']\n",
            "[('Соединенные', 'B_LOC'), ('Штаты', 'I_LOC'), (',', 'O'), ('Азербайджан', 'B_LOC'), (',', 'O'), ('и', 'O'), ('Бурунди', 'B_LOC'), ('являются', 'O'), ('седьмыми', 'O'), ('в', 'O'), ('списке', 'O'), ('наций', 'O'), ('—', 'O'), ('по', 'O'), ('три', 'O'), ('заключённых', 'O'), ('журналистов', 'O')]\n",
            "Штаты\n",
            "['королевство', 'калифорния', 'шатат', 'главуголь', 'америка', 'довольствие', 'австралия', 'хафизулла', 'канада', 'айова']\n",
            "[('В', 'O'), ('19', 'O'), ('часов', 'O'), ('по', 'O'), ('Московскому', 'O'), ('времени', 'O'), ('в', 'O'), ('Болгарии', 'B_LOC'), ('был', 'O'), ('открыт', 'O'), ('торжественно', 'O'), ('год', 'O'), ('Российской', 'B_LOC'), ('Федерации', 'I_LOC'), ('в', 'O'), ('Болгарии', 'B_LOC')]\n",
            "Федерации\n",
            "['автоперевозчик', 'цивилистика', 'империя', 'соединенный', 'корееведение', 'телерынок', 'лесосырьевой', 'эйфелев', 'лесопродукт', 'sbj_UN']\n",
            "[('«', 'O'), ('Нужно', 'O'), ('обращаться', 'O'), ('к', 'O'), ('народу', 'O'), ('Северной', 'B_LOC'), ('Кореи', 'I_LOC'), (',', 'O'), ('рассказывать', 'O'), ('о', 'O'), ('нарушениях', 'O'), ('прав', 'O'), ('человека', 'O'), (',', 'O'), ('которые', 'O'), ('происходят', 'O'), ('в', 'O'), ('стране', 'O'), ('»', 'O'), (',', 'O'), ('—', 'O'), ('цитирует', 'O'), ('Хвана', 'B_PER'), ('Чжан', 'I_PER'), ('Епа', 'I_PER'), ('Lenta.ru', 'B_ORG')]\n",
            "Кореи\n",
            "['вьетнам', 'китай', 'осетия', 'африка', 'индия', 'дакота', 'кавказ', 'иран', 'япония', 'америка']\n",
            "[('Во', 'O'), ('время', 'O'), ('поездки', 'O'), ('политика', 'O'), (',', 'O'), ('за', 'O'), ('которым', 'O'), ('охотятся', 'O'), ('спецслужбы', 'O'), ('Северной', 'B_LOC'), ('Кореи', 'I_LOC'), (',', 'O'), ('охраняли', 'O'), ('десятки', 'O'), ('американских', 'O'), ('полицейских', 'O')]\n",
            "Кореи\n",
            "['вьетнам', 'китай', 'осетия', 'африка', 'индия', 'дакота', 'кавказ', 'иран', 'япония', 'америка']\n",
            "[('Около', 'O'), ('30', 'O'), ('рабочих', 'O'), ('на', 'O'), ('заводе', 'B_ORG'), ('по', 'I_ORG'), ('производству', 'I_ORG'), ('ветрогенераторов', 'I_ORG'), ('Vestas', 'I_ORG'), (',', 'O'), ('расположенном', 'O'), ('в', 'O'), ('Ньюпорте', 'B_LOC'), (',', 'O'), ('столицы', 'O'), ('Острова', 'B_LOC'), ('Уайт', 'I_LOC'), (',', 'O'), ('Англия', 'B_LOC'), ('захватили', 'O'), ('свой', 'O'), ('завод', 'O'), ('в', 'O'), ('знак', 'O'), ('протеста', 'O'), ('против', 'O'), ('его', 'O'), ('планируемого', 'O'), ('закрытия', 'O')]\n",
            "Уайт\n",
            "['кларк', 'роджерс', 'эллиот', 'бейли', 'линдсей', 'атлантик', 'джонсон', 'херб', 'ричардсон', 'мур']\n",
            "[('Vestas', 'B_ORG'), ('—', 'O'), ('основной', 'O'), ('работодатель', 'O'), ('на', 'O'), ('Острове', 'B_LOC'), ('Уайт', 'I_LOC'), ('с', 'O'), ('населением', 'O'), ('около', 'O'), ('140', 'O'), ('000', 'O'), ('человек', 'O')]\n",
            "Уайт\n",
            "['кларк', 'роджерс', 'эллиот', 'бейли', 'линдсей', 'атлантик', 'джонсон', 'херб', 'ричардсон', 'мур']\n",
            "[('Завод', 'O'), ('закрыт', 'O'), ('несмотря', 'O'), ('на', 'O'), ('растущие', 'O'), ('прибыли', 'O'), ('компании', 'O'), (',', 'O'), ('фокусируясь', 'O'), ('на', 'O'), ('продажу', 'O'), ('в', 'O'), ('Китай', 'B_LOC'), ('в', 'O'), ('связи', 'O'), ('с', 'O'), ('падением', 'O'), ('спроса', 'O'), ('в', 'O'), ('Северной', 'B_LOC'), ('Европе', 'I_LOC')]\n",
            "Европе\n",
            "['германия', 'африка', 'страна', 'америка', 'европейский', 'япония', 'россия', 'китай', 'средиземноморье', 'англия']\n",
            "[('Как', 'O'), ('известно', 'O'), (',', 'O'), ('Иса', 'B_PER'), ('Ямадаев', 'I_PER'), ('является', 'O'), ('братом', 'O'), ('Сулимы', 'B_PER'), ('Ямадаева', 'I_PER'), (',', 'O'), ('Героя', 'O'), ('Российской', 'B_LOC'), ('Федерации', 'I_LOC'), (',', 'O'), ('на', 'O'), ('которого', 'O'), ('в', 'O'), ('ОАЭ', 'B_LOC'), ('была', 'O'), ('совершена', 'O'), ('попытка', 'O'), ('покушения', 'O'), ('28', 'O'), ('марта', 'O')]\n",
            "Федерации\n",
            "['автоперевозчик', 'цивилистика', 'империя', 'соединенный', 'корееведение', 'телерынок', 'лесосырьевой', 'эйфелев', 'лесопродукт', 'sbj_UN']\n",
            "[('Например', 'O'), (',', 'O'), ('за', 'O'), ('первое', 'O'), ('полугодие', 'O'), ('2009', 'O'), ('года', 'O'), ('цены', 'O'), ('на', 'O'), ('лекарства', 'O'), ('выросли', 'O'), ('в', 'O'), ('среднем', 'O'), ('по', 'O'), ('Российской', 'B_LOC'), ('федерации', 'I_LOC'), ('на', 'O'), ('18,3', 'O'), ('%', 'O'), (',', 'O'), ('что', 'O'), ('значительно', 'O'), ('превышает', 'O'), ('темпы', 'O'), ('роста', 'O'), ('цен', 'O'), ('на', 'O'), ('другие', 'O'), ('товары', 'O'), ('и', 'O'), ('услуги', 'O')]\n",
            "федерации\n",
            "['автоперевозчик', 'цивилистика', 'империя', 'соединенный', 'корееведение', 'телерынок', 'лесосырьевой', 'эйфелев', 'лесопродукт', 'sbj_UN']\n",
            "[('Петербургские', 'O'), ('экологи', 'O'), ('обнаружили', 'O'), ('жёлтые', 'O'), ('пятна', 'O'), ('и', 'O'), ('большое', 'O'), ('количество', 'O'), ('дохлой', 'O'), ('рыбы', 'O'), ('в', 'O'), ('реке', 'B_LOC'), ('Славянка', 'I_LOC')]\n",
            "Славянка\n",
            "['перуанка', 'климчак', 'yandex_UN', 'некрутье', 'айер', 'рок-ансамбль', 'крестовый', 'ижма', 'vniief_UN', 'крестовка']\n",
            "[('Они', 'O'), ('требуют', 'O'), ('привлечь', 'O'), ('к', 'O'), ('уголовной', 'O'), ('ответственности', 'O'), ('лиц', 'O'), (',', 'O'), ('виновных', 'O'), ('в', 'O'), ('загрязнении', 'O'), ('реки', 'B_LOC'), ('Славянки', 'I_LOC')]\n",
            "Славянки\n",
            "['перуанка', 'климчак', 'yandex_UN', 'некрутье', 'айер', 'рок-ансамбль', 'крестовый', 'ижма', 'vniief_UN', 'крестовка']\n",
            "[('Эта', 'O'), ('группа', 'O'), ('и', 'O'), ('Южная', 'B_ORG'), ('водозаборная', 'I_ORG'), ('станция', 'I_ORG'), ('ГУП', 'I_ORG'), ('«', 'I_ORG'), ('Водоканал', 'I_ORG'), ('»', 'I_ORG'), ('утверждают', 'O'), (',', 'O'), ('что', 'O'), ('5', 'O'), ('июня', 'O'), ('ни', 'O'), ('токсичных', 'O'), ('веществ', 'O'), (',', 'O'), ('ни', 'O'), ('мёртвой', 'O'), ('рыбы', 'O'), ('в', 'O'), ('устье', 'O'), ('Невы', 'B_LOC'), ('(', 'O'), ('которое', 'O'), ('находится', 'O'), ('в', 'O'), ('4', 'O'), ('-', 'O'), ('5', 'O'), ('км', 'O'), ('от', 'O'), ('коллектора', 'O'), (')', 'O'), ('они', 'O'), ('не', 'O'), ('нашли', 'O'), (':', 'O'), ('«', 'O'), ('В', 'O'), ('устье', 'O'), ('реки', 'B_LOC'), ('Славянки', 'I_LOC'), ('был', 'O'), ('проведен', 'O'), ('рейд', 'O'), ('по', 'O'), ('поиску', 'O'), ('масляных', 'O'), ('пятен', 'O'), ('на', 'O'), ('воде', 'O')]\n",
            "Славянки\n",
            "['перуанка', 'климчак', 'yandex_UN', 'некрутье', 'айер', 'рок-ансамбль', 'крестовый', 'ижма', 'vniief_UN', 'крестовка']\n",
            "[('Ниже', 'O'), ('устья', 'O'), ('реки', 'B_LOC'), ('Славянки', 'I_LOC'), ('находится', 'O'), ('южная', 'B_ORG'), ('водозаборная', 'I_ORG'), ('станция', 'I_ORG'), ('„', 'I_ORG'), ('Водоканала', 'I_ORG'), ('“', 'O'), (',', 'O'), ('на', 'O'), ('которой', 'O'), ('производятся', 'O'), ('пробы', 'O'), ('воды', 'O'), ('не', 'O'), ('менее', 'O'), ('четырех', 'O'), ('раз', 'O'), ('в', 'O'), ('сутки', 'O')]\n",
            "Славянки\n",
            "['перуанка', 'климчак', 'yandex_UN', 'некрутье', 'айер', 'рок-ансамбль', 'крестовый', 'ижма', 'vniief_UN', 'крестовка']\n",
            "[('В', 'O'), ('ночь', 'O'), ('с', 'O'), ('20', 'O'), ('на', 'O'), ('21', 'O'), ('июля', 'O'), ('в', 'O'), ('приток', 'O'), ('Невы', 'B_LOC'), ('реку', 'B_LOC'), ('Славянку', 'I_LOC'), ('опять', 'O'), ('были', 'O'), ('слиты', 'O'), ('отходы', 'O'), ('лакокрасочного', 'O'), ('производства', 'O')]\n",
            "Славянку\n",
            "['перуанка', 'климчак', 'yandex_UN', 'некрутье', 'айер', 'рок-ансамбль', 'крестовый', 'ижма', 'vniief_UN', 'крестовка']\n",
            "[('Об', 'O'), ('этом', 'O'), ('активистам', 'O'), ('Гринпис', 'B_ORG'), ('сообщили', 'O'), ('жители', 'O'), ('поселка', 'B_LOC'), ('Петро-Славянка', 'I_LOC')]\n",
            "Петро-Славянка\n",
            "[('Остаётся', 'O'), ('неизвестным', 'O'), ('даже', 'O'), ('Росприроднадзору', 'B_ORG'), (',', 'O'), ('какому', 'O'), ('предприятию', 'O'), ('принадлежит', 'O'), ('коллектор', 'O'), (',', 'O'), ('через', 'O'), ('который', 'O'), ('были', 'O'), ('осуществлены', 'O'), ('сбросы', 'O'), ('ядовитых', 'O'), ('веществ', 'O'), ('в', 'O'), ('реку', 'B_LOC'), ('Славянку', 'I_LOC')]\n",
            "Славянку\n",
            "['перуанка', 'климчак', 'yandex_UN', 'некрутье', 'айер', 'рок-ансамбль', 'крестовый', 'ижма', 'vniief_UN', 'крестовка']\n",
            "[('Все', 'O'), ('сбросы', 'O'), ('осуществлялись', 'O'), ('через', 'O'), ('один', 'O'), ('и', 'O'), ('тот', 'O'), ('же', 'O'), ('коллектор', 'O'), (',', 'O'), ('предположительно', 'O'), ('идущий', 'O'), ('из', 'O'), ('промзоны', 'B_LOC'), ('«', 'I_LOC'), ('Рыбацкое', 'I_LOC'), ('»', 'I_LOC')]\n",
            "«\n",
            "Рыбацкое\n",
            "['рыбачий', 'рыболовный', 'рыболовецкий', 'рыбак', 'парусный', 'орочский', 'весельный', 'карбас', 'авалинский', 'плоскодонный']\n",
            "»\n",
            "[('1', 'O'), ('февраля', 'O'), ('на', 'O'), ('ступеньках', 'O'), ('будущего', 'O'), ('президентского', 'B_ORG'), ('центра', 'I_ORG'), ('наследия', 'I_ORG'), ('возле', 'O'), ('бизнес-центра', 'B_LOC'), ('«', 'I_LOC'), ('Демидов', 'I_LOC'), ('»', 'I_LOC'), ('открылся', 'O'), ('памятник', 'B_LOC'), ('первому', 'I_LOC'), ('президенту', 'I_LOC'), ('России', 'I_LOC'), ('Борису', 'I_LOC'), ('Николаевичу', 'I_LOC'), ('Ельцину', 'I_LOC')]\n",
            "«\n",
            "Демидов\n",
            "['силантий', 'михайла', 'ляксандра', 'василий', 'артамон', 'степан', 'денис', 'законница', 'митрофан', 'матвей']\n",
            "»\n",
            "первому\n",
            "президенту\n",
            "России\n",
            "Борису\n",
            "Николаевичу\n",
            "Ельцину\n",
            "[('Уральцы', 'O'), ('никогда', 'O'), ('не', 'O'), ('забудут', 'O'), ('того', 'O'), (',', 'O'), ('что', 'O'), ('сделал', 'O'), ('Борис', 'B_PER'), ('Николаевич', 'I_PER'), ('для', 'O'), ('Свердловской', 'B_LOC'), ('области', 'I_LOC'), (',', 'O'), ('ещё', 'O'), ('будучи', 'O'), ('первым', 'O'), ('секретарём', 'O'), ('обкома', 'B_ORG'), ('партии', 'I_ORG')]\n",
            "области\n",
            "['обл', 'губерния', 'сфера', 'епархия', 'ялуторовский', 'облкомстат', 'район', 'уезд', 'округ', 'отрасль']\n",
            "[('В', 'O'), ('церемонии', 'O'), ('также', 'O'), ('приняли', 'O'), ('участие', 'O'), ('вдова', 'O'), ('Ельцина', 'B_PER'), ('Наина', 'B_PER'), ('Иосифовна', 'I_PER'), (',', 'O'), ('его', 'O'), ('друзья', 'O'), (',', 'O'), ('представители', 'O'), ('федеральной', 'O'), ('власти', 'O'), (',', 'O'), ('глава', 'O'), ('Свердловской', 'B_LOC'), ('области', 'I_LOC'), ('Александр', 'B_PER'), ('Мишарин', 'I_PER'), (',', 'O'), ('руководители', 'O'), ('соседних', 'O'), ('регионов', 'O')]\n",
            "области\n",
            "['обл', 'губерния', 'сфера', 'епархия', 'ялуторовский', 'облкомстат', 'район', 'уезд', 'округ', 'отрасль']\n",
            "[('И', 'O'), ('заложил', 'O'), ('основу', 'O'), ('этому', 'O'), ('первый', 'O'), ('президент', 'O'), (',', 'O'), ('живший', 'O'), ('тогда', 'O'), ('ещё', 'O'), ('в', 'O'), ('Свердловской', 'B_LOC'), ('области', 'I_LOC')]\n",
            "области\n",
            "['обл', 'губерния', 'сфера', 'епархия', 'ялуторовский', 'облкомстат', 'район', 'уезд', 'округ', 'отрасль']\n",
            "[('В', 'O'), ('мае', 'O'), ('1981', 'O'), ('года', 'O'), (',', 'O'), ('во', 'O'), ('Дворце', 'B_LOC'), ('молодёжи', 'I_LOC'), (',', 'O'), ('он', 'O'), ('провёл', 'O'), ('знаковую', 'O'), ('встречу', 'O'), ('со', 'O'), ('студентами', 'O'), ('и', 'O'), ('преподавателями', 'O'), ('16', 'O'), ('свердловских', 'O'), ('вузов', 'O')]\n",
            "молодёжи\n",
            "[('Поводом', 'O'), ('для', 'O'), ('отзыва', 'O'), ('стал', 'O'), ('тот', 'O'), ('факт', 'O'), (',', 'O'), ('что', 'O'), ('дипмиссия', 'B_ORG'), ('не', 'O'), ('смогла', 'O'), ('вовремя', 'O'), ('предоставить', 'O'), ('правительству', 'B_ORG'), ('Страны', 'I_ORG'), ('восходящего', 'I_ORG'), ('солнца', 'I_ORG'), ('точных', 'O'), ('сведений', 'O'), ('о', 'O'), ('визите', 'O'), ('российского', 'O'), ('президента', 'O'), ('на', 'O'), ('Курильские', 'B_LOC'), ('острова', 'I_LOC')]\n",
            "острова\n",
            "['бухта', 'мыс', 'островок', 'sari_UN', 'материк', 'залив', 'побережье', 'шпицберген', 'лесбос', 'гренландия']\n",
            "[('Однако', 'O'), (',', 'O'), ('как', 'O'), ('известно', 'O'), (',', 'O'), ('глава', 'O'), ('России', 'B_LOC'), ('31', 'O'), ('октября', 'O'), ('всё', 'O'), ('же', 'O'), ('побывал', 'O'), ('с', 'O'), ('рабочей', 'O'), ('поездкой', 'O'), ('на', 'O'), ('южных', 'B_LOC'), ('островах', 'I_LOC'), ('архипелага', 'I_LOC')]\n",
            "островах\n",
            "['бухта', 'мыс', 'островок', 'sari_UN', 'материк', 'залив', 'побережье', 'шпицберген', 'лесбос', 'гренландия']\n",
            "архипелага\n",
            "['остров', 'багамский', 'материк', 'азорский', 'цериго', 'сандвичев', 'тенедос', 'молуккский', 'антильский', 'туамоту']\n",
            "[('Правительство', 'B_ORG'), ('Японии', 'I_ORG'), ('выразило', 'O'), ('решительный', 'O'), ('протест', 'O'), ('против', 'O'), ('состоявшегося', 'O'), ('в', 'O'), ('пятницу', 'O'), ('визита', 'O'), ('российского', 'O'), ('министра', 'O'), ('обороны', 'O'), (',', 'O'), ('посетившего', 'O'), ('южные', 'B_LOC'), ('Курильские', 'I_LOC'), ('острова', 'I_LOC'), (',', 'O'), ('которые', 'O'), ('и', 'O'), ('Япония', 'B_LOC'), (',', 'O'), ('и', 'O'), ('Россия', 'B_LOC'), ('считают', 'O'), ('своими', 'O')]\n",
            "Курильские\n",
            "['азорский', 'командорский', 'багамский', 'канарский', 'итуруп', 'оркнейский', 'алеутский', 'сандвичев', 'антильский', 'аландский']\n",
            "острова\n",
            "['бухта', 'мыс', 'островок', 'sari_UN', 'материк', 'залив', 'побережье', 'шпицберген', 'лесбос', 'гренландия']\n",
            "[('Четыре', 'O'), ('острова', 'O'), (',', 'O'), ('которые', 'O'), ('называются', 'O'), ('Южными', 'B_LOC'), ('Курилами', 'I_LOC'), (',', 'O'), ('и', 'O'), ('которые', 'O'), ('японцы', 'O'), ('называют', 'O'), ('Северными', 'B_LOC'), ('территориями', 'I_LOC'), (',', 'O'), ('отошли', 'O'), ('к', 'O'), ('Советскому', 'B_LOC'), ('Союзу', 'I_LOC'), ('после', 'O'), ('Второй', 'O'), ('мировой', 'O'), ('войны', 'O')]\n",
            "Курилами\n",
            "['африка', 'сахалин', 'корея', 'побережье', 'камчатка', 'причерноморье', 'оконечность', 'дакота', 'америка', 'родезия']\n",
            "территориями\n",
            "['район', 'столица', 'зона', 'регион', 'анклав', 'украина', 'граница', 'республика', 'оккупировать', 'участок']\n",
            "Союзу\n",
            "['делегация', 'спелеодвижение', 'профсоюз', 'кинематография', 'ссп_UN', 'ascap_UN', 'республика', 'объединение', 'организация', 'власть']\n",
            "[('В', 'O'), ('19.58', 'O'), ('мск', 'O'), ('он', 'O'), ('приземлился', 'O'), ('на', 'O'), ('космодроме', 'O'), ('на', 'O'), ('мысе', 'B_LOC'), ('Канаверал', 'I_LOC'), ('во', 'O'), ('Флориде', 'B_LOC')]\n",
            "Канаверал\n",
            "['блосс', 'стерлегов', 'фиолента', 'кадош', 'сосунов', 'гонио', 'баннерс', 'суфрен', 'пахиос', 'ахелоев']\n",
            "[('В', 'O'), ('субботу', 'O'), ('в', 'O'), ('Центральном', 'B_LOC'), ('доме', 'I_LOC'), ('литераторов', 'I_LOC'), ('состоится', 'O'), ('прощание', 'O'), ('с', 'O'), ('актрисой', 'O')]\n",
            "доме\n",
            "['особняк', 'квартира', 'флигель', 'домик', 'коттедж', 'усадьба', 'дача', 'особнячок', 'хата', 'изба']\n",
            "литераторов\n",
            "['писатель', 'беллетрист', 'журналист', 'ученый', 'литературовед', 'поэт', 'критик', 'публицист', 'художник', 'искусствовед']\n",
            "[('Похороны', 'O'), ('Людмилы', 'B_PER'), ('Марковны', 'I_PER'), ('состоятся', 'O'), ('2', 'O'), ('апреля', 'O'), ('на', 'O'), ('Новодевичьем', 'B_LOC'), ('кладбище', 'I_LOC')]\n",
            "кладбище\n",
            "['могила', 'погост', 'часовня', 'костел', 'монастырь', 'склеп', 'могилка', 'новодевичий', 'синагога', 'церковь']\n",
            "[('Во', 'O'), ('время', 'O'), ('недавнего', 'O'), ('посещения', 'O'), (',', 'O'), ('предназначенного', 'O'), ('для', 'O'), ('Конституционного', 'B_ORG'), ('суда', 'I_ORG'), ('комплекса', 'B_LOC'), ('зданий', 'I_LOC'), ('Сената', 'I_LOC'), ('и', 'I_LOC'), ('Синода', 'I_LOC'), (',', 'O'), ('Зорькин', 'B_PER'), ('сказал', 'O'), (',', 'O'), ('что', 'O'), ('переезд', 'O'), ('повлечёт', 'O'), ('за', 'O'), ('собой', 'O'), ('перерыв', 'O'), ('в', 'O'), ('работе', 'O'), ('суда', 'O'), ('и', 'O'), ('спровоцирует', 'O'), ('персональные', 'O'), ('проблемы', 'O')]\n",
            "зданий\n",
            "['особняк', 'дом', 'особнячок', 'помещение', 'постройка', 'многоэтажка', 'коттедж', 'пристройка', 'башня', 'двухэтажный']\n",
            "Сената\n",
            "['синод', 'сенатор', 'парламент', 'мосгорсуд', 'правительство', 'синодский', 'сейм', 'апостолический', 'постанавливать', 'риксдаг']\n",
            "и\n",
            "Синода\n",
            "[('5', 'O'), ('апреля', 'O'), ('2011', 'O'), ('года', 'O'), ('столице', 'O'), ('Чеченской', 'B_LOC'), ('республики', 'I_LOC'), ('городе', 'B_LOC'), ('Грозном', 'I_LOC'), ('прошла', 'O'), ('церемония', 'O'), ('инаугурации', 'O'), ('экс-боевика', 'O'), ('сепаратистов', 'O'), (',', 'O'), ('а', 'O'), ('ныне', 'O'), ('генерал-майора', 'O'), ('МВД', 'B_ORG'), ('Рамзана', 'B_PER'), ('Кадырова', 'I_PER')]\n",
            "республики\n",
            "['государство', 'азербайджан', 'украина', 'башкирия', 'грузия', 'территория', 'армения', 'казахстан', 'ичкерия', 'татарстан']\n",
            "Грозном\n",
            "['калита', 'грозный', 'топорышкин', 'лапиков', 'хайтанин', 'сусанин', 'савватеевич', 'матеров', 'логгинович', 'панькин']\n",
            "[('Ещё', 'O'), ('28', 'O'), ('февраля', 'O'), ('президент', 'O'), ('Российской', 'B_LOC'), ('Федерации', 'I_LOC'), ('Дмитрий', 'B_PER'), ('Анатольевич', 'I_PER'), ('Медведев', 'I_PER'), ('предложил', 'O'), ('парламенту', 'B_ORG'), ('Чечни', 'I_ORG'), ('рассмотреть', 'O'), ('кандидатуру', 'O'), ('действующего', 'O'), ('ставленника', 'O'), ('Кремля', 'B_ORG'), (',', 'O'), ('с', 'O'), ('целью', 'O'), ('избрания', 'O'), ('его', 'O'), ('на', 'O'), ('второй', 'O'), ('срок', 'O')]\n",
            "Федерации\n",
            "['автоперевозчик', 'цивилистика', 'империя', 'соединенный', 'корееведение', 'телерынок', 'лесосырьевой', 'эйфелев', 'лесопродукт', 'sbj_UN']\n",
            "[('Полпред', 'O'), ('президента', 'O'), ('РФ', 'B_LOC'), ('в', 'O'), ('Северо-Кавказском', 'B_LOC'), ('федеральном', 'I_LOC'), ('округе', 'I_LOC'), ('Александр', 'B_PER'), ('Хлопонин', 'I_PER'), (',', 'O'), ('представители', 'O'), ('Госдумы', 'B_ORG'), ('России', 'I_ORG'), (',', 'O'), ('председатель', 'O'), ('Совета', 'B_ORG'), ('муфтиев', 'I_ORG'), ('России', 'I_ORG'), ('шейх', 'O'), ('Равиль', 'B_PER'), ('Гайнутдин', 'I_PER'), (',', 'O'), ('другие', 'O'), ('известные', 'O'), ('религиозные', 'O'), ('деятели', 'O'), ('и', 'O'), ('политики', 'O'), ('общим', 'O'), ('количеством', 'O'), ('около', 'O'), ('восьмисот', 'O'), ('человек', 'O'), ('приняли', 'O'), ('участие', 'O'), ('в', 'O'), ('этом', 'O'), ('знаменательном', 'O'), ('событии', 'O')]\n",
            "федеральном\n",
            "['региональный', 'республиканский', 'областной', 'муниципальный', 'краевой', 'субнациональный', 'законодательный', 'общегосударственный', 'бездефицитный', 'госэнергонадзор']\n",
            "округе\n",
            "['округ_', 'район', 'приволжский', 'генерал-губернатор', 'губерния', 'госуниверситет', 'область', 'окружной', 'уезд', 'окружный']\n",
            "[('Кан', 'B_PER'), ('сделал', 'O'), ('это', 'O'), ('заявление', 'O'), ('в', 'O'), ('понедельник', 'O'), ('7', 'O'), ('февраля', 'O'), ('на', 'O'), ('митинге', 'O'), (',', 'O'), ('собравшем', 'O'), ('более', 'O'), ('1000', 'O'), ('человек', 'O'), (',', 'O'), ('которые', 'O'), ('требовали', 'O'), ('возвращения', 'O'), ('четырех', 'O'), ('островов', 'O'), (',', 'O'), ('называемых', 'O'), ('в', 'O'), ('Японии', 'B_LOC'), ('«', 'O'), ('северными', 'O'), ('территориями', 'O'), ('»', 'O'), (',', 'O'), ('а', 'O'), ('в', 'O'), ('России', 'B_LOC'), ('–', 'O'), ('Южными', 'B_LOC'), ('Курилами', 'I_LOC')]\n",
            "Курилами\n",
            "['африка', 'сахалин', 'корея', 'побережье', 'камчатка', 'причерноморье', 'оконечность', 'дакота', 'америка', 'родезия']\n",
            "[('Из-за', 'O'), ('спора', 'O'), ('по', 'O'), ('островам', 'O'), (',', 'O'), ('захваченным', 'O'), ('Советским', 'B_LOC'), ('Союзом', 'I_LOC'), ('в', 'O'), ('конце', 'O'), ('второй', 'O'), ('мировой', 'O'), ('войны', 'O'), (',', 'O'), ('две', 'O'), ('страны', 'O'), ('в', 'O'), ('течение', 'O'), ('65', 'O'), ('лет', 'O'), ('остаются', 'O'), ('без', 'O'), ('официального', 'O'), ('мирного', 'O'), ('договора', 'O')]\n",
            "Союзом\n",
            "['делегация', 'спелеодвижение', 'профсоюз', 'кинематография', 'ссп_UN', 'ascap_UN', 'республика', 'объединение', 'организация', 'власть']\n",
            "[('«', 'O'), ('Сегодня', 'O'), ('утром', 'O'), ('у', 'O'), ('входа', 'O'), ('в', 'O'), ('здание', 'B_LOC'), ('Законодательного', 'I_LOC'), ('собрания', 'I_LOC'), ('мы', 'O'), ('провели', 'O'), ('встречу', 'O'), (',', 'O'), ('на', 'O'), ('ней', 'O'), ('присутствовали', 'O'), ('наши', 'O'), ('четыре', 'O'), ('депутата', 'O'), ('и', 'O'), ('их', 'O'), ('помощники', 'O')]\n",
            "Законодательного\n",
            "['правовой', 'учредительный', 'подзаконный', 'юрисдикционный', 'госвласть', 'нормативный', 'коллегиальный', 'международно-правовой', 'представительный', 'всеземский']\n",
            "собрания\n",
            "['совещание', 'митинг', 'съезд', 'конференция', 'заседание', 'сходка', 'партсобрание', 'сборище', 'сзываться', 'прения']\n",
            "[('Напомним', 'O'), (',', 'O'), ('28', 'O'), ('марта', 'O'), ('2010', 'O'), ('года', 'O'), ('Камчатский', 'B_LOC'), ('край', 'I_LOC'), ('и', 'O'), ('Чукотский', 'B_LOC'), ('автономный', 'I_LOC'), ('округ', 'I_LOC'), ('перешли', 'O'), ('на', 'O'), ('магаданское', 'O'), ('время', 'O')]\n",
            "край\n",
            "['краешек', 'кромка', 'пиринский', 'угол', 'пильчатый', 'окраина', 'margo_UN', 'уголок', 'странджанский', 'обрыв']\n",
            "автономный\n",
            "['коми-пермяцкий', 'ямало-ненецкий', 'корякский', 'ханты-мансийский', 'закатальский', 'усть-ордынский', 'усть-ордынский', 'дэйд', 'вотский', 'ненецкий']\n",
            "округ\n",
            "['округ_', 'район', 'приволжский', 'генерал-губернатор', 'губерния', 'госуниверситет', 'область', 'окружной', 'уезд', 'окружный']\n",
            "[('В', 'O'), ('результате', 'O'), ('в', 'O'), ('Дальневосточном', 'B_LOC'), ('федеральном', 'I_LOC'), ('округе', 'I_LOC'), ('осталось', 'O'), ('три', 'O'), ('часовых', 'O'), ('пояса', 'O')]\n",
            "федеральном\n",
            "['региональный', 'республиканский', 'областной', 'муниципальный', 'краевой', 'субнациональный', 'законодательный', 'общегосударственный', 'бездефицитный', 'госэнергонадзор']\n",
            "округе\n",
            "['округ_', 'район', 'приволжский', 'генерал-губернатор', 'губерния', 'госуниверситет', 'область', 'окружной', 'уезд', 'окружный']\n",
            "[('Посол', 'O'), ('Евросоюза', 'B_ORG'), ('на', 'O'), ('Южном', 'B_LOC'), ('Кавказе', 'I_LOC'), ('Питер', 'B_PER'), ('Семнеби', 'I_PER'), ('и', 'O'), ('представители', 'O'), ('ПАСЕ', 'B_ORG'), ('(', 'O'), ('Парламентской', 'B_ORG'), ('ассамблеи', 'I_ORG'), ('Совета', 'I_ORG'), ('Европы', 'I_ORG'), (')', 'O'), ('призывают', 'O'), ('руководство', 'B_ORG'), ('Грузии', 'I_ORG'), ('отменить', 'O'), ('чрезвычайное', 'O'), ('положение', 'O'), (',', 'O'), ('при', 'O'), ('котором', 'O'), ('запрещены', 'O'), ('митинги', 'O'), (',', 'O'), ('демонстрации', 'O'), ('и', 'O'), ('вещание', 'O'), ('независимых', 'O'), ('теле-', 'O'), ('и', 'O'), ('радиостанций', 'O'), (',', 'O'), ('как', 'O'), ('можно', 'O'), ('скорее', 'O')]\n",
            "Кавказе\n",
            "['пальмира', 'таврия', 'причерноморье', 'кыштовский', 'осетия', 'африка', 'прикаспий', 'буковина', 'сибирь', 'крым']\n",
            "[('Самолет', 'O'), ('с', 'O'), ('Виталием', 'B_PER'), ('Калоевым', 'I_PER'), ('на', 'O'), ('борту', 'O'), ('приземлился', 'O'), ('в', 'O'), ('столичном', 'B_LOC'), ('аэропорту', 'I_LOC'), ('«', 'I_LOC'), ('Домодедово', 'I_LOC'), ('»', 'I_LOC')]\n",
            "аэропорту\n",
            "['вокзал', 'шереметьево', 'аэродром', 'внуково', 'метро', 'электричка', 'домодедово', 'аэровокзал', 'автобус', 'такси']\n",
            "«\n",
            "Домодедово\n",
            "['шереметьево', 'внуково', 'хитроу', 'курумочи', 'толмачево', 'ферихедь', 'пулково', 'жуляны', 'донмыонг', 'борисполь']\n",
            "»\n",
            "[('Калоев', 'B_PER'), (',', 'O'), ('потерявший', 'O'), ('в', 'O'), ('авиакатастрофе', 'O'), ('над', 'O'), ('Боденским', 'B_LOC'), ('озером', 'I_LOC'), ('в', 'O'), ('2002', 'O'), ('году', 'O'), ('свою', 'O'), ('семью', 'O'), (',', 'O'), ('заявил', 'O'), (',', 'O'), ('что', 'O'), ('благодарен', 'O'), ('всем', 'O'), ('гражданам', 'O'), ('России', 'B_LOC'), ('за', 'O'), ('поддержку', 'O'), (',', 'O'), ('которую', 'O'), ('они', 'O'), ('ему', 'O'), ('оказали', 'O')]\n",
            "озером\n",
            "['река', 'речка', 'озерко', 'пруд', 'речушка', 'озерцо', 'долина', 'ручей', 'устье', 'водоем']\n",
            "[('Работать', 'O'), ('будущий', 'O'), ('сотрудник', 'O'), ('будет', 'O'), ('в', 'O'), ('штаб-квартире', 'B_LOC'), ('Google', 'I_LOC'), (',', 'O'), ('расположенной', 'O'), ('в', 'O'), ('городе', 'B_LOC'), ('Маунтин-Вью', 'I_LOC'), (',', 'I_LOC'), ('штат', 'I_LOC'), ('Калифорния', 'I_LOC')]\n",
            "Google\n",
            "Маунтин-Вью\n",
            ",\n",
            "штат\n",
            "Калифорния\n",
            "[('По', 'O'), ('пути', 'O'), ('Керри', 'B_PER'), ('сделал', 'O'), ('остановку', 'O'), ('в', 'O'), ('Кабуле', 'B_LOC'), (',', 'O'), ('где', 'O'), ('в', 'O'), ('беседе', 'O'), ('с', 'O'), ('корреспондентами', 'O'), ('в', 'O'), ('афганской', 'B_LOC'), ('столице', 'I_LOC'), ('отметил', 'O'), (',', 'O'), ('что', 'O'), ('отношения', 'O'), ('Америки', 'B_LOC'), ('с', 'O'), ('Пакистаном', 'B_LOC'), ('переживают', 'O'), ('«', 'O'), ('критический', 'O'), ('момент', 'O'), ('»', 'O'), (',', 'O'), ('и', 'O'), ('что', 'O'), ('обеим', 'O'), ('странам', 'O'), ('предстоит', 'O'), ('решить', 'O'), ('«', 'O'), ('ряд', 'O'), ('очень', 'O'), ('серьезных', 'O'), ('проблем', 'O'), ('»', 'O')]\n",
            "столице\n",
            "['город', 'провинция', 'петербург', 'окраина', 'москва', 'территория', 'городок', 'кавказ', 'пригород', 'империя']\n",
            "[('В', 'O'), ('ходе', 'O'), ('процесса', 'O'), ('Санников', 'B_PER'), ('выступил', 'O'), ('с', 'O'), ('заявлением', 'O'), (':', 'O'), ('он', 'O'), ('сообщил', 'O'), (',', 'O'), ('что', 'O'), ('в', 'O'), ('изоляторе', 'B_LOC'), ('КГБ', 'I_LOC'), ('его', 'O'), ('пытали', 'O'), ('и', 'O'), ('унижали', 'O'), ('его', 'O'), ('человеческое', 'O'), ('достоинство', 'O')]\n",
            "КГБ\n",
            "['нквд', 'фсб', 'мгб', 'гестапо', 'мвд', 'гпу', 'милиция', 'контрразведка', 'цру', 'спецслужба']\n",
            "[('Марк', 'B_PER'), ('Тоунер', 'I_PER'), (',', 'O'), ('исполняющий', 'O'), ('обязанности', 'O'), ('официального', 'O'), ('представителя', 'O'), ('Госдепартамента', 'B_ORG'), ('США', 'I_ORG'), (',', 'O'), ('выступил', 'O'), ('сегодня', 'O'), ('со', 'O'), ('специальным', 'O'), ('заявлением', 'O'), (':', 'O'), ('«', 'O'), ('Соединенные', 'B_LOC'), ('Штаты', 'I_LOC'), ('осуждают', 'O'), ('приговор', 'O'), (',', 'O'), ('вынесенный', 'O'), ('14', 'O'), ('мая', 'O'), ('кандидату', 'O'), ('в', 'O'), ('президенты', 'O'), ('Андрею', 'B_PER'), ('Санникову', 'I_PER'), ('и', 'O'), ('другим', 'O'), ('демократическим', 'O'), ('активистам', 'O'), ('в', 'O'), ('Беларуси', 'B_LOC')]\n",
            "Штаты\n",
            "['королевство', 'калифорния', 'шатат', 'главуголь', 'америка', 'довольствие', 'австралия', 'хафизулла', 'канада', 'айова']\n",
            "[('Результаты', 'O'), ('идущих', 'O'), ('в', 'O'), ('Беларуси', 'B_LOC'), ('судебных', 'O'), ('слушаний', 'O'), ('будут', 'O'), ('приняты', 'O'), ('во', 'O'), ('внимание', 'O'), ('Соединёнными', 'B_LOC'), ('штатами', 'I_LOC'), (',', 'O'), ('которые', 'O'), ('продолжают', 'O'), ('рассмотрение', 'O'), ('своих', 'O'), ('отношений', 'O'), ('с', 'O'), ('Беларусью', 'B_LOC'), (',', 'O'), ('а', 'O'), ('также', 'O'), ('дальнейших', 'O'), ('мер', 'O'), ('»', 'O')]\n",
            "штатами\n",
            "['королевство', 'калифорния', 'шатат', 'главуголь', 'америка', 'довольствие', 'австралия', 'хафизулла', 'канада', 'айова']\n",
            "[('Палестинцы', 'O'), ('связывают', 'O'), ('надежды', 'O'), ('с', 'O'), ('признанием', 'O'), ('ООН', 'B_ORG'), ('их', 'O'), ('государственности', 'O'), ('Воскресное', 'O'), ('заседание', 'O'), ('кабинета', 'B_ORG'), ('министров', 'I_ORG'), ('глава', 'O'), ('правительства', 'B_ORG'), ('Израиля', 'I_ORG'), ('Биньямин', 'B_PER'), ('Нетаньяху', 'I_PER'), ('провел', 'O'), ('в', 'O'), ('Старом', 'B_LOC'), ('городе', 'I_LOC'), (',', 'O'), ('а', 'O'), ('не', 'O'), ('в', 'O'), ('традиционном', 'O'), ('месте', 'O'), ('в', 'O'), ('Западном', 'B_LOC'), ('Иерусалиме', 'I_LOC')]\n",
            "городе\n",
            "['столица', 'деревня', 'поселок', 'городок', 'селение', 'городишко', 'пригород', 'село', 'окрестность', 'москва']\n",
            "Иерусалиме\n",
            "['галилея', 'вифлеем', 'афон', 'сион', 'капернаум', 'рим', 'коринф', 'храм', 'вифаний', 'вавилон']\n",
            "[('Однако', 'O'), ('арабы', 'O'), ('столь', 'O'), ('же', 'O'), ('твердо', 'O'), ('заявляют', 'O'), (',', 'O'), ('что', 'O'), ('мир', 'O'), ('в', 'O'), ('регионе', 'O'), ('невозможен', 'O'), ('до', 'O'), ('тех', 'O'), ('пор', 'O'), (',', 'O'), ('пока', 'O'), ('Израиль', 'B_LOC'), ('не', 'O'), ('вернет', 'O'), ('Восточный', 'B_LOC'), ('Иерусалим', 'I_LOC'), ('со', 'O'), ('Старым', 'B_LOC'), ('городом', 'I_LOC'), (',', 'O'), ('захваченным', 'O'), ('у', 'O'), ('Иордании', 'B_LOC'), ('во', 'O'), ('время', 'O'), ('Шестидневной', 'O'), ('войны', 'O'), ('1967', 'O'), ('года', 'O')]\n",
            "Иерусалим\n",
            "['галилея', 'вифлеем', 'афон', 'сион', 'капернаум', 'рим', 'коринф', 'храм', 'вифаний', 'вавилон']\n",
            "городом\n",
            "['столица', 'деревня', 'поселок', 'городок', 'селение', 'городишко', 'пригород', 'село', 'окрестность', 'москва']\n",
            "[('Палестинцы', 'O'), ('отказываются', 'O'), ('от', 'O'), ('возобновления', 'O'), ('переговоров', 'O'), (',', 'O'), ('поскольку', 'O'), ('Израиль', 'B_LOC'), ('отказывается', 'O'), ('заморозить', 'O'), ('расширение', 'O'), ('поселений', 'O'), ('и', 'O'), ('признать', 'O'), ('Палестинское', 'B_LOC'), ('государство', 'I_LOC'), ('на', 'O'), ('основе', 'O'), ('границ', 'O'), ('1967', 'O'), ('года', 'O')]\n",
            "государство\n",
            "['государственность', 'держава', 'империя', 'страна', 'нация', 'республика', 'россия', 'общество', 'демократия', 'правительство']\n",
            "[('Глава', 'O'), ('палестинской', 'B_ORG'), ('делегации', 'I_ORG'), ('на', 'O'), ('переговорах', 'O'), ('Саеб', 'B_PER'), ('Эрекат', 'I_PER'), ('призвал', 'O'), ('ООН', 'B_ORG'), ('«', 'O'), ('ответить', 'O'), ('на', 'O'), ('односторонние', 'O'), ('действия', 'O'), ('Израиля', 'B_LOC'), ('признанием', 'O'), ('Палестинского', 'B_LOC'), ('государства', 'I_LOC'), ('в', 'O'), ('границах', 'O'), ('67-го', 'O'), ('года', 'O'), ('со', 'O'), ('столицей', 'O'), ('в', 'O'), ('Восточном', 'B_LOC'), ('Иерусалиме', 'I_LOC'), ('»', 'O')]\n",
            "государства\n",
            "['государственность', 'держава', 'империя', 'страна', 'нация', 'республика', 'россия', 'общество', 'демократия', 'правительство']\n",
            "Иерусалиме\n",
            "['галилея', 'вифлеем', 'афон', 'сион', 'капернаум', 'рим', 'коринф', 'храм', 'вифаний', 'вавилон']\n",
            "[('«', 'O'), ('Пройдет', 'O'), ('несколько', 'O'), ('лет', 'O'), (',', 'O'), ('вероятно', 'O'), ('до', 'O'), ('2024', 'O'), ('года', 'O'), (',', 'O'), ('прежде', 'O'), ('чем', 'O'), ('база', 'O'), ('будет', 'O'), ('функционировать', 'O'), (',', 'O'), ('и', 'O'), ('на', 'O'), ('базе', 'O'), ('будут', 'O'), ('постоянно', 'O'), ('сменяемые', 'O'), ('смены', 'O'), (',', 'O'), ('как', 'O'), ('это', 'O'), ('происходит', 'O'), ('сейчас', 'O'), ('на', 'O'), ('международной', 'B_LOC'), ('космической', 'I_LOC'), ('станции', 'I_LOC'), ('»', 'O')]\n",
            "космической\n",
            "['межпланетный', 'космос', 'межзвездный', 'пилотировать', 'околоземный', 'орбитальный', 'гиперзвуковой', 'воздушный', 'междупланетный', 'околосолнечный']\n",
            "станции\n",
            "['полустанок', 'депо', 'вокзал', 'поезд', 'перегон', 'платформа', 'поселок', 'вагон', 'остановка', 'полежаевская']\n",
            "[('На', 'O'), ('лекции', 'O'), (',', 'O'), ('которая', 'O'), ('состоится', 'O'), ('20', 'O'), ('марта', 'O'), (',', 'O'), ('в', 'O'), ('субботу', 'O'), (',', 'O'), ('в', 'O'), ('16:00', 'O'), ('в', 'O'), ('книжном', 'B_LOC'), ('магазине', 'I_LOC'), ('«', 'I_LOC'), ('Библио-Глобус', 'I_LOC'), ('»', 'I_LOC'), ('на', 'O'), ('Лубянке', 'B_LOC'), (',', 'O'), ('Александр', 'B_PER'), ('покажет', 'O'), ('несложные', 'O'), ('физические', 'O'), ('эксперименты', 'O'), (':', 'O'), ('измерение', 'O'), ('времени', 'O'), ('с', 'O'), ('помощью', 'O'), ('верёвки', 'O'), (',', 'O'), ('законы', 'O'), ('отражения', 'O'), ('и', 'O'), ('преломления', 'O'), (',', 'O'), ('закон', 'O'), ('Гука', 'B_PER'), (',', 'O'), ('образование', 'O'), ('кристаллов', 'O'), ('и', 'O'), ('многие', 'O'), ('другие', 'O'), ('«', 'O'), ('фокусы', 'O'), ('»', 'O'), (',', 'O'), ('которые', 'O'), ('будут', 'O'), ('интересны', 'O'), ('и', 'O'), ('детям', 'O'), (',', 'O'), ('и', 'O'), ('взрослым', 'O')]\n",
            "магазине\n",
            "['супермаркет', 'магазинчик', 'гастроном', 'ларек', 'бутик', 'киоск', 'лавка', 'булочная', 'универмаг', 'аптека']\n",
            "«\n",
            "Библио-Глобус\n",
            "['novartis_UN', 'самсунг', 'apple_UN', 'sportland_UN', 'лицензированный', 'гум', 'онлайновый', 'яндекс', 'супермаркет', 'техцентр']\n",
            "»\n",
            "[('Поддержку', 'O'), ('Бесселю', 'B_PER'), ('Коку', 'I_PER'), ('выразили', 'O'), ('30', 'O'), ('шахматных', 'O'), ('федераций', 'O'), ('среди', 'O'), ('них', 'O'), ('почти', 'O'), ('все', 'O'), ('федерации', 'O'), ('стран', 'O'), ('западной', 'B_LOC'), ('Европы', 'I_LOC'), (',', 'O'), ('также', 'O'), ('США', 'B_LOC')]\n",
            "Европы\n",
            "['германия', 'африка', 'страна', 'америка', 'европейский', 'япония', 'россия', 'китай', 'средиземноморье', 'англия']\n",
            "[('На', 'O'), ('Интернет', 'B_ORG'), ('странице', 'O'), ('Бесселя', 'B_PER'), ('Кока', 'I_PER'), ('перечислены', 'O'), ('следующие', 'O'), ('федерации', 'O'), (',', 'O'), ('которые', 'O'), ('его', 'O'), ('поддерживают', 'O'), (':', 'O'), ('•', 'O'), ('Афганистан', 'B_LOC'), ('•', 'O'), ('Андорра', 'B_LOC'), ('•', 'O'), ('Австралия', 'B_LOC'), ('•', 'O'), ('Бельгия', 'B_LOC'), ('•', 'O'), ('Канада', 'B_LOC'), ('•', 'O'), ('Чехия', 'B_LOC'), ('•', 'O'), ('Дания', 'B_LOC'), ('•', 'O'), ('Англия', 'B_LOC'), ('•', 'O'), ('Франция', 'B_LOC'), ('•', 'O'), ('Германия', 'B_LOC'), ('•', 'O'), ('Исландия', 'B_LOC'), ('•', 'O'), ('Ирландия', 'B_LOC'), ('•', 'O'), ('Лихтенштейн', 'B_LOC'), ('•', 'O'), ('Люксембург', 'B_LOC'), ('•', 'O'), ('Малави', 'B_LOC'), ('•', 'O'), ('Мальта', 'B_LOC'), ('•', 'O'), ('Монако', 'B_LOC'), ('•', 'O'), ('Намибия', 'B_LOC'), ('•', 'O'), ('Нидерланды', 'B_LOC'), ('•', 'O'), ('Нидерландские', 'B_LOC'), ('Антилы', 'I_LOC'), ('•', 'O'), ('Норвегия', 'B_LOC'), ('•', 'O'), ('Пакистан', 'B_LOC'), ('•', 'O'), ('Палестина', 'B_LOC'), ('•', 'O'), ('Парагвай', 'B_LOC'), ('•', 'O'), ('Словакия', 'B_LOC'), ('•', 'O'), ('Испания', 'B_LOC'), ('•', 'O'), ('Швейцария', 'B_LOC'), ('•', 'O'), ('Таиланд', 'B_LOC'), ('•', 'O'), ('Турция', 'B_LOC'), ('•', 'O'), ('США', 'B_LOC'), ('Поддержку', 'O'), ('Кирсану', 'B_PER'), ('Илюмжинову', 'I_PER'), ('выразили', 'O'), ('40', 'O'), ('шахматных', 'O'), ('федераций', 'O'), (',', 'O'), ('среди', 'O'), ('них', 'O'), ('почти', 'O'), ('все', 'O'), ('бывшие', 'O'), ('республики', 'O'), ('СССР', 'B_LOC'), (',', 'O'), ('арабские', 'O'), ('страны', 'O'), ('и', 'O'), ('африканские', 'O'), ('страны', 'O')]\n",
            "Антилы\n",
            "[('Командир', 'O'), ('13-й', 'B_ORG'), ('долговременной', 'I_ORG'), ('экспедиции', 'I_ORG'), ('Павел', 'B_PER'), ('Виноградов', 'I_PER'), ('и', 'O'), ('бортинженер', 'O'), ('Джеффри', 'B_PER'), ('Уильямс', 'I_PER'), ('впервые', 'O'), ('участвовали', 'O'), ('в', 'O'), ('пресс-конференции', 'O'), ('с', 'O'), ('борта', 'B_LOC'), ('МКС', 'I_LOC')]\n",
            "МКС\n",
            "['орбитальный', 'шаттлов', 'нобилевский', 'маловысотный', 'двухблочный', 'дпл_UN', 'пилотировать', 'нефтеперекачивающий', 'апл', 'электрифицировать']\n",
            "[('Вопросы', 'O'), ('задавались', 'O'), ('из', 'O'), ('Космического', 'B_LOC'), ('центра', 'I_LOC'), ('Джонсона', 'I_LOC'), ('в', 'O'), ('Хьюстоне', 'B_LOC'), (',', 'O'), ('Космического', 'B_LOC'), ('центра', 'I_LOC'), ('Кеннеди', 'I_LOC'), ('во', 'O'), ('Флориде', 'B_LOC'), ('и', 'O'), ('из', 'O'), ('Центра', 'B_LOC'), ('управления', 'I_LOC'), ('полётом', 'I_LOC'), ('под', 'O'), ('Москвой', 'B_LOC')]\n",
            "центра\n",
            "['средоточие', 'периферия', 'учреждение', 'эпицентр', 'столица', 'объект', 'элита', 'сфера', 'окраина', 'штаб-квартира']\n",
            "Джонсона\n",
            "['бейли', 'фостер', 'аллан', 'уилсон', 'кингсли', 'стиллер', 'пинхас', 'голсуорсить', 'брайан', 'эдмонд']\n",
            "центра\n",
            "['средоточие', 'периферия', 'учреждение', 'эпицентр', 'столица', 'объект', 'элита', 'сфера', 'окраина', 'штаб-квартира']\n",
            "Кеннеди\n",
            "['дзюбай', 'леннон', 'салстон', 'маклафлин', 'глэбб', 'уэлпля', 'элтон', 'хинкли', 'франкенхаймер', 'болтон']\n",
            "управления\n",
            "['отдел', 'увд', 'ведение', 'заведывание', 'гидрометеослужба', 'автобронетанковый', 'довольствующий', 'инспектор', 'ведомство', 'дальстрой']\n",
            "полётом\n",
            "[('С', 'O'), ('13', 'O'), ('по', 'O'), ('14', 'O'), ('апреля', 'O'), ('в', 'O'), ('Аль', 'B_LOC'), ('Аин', 'I_LOC'), ('(', 'O'), ('Al', 'B_LOC'), ('Ain', 'I_LOC'), (')', 'O'), ('(', 'O'), ('Объединённые', 'B_LOC'), ('Арабские', 'I_LOC'), ('Эмираты', 'I_LOC'), (')', 'O'), ('состоялось', 'O'), ('заседание', 'O'), ('президентского', 'B_ORG'), ('совета', 'I_ORG'), ('ФИДЕ', 'I_ORG')]\n",
            "Аин\n",
            "['bardenhewer_UN', 'аинский', 'scott_UN', 'rowe_UN', 'protection_UN', 'agropyrum_UN', 'diaboli_UN', 'библа', 'rodriguez_UN', 'выбить']\n",
            "Ain\n",
            "Арабские\n",
            "['греческий', 'славянский', 'мусульманский', 'тюркский', 'китайский', 'скандинавский', 'хантыйский', 'латинский', 'хеттский', 'баскский']\n",
            "Эмираты\n",
            "['халифат', 'оаэ', 'шейх', 'корач', 'карьял', 'сапорт', 'интертото', 'стэнли', 'отличительный', 'оман']\n",
            "[('Этот', 'O'), ('турнир', 'O'), ('пройдёт', 'O'), ('по', 'O'), ('той', 'O'), ('же', 'O'), ('формуле', 'O'), (',', 'O'), ('что', 'O'), ('и', 'O'), ('первый', 'O'), ('такой', 'O'), ('турнир', 'O'), (',', 'O'), ('который', 'O'), ('состоялся', 'O'), ('в', 'O'), ('2005', 'O'), ('году', 'O'), ('в', 'O'), ('Сан', 'B_LOC'), ('Луисе', 'I_LOC'), ('(', 'O'), ('Аргентина', 'B_LOC'), (')', 'O')]\n",
            "Луисе\n",
            "['гонзалес', 'пьетро', 'наварро', 'эстрелл', 'денни', 'каррерас', 'ривер', 'бельгийка', 'диего', 'джудит']\n",
            "[('Алексей', 'B_PER'), ('Ратманский', 'I_PER'), ('подытожил', 'O'), ('свою', 'O'), ('работу', 'O'), ('в', 'O'), ('главном', 'B_LOC'), ('театре', 'I_LOC'), ('страны', 'I_LOC'), ('грандиозным', 'O'), ('гала-концертом', 'O')]\n",
            "театре\n",
            "['мхат', 'труппа', 'спектакль', 'цирк', 'студия', 'ленком', 'балет', 'опера', 'тюз', 'бдт_UN']\n",
            "страны\n",
            "['россия', 'европа', 'государство', 'регион', 'держава', 'континент', 'человечество', 'мир', 'планета', 'республика']\n",
            "[('Виктору', 'B_PER'), ('Буту', 'I_PER'), ('впервые', 'O'), ('разрешили', 'O'), ('свидание', 'O'), ('с', 'O'), ('семьёй', 'O'), ('в', 'O'), ('тюрьме', 'B_LOC'), ('США', 'I_LOC'), ('Супруга', 'O'), ('«', 'O'), ('оружейного', 'O'), ('барона', 'O'), ('»', 'O'), ('рассчитывает', 'O'), (',', 'O'), ('что', 'O'), ('теперь', 'O'), ('эти', 'O'), ('встречи', 'O'), ('станут', 'O'), ('регулярными', 'O')]\n",
            "США\n",
            "['великобритания', 'япония', 'фрг', 'франция', 'англия', 'германия', 'канада', 'швейцария', 'швеция', 'италия']\n",
            "[('В', 'O'), ('первый', 'O'), ('раз', 'O'), ('за', 'O'), ('два', 'O'), ('месяца', 'O'), ('с', 'O'), ('тех', 'O'), ('пор', 'O'), (',', 'O'), ('как', 'O'), ('Виктор', 'B_PER'), ('Бут', 'I_PER'), ('был', 'O'), ('экстрадитрован', 'O'), ('из', 'O'), ('Таиланда', 'B_LOC'), ('в', 'O'), ('США', 'B_LOC'), (',', 'O'), ('российскому', 'O'), ('бизнесмену', 'O'), (',', 'O'), ('находящемуся', 'O'), ('в', 'O'), ('федеральной', 'B_LOC'), ('тюрьме', 'I_LOC'), ('Нью-Йорка', 'I_LOC'), (',', 'O'), ('разрешили', 'O'), ('свидание', 'O'), ('с', 'O'), ('женой', 'O'), (',', 'O'), ('сообщает', 'O'), ('NEWSru.com', 'B_ORG')]\n",
            "тюрьме\n",
            "['концлагерь', 'каторга', 'карцер', 'лагерь', 'острог', 'бутырки', 'темница', 'каталажка', 'психушка', 'гауптвахта']\n",
            "Нью-Йорка\n",
            "['лондон', 'лос-анджелес', 'париж', 'токио', 'сан-франциско', 'чикаго', 'филадельфия', 'вашингтон', 'берлин', 'гамбург']\n",
            "[('Реформа', 'O'), ('системы', 'O'), ('корпоративного', 'O'), ('налогообложения', 'O'), ('в', 'O'), ('Новой', 'B_LOC'), ('Зеландии', 'I_LOC'), ('будет', 'O'), ('проведена', 'O'), ('не', 'O'), ('ранее', 'O'), (',', 'O'), ('чем', 'O'), ('через', 'O'), ('два', 'O'), ('года', 'O')]\n",
            "Зеландии\n",
            "['гвинея', 'каледония', 'аскания', 'орлеан', 'корчин', 'нордиск', 'корчина', 'орлеана', 'саят', 'силокс']\n",
            "[('Об', 'O'), ('этом', 'O'), ('заявил', 'O'), ('министр', 'O'), ('финансов', 'O'), ('Новой', 'B_LOC'), ('Зеландии', 'I_LOC'), ('Майкл', 'B_PER'), ('Каллен', 'I_PER')]\n",
            "Зеландии\n",
            "['гвинея', 'каледония', 'аскания', 'орлеан', 'корчин', 'нордиск', 'корчина', 'орлеана', 'саят', 'силокс']\n",
            "[('Министр', 'O'), ('по', 'O'), ('государственным', 'O'), ('сборам', 'O'), ('Новой', 'B_LOC'), ('Зеландии', 'I_LOC'), ('Питер', 'B_PER'), ('Данн', 'I_PER'), ('подчеркнул', 'O'), (',', 'O'), ('что', 'O'), ('правительство', 'O'), ('еще', 'O'), ('несколько', 'O'), ('месяцев', 'O'), ('назад', 'O'), ('приступило', 'O'), ('к', 'O'), ('пересмотру', 'O'), ('существующего', 'O'), ('налогового', 'O'), ('режима', 'O'), ('для', 'O'), ('компаний', 'O')]\n",
            "Зеландии\n",
            "['гвинея', 'каледония', 'аскания', 'орлеан', 'корчин', 'нордиск', 'корчина', 'орлеана', 'саят', 'силокс']\n",
            "[('Между', 'O'), ('тем', 'O'), ('организация', 'B_ORG'), ('Business', 'I_ORG'), ('NZ', 'I_ORG'), (',', 'O'), ('которая', 'O'), ('объединяет', 'O'), ('ведущие', 'O'), ('бизнес-ассоциации', 'O'), ('Новой', 'B_LOC'), ('Зеландии', 'I_LOC'), (',', 'O'), ('выступила', 'O'), ('за', 'O'), ('ускоренное', 'O'), ('реформирование', 'O'), ('системы', 'O'), ('корпоративного', 'O'), ('налогообложения', 'O'), (',', 'O'), ('отметив', 'O'), (',', 'O'), ('что', 'O'), ('для', 'O'), ('выполнения', 'O'), ('этой', 'O'), ('задачи', 'O'), ('достаточно', 'O'), ('менее', 'O'), ('двух', 'O'), ('лет', 'O')]\n",
            "Зеландии\n",
            "['гвинея', 'каледония', 'аскания', 'орлеан', 'корчин', 'нордиск', 'корчина', 'орлеана', 'саят', 'силокс']\n",
            "[('Корпорация', 'B_ORG'), ('Philips', 'I_ORG'), ('подала', 'O'), ('заявку', 'O'), ('на', 'O'), ('сотрудничество', 'O'), ('с', 'O'), ('инноградом', 'B_LOC'), ('Сколково', 'I_LOC'), ('В', 'O'), ('рамках', 'O'), ('подмосковного', 'B_ORG'), ('инновационного', 'I_ORG'), ('центра', 'I_ORG'), ('компания', 'B_ORG'), ('собирается', 'O'), ('заняться', 'O'), ('производством', 'O'), ('светодиодов', 'O'), ('и', 'O'), ('медицинской', 'O'), ('техники', 'O')]\n",
            "Сколково\n",
            "[('Корпорация', 'B_ORG'), ('Philips', 'I_ORG'), ('всерьёз', 'O'), ('заинтересована', 'O'), ('в', 'O'), ('налаживании', 'O'), ('партнёрства', 'O'), ('с', 'O'), ('российской', 'B_LOC'), ('Кремниевой', 'I_LOC'), ('долиной', 'I_LOC'), ('и', 'O'), ('даже', 'O'), ('подала', 'O'), ('заявку', 'O'), ('на', 'O'), ('участие', 'O'), ('в', 'O'), ('проекте', 'B_ORG'), ('«', 'I_ORG'), ('Сколково', 'I_ORG'), ('»', 'I_ORG')]\n",
            "Кремниевой\n",
            "['монокристаллический', 'акриловый', 'иминодиуксусный', 'адипиновый', 'борный', 'поликристаллический', 'рибонуклеиновый', 'нуклеиновый', 'тонкопленочный', 'азотный']\n",
            "долиной\n",
            "['ущелие', 'верховье', 'река', 'пойма', 'устье', 'речка', 'отрог', 'распадок', 'перевал', 'хангай']\n",
            "[('Сябренко', 'B_PER'), ('также', 'O'), ('рассказала', 'O'), ('о', 'O'), ('том', 'O'), (',', 'O'), ('чем', 'O'), ('бы', 'O'), ('хотела', 'O'), ('заняться', 'O'), ('корпорация', 'B_ORG'), ('Philips', 'I_ORG'), ('в', 'O'), ('рамках', 'O'), ('подмосковного', 'B_LOC'), ('иннограда', 'I_LOC')]\n",
            "иннограда\n",
            "[('Corus', 'O'), ('Chess', 'O'), ('Tournament', 'O'), ('2006', 'O'), ('В', 'O'), ('маленьком', 'O'), ('голландском', 'B_LOC'), ('городке', 'I_LOC'), ('Вейк-ан-Зее', 'I_LOC'), ('проводится', 'O'), ('традиционный', 'O'), ('шахматный', 'O'), ('турнир', 'O'), ('—', 'O'), ('«', 'O'), ('Шахматный', 'O'), ('турнир', 'O'), ('Корус', 'O'), ('»', 'O'), ('(', 'O'), ('Corus', 'O'), ('Chess', 'O'), ('Tournament', 'O'), (')', 'O'), (',', 'O'), ('который', 'O'), (',', 'O'), ('на', 'O'), ('самом', 'O'), ('деле', 'O'), ('состоит', 'O'), ('из', 'O'), ('нескольких', 'O'), ('турниров', 'O'), ('—', 'O'), ('A', 'O'), (',', 'O'), ('B', 'O'), (',', 'O'), ('C', 'O'), ('и', 'O'), ('несколько', 'O'), ('турниров', 'O'), ('для', 'O'), ('любителей', 'O')]\n",
            "городке\n",
            "['городишко', 'деревушка', 'поселок', 'город', 'деревенька', 'селение', 'домик', 'местечко', 'деревня', 'хуторок']\n",
            "Вейк-ан-Зее\n",
            "[('Её', 'O'), ('«', 'O'), ('запустили', 'O'), ('в', 'O'), ('эксплуатацию', 'O'), ('»', 'O'), ('6', 'O'), ('сентября', 'O'), ('в', 'O'), ('Центральном', 'B_LOC'), ('округе', 'I_LOC'), ('столицы', 'I_LOC'), ('в', 'O'), ('Лужниках', 'B_LOC')]\n",
            "округе\n",
            "['округ_', 'район', 'приволжский', 'генерал-губернатор', 'губерния', 'госуниверситет', 'область', 'окружной', 'уезд', 'окружный']\n",
            "столицы\n",
            "['город', 'провинция', 'петербург', 'окраина', 'москва', 'территория', 'городок', 'кавказ', 'пригород', 'империя']\n",
            "[('До', 'O'), ('принятия', 'O'), ('соответствующего', 'O'), ('решения', 'O'), ('возникла', 'O'), ('проблема', 'O'), ('с', 'O'), ('велосипедистами', 'O'), ('на', 'O'), ('склонах', 'O'), ('Воробьёвых', 'B_LOC'), ('гор', 'I_LOC'), (',', 'O'), ('которые', 'O'), ('нелегально', 'O'), ('построили', 'O'), ('скоростные', 'O'), ('трассы', 'O'), (',', 'O'), ('трамплины', 'O'), ('и', 'O'), ('начали', 'O'), ('понемногу', 'O'), ('«', 'O'), ('портить', 'O'), ('»', 'O'), ('природу', 'O'), (',', 'O'), ('выламывая', 'O'), ('деревья', 'O'), ('и', 'O'), ('разрушая', 'O'), ('почвенный', 'O'), ('покров', 'O')]\n",
            "гор\n",
            "['холм', 'сопка', 'скала', 'увал', 'отрог', 'вершина', 'утес', 'плато', 'склон', 'перевал']\n",
            "[('Следует', 'O'), ('иметь', 'O'), ('в', 'O'), ('виду', 'O'), (',', 'O'), ('что', 'O'), ('в', 'O'), ('центре', 'B_ORG'), ('Кин-Топ', 'I_ORG'), ('занимаются', 'O'), ('взрослые', 'O'), ('и', 'O'), ('дети', 'O'), (',', 'O'), ('переселенцы', 'O'), ('из', 'O'), ('бывшего', 'O'), ('Советского', 'B_LOC'), ('Союза', 'I_LOC'), (',', 'O'), ('считающие', 'O'), (',', 'O'), ('что', 'O'), ('русский', 'O'), ('язык', 'O'), ('нужно', 'O'), ('обязательно', 'O'), ('сохранить', 'O'), ('как', 'O'), ('язык', 'O'), ('общения', 'O'), ('и', 'O'), ('как', 'O'), ('возможность', 'O'), ('приобщения', 'O'), ('к', 'O'), ('великой', 'O'), ('и', 'O'), ('давней', 'O'), ('культуре', 'O'), ('русского', 'O'), ('народа', 'O')]\n",
            "Союза\n",
            "['делегация', 'спелеодвижение', 'профсоюз', 'кинематография', 'ссп_UN', 'ascap_UN', 'республика', 'объединение', 'организация', 'власть']\n",
            "[('А', 'O'), ('чем', 'O'), ('только', 'O'), ('они', 'O'), ('не', 'O'), ('интересуются', 'O'), ('!', 'O'), ('От', 'O'), ('обычных', 'O'), ('школьных', 'O'), ('предметов', 'O'), ('до', 'O'), ('геологии', 'O'), (',', 'O'), ('танцев', 'O'), (',', 'O'), ('самообороны', 'O'), (',', 'O'), ('балета', 'O'), (',', 'O'), ('кукольного', 'O'), ('театра', 'O'), (',', 'O'), ('походов', 'O'), ('и', 'O'), ('даже', 'O'), ('…', 'O'), ('китайского', 'O'), ('языка', 'O'), ('!', 'O'), ('Преподаватели', 'O'), ('—', 'O'), ('со', 'O'), ('всех', 'O'), ('концов', 'O'), ('Советского', 'B_LOC'), ('Союза', 'I_LOC'), (',', 'O'), ('самые', 'O'), ('высококвалифицированные', 'O'), ('и', 'O'), ('достойные', 'O')]\n",
            "Союза\n",
            "['делегация', 'спелеодвижение', 'профсоюз', 'кинематография', 'ссп_UN', 'ascap_UN', 'республика', 'объединение', 'организация', 'власть']\n",
            "[('Кстати', 'O'), (',', 'O'), ('станция', 'B_LOC'), ('метро', 'I_LOC'), ('Московская', 'I_LOC'), ('в', 'O'), ('Дюссельдорфе', 'B_LOC'), ('отделана', 'O'), ('камнем', 'O'), (',', 'O'), ('привезенныи', 'O'), ('из', 'O'), ('России', 'B_LOC'), (',', 'O'), ('а', 'O'), ('недалеко', 'O'), ('—', 'O'), ('памятник', 'B_LOC'), ('Пушкину', 'I_LOC')]\n",
            "метро\n",
            "['трамвай', 'вокзал', 'электричка', 'маяковская', 'троллейбус', 'метрополитен', 'аэропорт', 'новослободский', 'савеловский', 'автозаправочный']\n",
            "Московская\n",
            "['петербургский', 'ленинградский', 'киевский', 'столичный', 'одесский', 'харьковский', 'ташкентский', 'саратовский', 'санкт-петербургский', 'питерский']\n",
            "Пушкину\n",
            "['гоголь', 'лермонтов', 'тургенев', 'баратынский', 'жуковский', 'карамзин', 'фет', 'некрасов', 'тютчев', 'шекспир']\n",
            "[('Дюссельдорф', 'B_LOC'), ('—', 'O'), ('центр', 'O'), ('моды', 'O'), ('не', 'O'), ('только', 'O'), ('Германии', 'B_LOC'), (',', 'O'), ('но', 'O'), ('и', 'O'), ('всей', 'O'), ('Западной', 'B_LOC'), ('Европы', 'I_LOC')]\n",
            "Европы\n",
            "['германия', 'африка', 'страна', 'америка', 'европейский', 'япония', 'россия', 'китай', 'средиземноморье', 'англия']\n",
            "[('По', 'O'), ('мнению', 'O'), ('директора', 'O'), ('Международного', 'B_ORG'), ('института', 'I_ORG'), ('политической', 'I_ORG'), ('экспертизы', 'I_ORG'), ('Евгения', 'B_PER'), ('Минченко', 'I_PER'), (',', 'O'), ('в', 'O'), ('этом', 'O'), ('году', 'O'), ('вероятность', 'O'), ('досрочного', 'O'), ('прекращения', 'O'), ('полномочий', 'O'), ('главы', 'O'), ('Московской', 'B_LOC'), ('области', 'I_LOC'), ('Бориса', 'B_PER'), ('Громова', 'I_PER'), ('стала', 'O'), ('достаточна', 'O'), ('велика', 'O')]\n",
            "области\n",
            "['обл', 'губерния', 'сфера', 'епархия', 'ялуторовский', 'облкомстат', 'район', 'уезд', 'округ', 'отрасль']\n",
            "[('Жители', 'O'), ('Соединённого', 'B_LOC'), ('Королевства', 'I_LOC'), ('продолжают', 'O'), ('агрессивно', 'O'), ('возмущаться', 'O'), ('из-за', 'O'), ('убийства', 'O'), ('полицейским', 'O'), ('темнокожего', 'O')]\n",
            "Королевства\n",
            "['штат', 'король', 'великобритания', 'принц', 'герцогство', 'франция', 'дания', 'британия', 'германия', 'сицилия']\n",
            "[('Вслед', 'O'), ('за', 'O'), ('Лондоном', 'B_LOC'), ('и', 'O'), ('Бирмингемом', 'B_LOC'), ('беспорядки', 'O'), ('вспыхнули', 'O'), ('ещё', 'O'), ('в', 'O'), ('нескольких', 'O'), ('крупных', 'B_LOC'), ('британских', 'I_LOC'), ('городах', 'I_LOC'), (':', 'I_LOC'), ('Ливерпуле', 'I_LOC'), (',', 'I_LOC'), ('Манчестере', 'I_LOC'), ('и', 'I_LOC'), ('Бристоле', 'I_LOC')]\n",
            "британских\n",
            "['американский', 'японский', 'английский', 'великобританский', 'шведский', 'французский', 'норвежский', 'южнокорейский', 'канадский', 'австро-венгерский']\n",
            "городах\n",
            "['столица', 'деревня', 'поселок', 'городок', 'селение', 'городишко', 'пригород', 'село', 'окрестность', 'москва']\n",
            ":\n",
            "Ливерпуле\n",
            "['барселона', 'дакар', 'детройт', 'рио-де-жанейро', 'глазго', 'манчестер', 'депортиво_A', 'сакраменто', 'впринцип', 'рейнджерс']\n",
            ",\n",
            "Манчестере\n",
            "['стейтс', 'шеффилд', 'ливерпуль', 'бирмингем', 'кассель', 'глазго', 'мексико', 'лондон', 'лидс', 'тиколка']\n",
            "и\n",
            "Бристоле\n",
            "[('Напомним', 'O'), (',', 'O'), ('что', 'O'), ('причиной', 'O'), ('беспорядков', 'O'), ('в', 'O'), ('лондонском', 'B_LOC'), ('районе', 'I_LOC'), ('Тоттенхэм', 'I_LOC'), ('стало', 'O'), ('убийство', 'O'), ('полицейским', 'O'), ('29-летнего', 'O'), ('темнокожего', 'O'), ('британца', 'O'), ('Марка', 'B_PER'), ('Дуггана', 'I_PER'), (',', 'O'), ('которое', 'O'), ('произошло', 'O'), ('4', 'O'), ('августа', 'O')]\n",
            "районе\n",
            "['окраина', 'поселок', 'р-н', 'территория', 'уезд', 'город', 'местность', 'регион', 'катангский', 'станица']\n",
            "Тоттенхэм\n",
            "[('Федеральное', 'B_ORG'), ('авиационное', 'I_ORG'), ('управление', 'I_ORG'), ('пояснило', 'O'), (',', 'O'), ('что', 'O'), ('в', 'O'), ('субботу', 'O'), ('после', 'O'), ('полудня', 'O'), ('(', 'O'), ('время', 'O'), ('Восточного', 'B_LOC'), ('побережья', 'I_LOC'), ('США', 'I_LOC'), (')', 'O'), (',', 'O'), ('в', 'O'), ('тот', 'O'), ('момент', 'O'), (',', 'O'), ('когда', 'O'), ('снижающийся', 'O'), ('пассажирский', 'O'), ('лайнер', 'O'), ('компании', 'B_ORG'), ('Piedmont', 'I_ORG'), ('Airlines', 'I_ORG'), ('вошел', 'O'), ('в', 'O'), ('строго', 'O'), ('охраняемое', 'O'), ('воздушное', 'O'), ('пространство', 'O'), ('над', 'O'), ('американской', 'O'), ('столицей', 'O'), (',', 'O'), ('в', 'O'), ('непосредственной', 'O'), ('близости', 'O'), ('от', 'O'), ('здания', 'B_LOC'), ('Конгресса', 'I_LOC'), (',', 'O'), ('с', 'O'), ('ним', 'O'), ('пропала', 'O'), ('связь', 'O')]\n",
            "побережья\n",
            "['побережие', 'берег', 'оконечность', 'материк', 'порт', 'прибрежье', 'атлантика', 'африка', 'причерноморье', 'каспий']\n",
            "США\n",
            "['великобритания', 'япония', 'фрг', 'франция', 'англия', 'германия', 'канада', 'швейцария', 'швеция', 'италия']\n",
            "Конгресса\n",
            "['конференция', 'симпозиум', 'форум', 'кинофестиваль', 'съезд', 'совещание', 'пен-клуб', 'саммит', 'авиасалон', 'фестиваль']\n",
            "[('Авиационное', 'B_ORG'), ('управление', 'I_ORG'), ('сообщило', 'O'), (',', 'O'), ('что', 'O'), ('связь', 'O'), ('с', 'O'), ('бортом', 'O'), ('восстановили', 'O'), (',', 'O'), ('и', 'O'), ('самолет', 'O'), (',', 'O'), ('следовавший', 'O'), ('обычным', 'O'), ('рейсом', 'O'), ('из', 'O'), ('города', 'B_LOC'), ('Хилтон', 'I_LOC'), ('Хэд', 'I_LOC'), ('в', 'O'), ('Южной', 'B_LOC'), ('Каролине', 'I_LOC'), (',', 'O'), ('благополучно', 'O'), ('приземлился', 'O'), ('в', 'O'), ('пункте', 'O'), ('назначения', 'O'), ('–', 'O'), ('Вашингтонском', 'B_LOC'), ('аэропорту', 'I_LOC'), ('Рейган', 'I_LOC')]\n",
            "Хилтон\n",
            "['пятизвездный', 'банхоф', 'четырехзвездочный', 'пятизвездочный', 'амбассадор', 'медитерранеан', 'istria_UN', 'мажестик', 'бургонский', 'звездочный']\n",
            "Хэд\n",
            "Каролине\n",
            "['дакота', 'барабар', 'барбара', 'луиза', 'генриетта', 'пальмира', 'ренато', 'герцогиня', 'сайер', 'сесиль']\n",
            "аэропорту\n",
            "['вокзал', 'шереметьево', 'аэродром', 'внуково', 'метро', 'электричка', 'домодедово', 'аэровокзал', 'автобус', 'такси']\n",
            "Рейган\n",
            "['уит', 'руэл', 'мубарак', 'кэдиш', 'трумэн', 'тафт', 'хейуорд', 'эйзенхауэр', 'миллхауз', 'floyd_UN']\n",
            "[('На', 'O'), ('заре', 'O'), ('первого', 'O'), ('дня', 'O'), ('Нового', 'O'), ('года', 'O'), ('нефть', 'O'), ('начали', 'O'), ('качать', 'O'), ('по', 'O'), ('трубам', 'O'), (',', 'O'), ('протянувшимся', 'O'), ('более', 'O'), (',', 'O'), ('чем', 'O'), ('на', 'O'), ('3600', 'O'), ('км', 'O'), ('из', 'O'), ('Восточной', 'B_LOC'), ('Сибири', 'I_LOC'), ('в', 'O'), ('северовосточный', 'B_LOC'), ('китайский', 'I_LOC'), ('город', 'I_LOC'), ('Дацин', 'I_LOC')]\n",
            "Сибири\n",
            "['забайкалье', 'урал', 'кавказ', 'туркестан', 'африка', 'колыма', 'европа', 'приуралье', 'сахалин', 'юг']\n",
            "китайский\n",
            "['японский', 'болгарский', 'французский', 'итальянский', 'испанский', 'иранский', 'румынский', 'монгольский', 'индийский', 'мексиканский']\n",
            "город\n",
            "['столица', 'деревня', 'поселок', 'городок', 'селение', 'городишко', 'пригород', 'село', 'окрестность', 'москва']\n",
            "Дацин\n",
            "['ангарск', 'нефтепровод', 'днс_UN', 'транскитайский', 'уньвинский', 'бтд_UN', 'трансаравийский', 'берикей', 'ктк_UN', 'североевропейский']\n",
            "[('До', 'O'), ('сих', 'O'), ('пор', 'O'), ('доставка', 'O'), ('сырой', 'O'), ('нефти', 'O'), ('осуществлялись', 'O'), ('по', 'O'), ('железной', 'O'), ('дороге', 'O'), ('в', 'O'), ('тихоокеанский', 'B_LOC'), ('порт', 'I_LOC'), ('Козьмино', 'I_LOC')]\n",
            "порт\n",
            "['гавань', 'судно', 'пароход', 'пристань', 'пароходство', 'эскадра', 'бухта', 'причал', 'корабль', 'побережье']\n",
            "Козьмино\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_sent = []\n",
        "clean_tags = []\n",
        "for i in new_sents:\n",
        "    words = []\n",
        "    tags = []\n",
        "    for w, t in i:\n",
        "        words.append(w)\n",
        "        tags.append(t)\n",
        "    clean_sent.append(words)\n",
        "    clean_tags.append(tags)"
      ],
      "metadata": {
        "id": "QdWqzdyK9svy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_new = []\n",
        "for i in clean_sent:\n",
        "    join_new.append(\" \".join(i))"
      ],
      "metadata": {
        "id": "iobkK0RT9svy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_tags = []\n",
        "for i in clean_tags:\n",
        "    join_tags.append(\" \".join(i))"
      ],
      "metadata": {
        "id": "Rec5wpo89svy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(join_new)"
      ],
      "metadata": {
        "id": "qjRu2Cdl9svy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.DataFrame(join_tags)"
      ],
      "metadata": {
        "id": "EnzW4FmJ9svy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['tags'] = data2[0]"
      ],
      "metadata": {
        "id": "8U4qLERy9svy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"len_words\"] = data[0].str.split().apply(len)\n",
        "data[\"len_tags\"] = data['tags'].str.split().apply(len)"
      ],
      "metadata": {
        "id": "TB3UQ_XY9svz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"aug_I_LOC_last.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "9N53jhcArmgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "80b9f3e8-4848-46bc-ecbb-ffdefc867a56",
        "id": "2qWrQ-un0SXd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    0  \\\n",
              "0   В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1   Освещающие акцию блоггеры сообщили , что автоб...   \n",
              "2   Барак Обама принимает в Белом квартире своего ...   \n",
              "3   В частности , лидеры намерены обменяться мнени...   \n",
              "4   В понедельник Джаред Лофнер в наручниках и в с...   \n",
              "5   Тогда были убиты шесть человек , а член Палаты...   \n",
              "6   Обама выступал в Белом хате через несколько ча...   \n",
              "7   Президент и первая леди Мишель Обама задержали...   \n",
              "8   В тот же день Южная вьетнаме заявила , что вся...   \n",
              "9   До сих пор среди главных стратегических партнё...   \n",
              "10  Турция поможет крымским татарам По итогам встр...   \n",
              "11  Почему ? Мусульманский мир довольно обширен … ...   \n",
              "12  Кроме того , после завоевания Крыма Россией , ...   \n",
              "13  Голос Америки : Достаточно ли сегодня у Крыма ...   \n",
              "14  Голос Америки : Спасибо за интервью ! Гагаузы ...   \n",
              "15  В условиях политической нестабильности и дезин...   \n",
              "16  В конце субботней классификации Михаэль Шумахе...   \n",
              "17  В августе 2004 года \" продуктопровод \" , проло...   \n",
              "18  К Кронштадтскому переулке , где болельщика « С...   \n",
              "19  Впрочем , показательно , что на Манежной пресн...   \n",
              "20  Сегодня на Кронштадтском площади не было почти...   \n",
              "21  \" Эх , яблочко \" ... Кроме сторонников ДПНИ , ...   \n",
              "22  Вот как эту панихиду прокомментировал писатель...   \n",
              "23  Продолжает отбывать 10-и летний срок заключени...   \n",
              "24  Соединенные довольствии , Азербайджан , и Буру...   \n",
              "25  В 19 часов по Московскому времени в Болгарии б...   \n",
              "26  « Нужно обращаться к народу Северной америке ,...   \n",
              "27  Во время поездки политика , за которым охотятс...   \n",
              "28  Около 30 рабочих на заводе по производству вет...   \n",
              "29  Vestas — основной работодатель на Острове линд...   \n",
              "30  Завод закрыт несмотря на растущие прибыли комп...   \n",
              "31  Как известно , Иса Ямадаев является братом Сул...   \n",
              "32  Например , за первое полугодие 2009 года цены ...   \n",
              "33  Петербургские экологи обнаружили жёлтые пятна ...   \n",
              "34  Они требуют привлечь к уголовной ответственнос...   \n",
              "35  Эта группа и Южная водозаборная станция ГУП « ...   \n",
              "36  Ниже устья реки ижме находится южная водозабор...   \n",
              "37  В ночь с 20 на 21 июля в приток Невы реку клим...   \n",
              "38  Об этом активистам Гринпис сообщили жители пос...   \n",
              "39  Остаётся неизвестным даже Росприроднадзору , к...   \n",
              "40  Все сбросы осуществлялись через один и тот же ...   \n",
              "41  1 февраля на ступеньках будущего президентског...   \n",
              "42  Уральцы никогда не забудут того , что сделал Б...   \n",
              "43  В церемонии также приняли участие вдова Ельцин...   \n",
              "44  И заложил основу этому первый президент , живш...   \n",
              "45  В мае 1981 года , во Дворце молодёжи , он пров...   \n",
              "46  Поводом для отзыва стал тот факт , что дипмисс...   \n",
              "47  Однако , как известно , глава России 31 октябр...   \n",
              "48  Правительство Японии выразило решительный прот...   \n",
              "49  Четыре острова , которые называются Южными афр...   \n",
              "\n",
              "                                                 tags  len_words  len_tags  \n",
              "0   O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...         35        35  \n",
              "1   O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...         27        27  \n",
              "2       B_PER I_PER O O B_LOC I_LOC O O O B_PER I_PER         11        11  \n",
              "3   O O O O O O O O O O O B_ORG O B_LOC O O O B_LO...         24        24  \n",
              "4   O O B_PER I_PER O O O O O O O O O O O B_LOC I_LOC         17        17  \n",
              "5   O O O O O O O O B_ORG I_ORG I_ORG I_ORG O B_LO...         27        27  \n",
              "6   B_PER O O B_LOC I_LOC O O O O O O O O O O O O ...         24        24  \n",
              "7   O O O O B_PER I_PER O O B_LOC I_LOC O O O O O ...         19        19  \n",
              "8   O O O O B_LOC I_LOC O O O O O O B_LOC O O O O ...         25        25  \n",
              "9   O O O O O O O O B_LOC O O O O O O O O B_LOC I_...         25        25  \n",
              "10  B_LOC O O O O O O O O O O B_LOC O O O O O O O ...         26        26  \n",
              "11  O O O O O O O B_PER I_PER O O O O B_LOC I_LOC ...         25        25  \n",
              "12  O O O O O B_LOC B_LOC O O O O O O O O O O B_LO...         19        19  \n",
              "13  B_ORG I_ORG O O O O O B_LOC O O O O O O O B_PE...         24        24  \n",
              "14  B_ORG I_ORG O O O O O O O O O O O B_LOC O O O ...         44        44  \n",
              "15  O O O O O O O O B_LOC O O O O O O O O O O O O ...         39        39  \n",
              "16  O O O O B_PER I_PER O O O O B_LOC O B_LOC I_LO...         27        27  \n",
              "17  O O O O O O O O O O O O B_LOC I_LOC O O O O O ...         27        27  \n",
              "18  O B_LOC I_LOC O O O O B_ORG O B_PER I_PER O O ...         34        34  \n",
              "19                O O O O O O B_LOC I_LOC O O O O O O         14        14  \n",
              "20                          O O B_LOC I_LOC O O O O O          9         9  \n",
              "21  O O O O O O O O B_ORG O O B_LOC I_LOC O O O B_...         28        28  \n",
              "22  O O O O O O O O B_PER I_PER O O O O O O O O O ...         82        82  \n",
              "23  O O O O O O O O B_PER I_PER O B_PER I_PER O O ...         30        30  \n",
              "24  B_LOC I_LOC O B_LOC O O B_LOC O O O O O O O O O O         17        17  \n",
              "25    O O O O O O O B_LOC O O O O B_LOC I_LOC O B_LOC         16        16  \n",
              "26  O O O O O B_LOC I_LOC O O O O O O O O O O O O ...         26        26  \n",
              "27            O O O O O O O O O B_LOC I_LOC O O O O O         16        16  \n",
              "28  O O O O B_ORG I_ORG I_ORG I_ORG I_ORG O O O B_...         29        29  \n",
              "29              B_ORG O O O O B_LOC I_LOC O O O O O O         13        13  \n",
              "30  O O O O O O O O O O O O B_LOC O O O O O O B_LO...         21        21  \n",
              "31  O O O B_PER I_PER O O B_PER I_PER O O B_LOC I_...         24        24  \n",
              "32  O O O O O O O O O O O O O O B_LOC I_LOC O O O ...         31        31  \n",
              "33                  O O O O O O O O O O O B_LOC I_LOC         13        13  \n",
              "34                  O O O O O O O O O O O B_LOC I_LOC         13        13  \n",
              "35  O O O B_ORG I_ORG I_ORG I_ORG I_ORG I_ORG I_OR...         54        54  \n",
              "36  O O B_LOC I_LOC O B_ORG I_ORG I_ORG I_ORG I_OR...         23        23  \n",
              "37    O O O O O O O O O B_LOC B_LOC I_LOC O O O O O O         18        18  \n",
              "38                        O O O B_ORG O O B_LOC I_LOC          8         8  \n",
              "39  O O O B_ORG O O O O O O O O O O O O O O B_LOC ...         20        20  \n",
              "40  O O O O O O O O O O O O O B_LOC I_LOC I_LOC I_LOC         17        17  \n",
              "41  O O O O O B_ORG I_ORG I_ORG O B_LOC I_LOC I_LO...         21        21  \n",
              "42  O O O O O O O O B_PER I_PER O B_LOC I_LOC O O ...         20        20  \n",
              "43  O O O O O O B_PER B_PER I_PER O O O O O O O O ...         26        26  \n",
              "44                  O O O O O O O O O O O B_LOC I_LOC         13        13  \n",
              "45    O O O O O O B_LOC I_LOC O O O O O O O O O O O O         20        20  \n",
              "46  O O O O O O O O B_ORG O O O O B_ORG I_ORG I_OR...         26        26  \n",
              "47  O O O O O O B_LOC O O O O O O O O O B_LOC I_LO...         19        19  \n",
              "48  B_ORG I_ORG O O O O O O O O O O O O O B_LOC I_...         27        27  \n",
              "49  O O O O O B_LOC I_LOC O O O O O B_LOC I_LOC O ...         23        23  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-718ff5c5-615f-4aa8-9967-1ebfae14f587\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>tags</th>\n",
              "      <th>len_words</th>\n",
              "      <th>len_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Барак Обама принимает в Белом квартире своего ...</td>\n",
              "      <td>B_PER I_PER O O B_LOC I_LOC O O O B_PER I_PER</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В частности , лидеры намерены обменяться мнени...</td>\n",
              "      <td>O O O O O O O O O O O B_ORG O B_LOC O O O B_LO...</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В понедельник Джаред Лофнер в наручниках и в с...</td>\n",
              "      <td>O O B_PER I_PER O O O O O O O O O O O B_LOC I_LOC</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Тогда были убиты шесть человек , а член Палаты...</td>\n",
              "      <td>O O O O O O O O B_ORG I_ORG I_ORG I_ORG O B_LO...</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Обама выступал в Белом хате через несколько ча...</td>\n",
              "      <td>B_PER O O B_LOC I_LOC O O O O O O O O O O O O ...</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Президент и первая леди Мишель Обама задержали...</td>\n",
              "      <td>O O O O B_PER I_PER O O B_LOC I_LOC O O O O O ...</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>В тот же день Южная вьетнаме заявила , что вся...</td>\n",
              "      <td>O O O O B_LOC I_LOC O O O O O O B_LOC O O O O ...</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>До сих пор среди главных стратегических партнё...</td>\n",
              "      <td>O O O O O O O O B_LOC O O O O O O O O B_LOC I_...</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Турция поможет крымским татарам По итогам встр...</td>\n",
              "      <td>B_LOC O O O O O O O O O O B_LOC O O O O O O O ...</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Почему ? Мусульманский мир довольно обширен … ...</td>\n",
              "      <td>O O O O O O O B_PER I_PER O O O O B_LOC I_LOC ...</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Кроме того , после завоевания Крыма Россией , ...</td>\n",
              "      <td>O O O O O B_LOC B_LOC O O O O O O O O O O B_LO...</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Голос Америки : Достаточно ли сегодня у Крыма ...</td>\n",
              "      <td>B_ORG I_ORG O O O O O B_LOC O O O O O O O B_PE...</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Голос Америки : Спасибо за интервью ! Гагаузы ...</td>\n",
              "      <td>B_ORG I_ORG O O O O O O O O O O O B_LOC O O O ...</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>В условиях политической нестабильности и дезин...</td>\n",
              "      <td>O O O O O O O O B_LOC O O O O O O O O O O O O ...</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>В конце субботней классификации Михаэль Шумахе...</td>\n",
              "      <td>O O O O B_PER I_PER O O O O B_LOC O B_LOC I_LO...</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>В августе 2004 года \" продуктопровод \" , проло...</td>\n",
              "      <td>O O O O O O O O O O O O B_LOC I_LOC O O O O O ...</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>К Кронштадтскому переулке , где болельщика « С...</td>\n",
              "      <td>O B_LOC I_LOC O O O O B_ORG O B_PER I_PER O O ...</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Впрочем , показательно , что на Манежной пресн...</td>\n",
              "      <td>O O O O O O B_LOC I_LOC O O O O O O</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Сегодня на Кронштадтском площади не было почти...</td>\n",
              "      <td>O O B_LOC I_LOC O O O O O</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>\" Эх , яблочко \" ... Кроме сторонников ДПНИ , ...</td>\n",
              "      <td>O O O O O O O O B_ORG O O B_LOC I_LOC O O O B_...</td>\n",
              "      <td>28</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Вот как эту панихиду прокомментировал писатель...</td>\n",
              "      <td>O O O O O O O O B_PER I_PER O O O O O O O O O ...</td>\n",
              "      <td>82</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Продолжает отбывать 10-и летний срок заключени...</td>\n",
              "      <td>O O O O O O O O B_PER I_PER O B_PER I_PER O O ...</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Соединенные довольствии , Азербайджан , и Буру...</td>\n",
              "      <td>B_LOC I_LOC O B_LOC O O B_LOC O O O O O O O O O O</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>В 19 часов по Московскому времени в Болгарии б...</td>\n",
              "      <td>O O O O O O O B_LOC O O O O B_LOC I_LOC O B_LOC</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>« Нужно обращаться к народу Северной америке ,...</td>\n",
              "      <td>O O O O O B_LOC I_LOC O O O O O O O O O O O O ...</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Во время поездки политика , за которым охотятс...</td>\n",
              "      <td>O O O O O O O O O B_LOC I_LOC O O O O O</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Около 30 рабочих на заводе по производству вет...</td>\n",
              "      <td>O O O O B_ORG I_ORG I_ORG I_ORG I_ORG O O O B_...</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Vestas — основной работодатель на Острове линд...</td>\n",
              "      <td>B_ORG O O O O B_LOC I_LOC O O O O O O</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Завод закрыт несмотря на растущие прибыли комп...</td>\n",
              "      <td>O O O O O O O O O O O O B_LOC O O O O O O B_LO...</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Как известно , Иса Ямадаев является братом Сул...</td>\n",
              "      <td>O O O B_PER I_PER O O B_PER I_PER O O B_LOC I_...</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Например , за первое полугодие 2009 года цены ...</td>\n",
              "      <td>O O O O O O O O O O O O O O B_LOC I_LOC O O O ...</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Петербургские экологи обнаружили жёлтые пятна ...</td>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Они требуют привлечь к уголовной ответственнос...</td>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Эта группа и Южная водозаборная станция ГУП « ...</td>\n",
              "      <td>O O O B_ORG I_ORG I_ORG I_ORG I_ORG I_ORG I_OR...</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ниже устья реки ижме находится южная водозабор...</td>\n",
              "      <td>O O B_LOC I_LOC O B_ORG I_ORG I_ORG I_ORG I_OR...</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>В ночь с 20 на 21 июля в приток Невы реку клим...</td>\n",
              "      <td>O O O O O O O O O B_LOC B_LOC I_LOC O O O O O O</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Об этом активистам Гринпис сообщили жители пос...</td>\n",
              "      <td>O O O B_ORG O O B_LOC I_LOC</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Остаётся неизвестным даже Росприроднадзору , к...</td>\n",
              "      <td>O O O B_ORG O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Все сбросы осуществлялись через один и тот же ...</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC I_LOC</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1 февраля на ступеньках будущего президентског...</td>\n",
              "      <td>O O O O O B_ORG I_ORG I_ORG O B_LOC I_LOC I_LO...</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Уральцы никогда не забудут того , что сделал Б...</td>\n",
              "      <td>O O O O O O O O B_PER I_PER O B_LOC I_LOC O O ...</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>В церемонии также приняли участие вдова Ельцин...</td>\n",
              "      <td>O O O O O O B_PER B_PER I_PER O O O O O O O O ...</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>И заложил основу этому первый президент , живш...</td>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>В мае 1981 года , во Дворце молодёжи , он пров...</td>\n",
              "      <td>O O O O O O B_LOC I_LOC O O O O O O O O O O O O</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Поводом для отзыва стал тот факт , что дипмисс...</td>\n",
              "      <td>O O O O O O O O B_ORG O O O O B_ORG I_ORG I_OR...</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Однако , как известно , глава России 31 октябр...</td>\n",
              "      <td>O O O O O O B_LOC O O O O O O O O O B_LOC I_LO...</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Правительство Японии выразило решительный прот...</td>\n",
              "      <td>B_ORG I_ORG O O O O O O O O O O O O O B_LOC I_...</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Четыре острова , которые называются Южными афр...</td>\n",
              "      <td>O O O O O B_LOC I_LOC O O O O O B_LOC I_LOC O ...</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-718ff5c5-615f-4aa8-9967-1ebfae14f587')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-718ff5c5-615f-4aa8-9967-1ebfae14f587 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-718ff5c5-615f-4aa8-9967-1ebfae14f587');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug = pd.read_csv(\"/content/drive/MyDrive/kaggle HW2/aug_I_LOC_last.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "S45GLz0g8Qy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug[\"word_labels\"] = aug.tags.str.split().apply(\",\".join)"
      ],
      "metadata": {
        "id": "J2-y2ns98gpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug = aug[[\"Unnamed: 0\", \"0\", \"word_labels\"]]"
      ],
      "metadata": {
        "id": "kOWcLS3K9AcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug = aug.rename(columns={\"Unnamed: 0\": \"Sentence #\", \"0\": \"sentence\", \"word_labels\": \"word_labels\"})"
      ],
      "metadata": {
        "id": "M5U7b8sd9b1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.concat([data_df, aug], ignore_index=True, sort=False)"
      ],
      "metadata": {
        "id": "jEA63HUg-KkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = result"
      ],
      "metadata": {
        "id": "tYe-jsRG-QBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ncHYU6CL_DWX",
        "outputId": "08b94e93-4d9b-489d-8df3-54dc00470529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentence #                                           sentence  \\\n",
              "0              0  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1              1  Среди требований , выдвигаемых организаторами ...   \n",
              "2              2  Участникам акции предлагалось принести с собой...   \n",
              "3              3  Начало акции было намечено на 19 часов ; подчё...   \n",
              "4              4  Освещающие акцию блоггеры сообщили , что автоб...   \n",
              "...          ...                                                ...   \n",
              "2644        1125  На заре первого дня Нового года нефть начали к...   \n",
              "2645        1126  На заре первого дня Нового года нефть начали к...   \n",
              "2646        1127  На заре первого дня Нового года нефть начали к...   \n",
              "2647        1128  На заре первого дня Нового года нефть начали к...   \n",
              "2648        1129  На заре первого дня Нового года нефть начали к...   \n",
              "\n",
              "                                            word_labels  \n",
              "0     O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  \n",
              "1     O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...  \n",
              "2     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...  \n",
              "3                     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "4     O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...  \n",
              "...                                                 ...  \n",
              "2644  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...  \n",
              "2645  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...  \n",
              "2646  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...  \n",
              "2647  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...  \n",
              "2648  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...  \n",
              "\n",
              "[2649 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b3b88e4-3748-4a1f-8b49-a1fe5fdbdffe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>1125</td>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2645</th>\n",
              "      <td>1126</td>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2646</th>\n",
              "      <td>1127</td>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2647</th>\n",
              "      <td>1128</td>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2648</th>\n",
              "      <td>1129</td>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2649 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3b88e4-3748-4a1f-8b49-a1fe5fdbdffe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b3b88e4-3748-4a1f-8b49-a1fe5fdbdffe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b3b88e4-3748-4a1f-8b49-a1fe5fdbdffe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset and dataloader"
      ],
      "metadata": {
        "id": "hUzVT37ex4oR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are imports, most of them are from legacy tries with different mosels and tokenizers."
      ],
      "metadata": {
        "id": "-Pak7EkyrayG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pdb\n",
        "import torch\n",
        "from torch import cuda\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, AutoModelForSeq2SeqLM,  AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "uFwEKUXX5YBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating config dictionary for our model training and evaluating variables.  \n",
        "Theese params are from very last attempt.\n",
        "I've decided to use huge max lenght and small batch size.  \n",
        "This time GPU was avaliable and I've set epochs to 20, all previous attemts I was using 1, 3, 5, or 15.  \n",
        "We will use PyTorch tensors that we provide to our model."
      ],
      "metadata": {
        "id": "VctfuI_Nru5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {#'model_name': \"DeepPavlov/rubert-base-cased\",\n",
        "         'max_length': 512,\n",
        "         'train_batch_size':8,\n",
        "         'valid_batch_size':16,\n",
        "         'epochs':20,\n",
        "         'learning_rate':1e-05,\n",
        "         'max_grad_norm':10,\n",
        "         'device': 'cuda' if cuda.is_available() else 'cpu'}"
      ],
      "metadata": {
        "id": "olDAIYYj56Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {#'model_name': \"DeepPavlov/rubert-base-cased\",\n",
        "         'max_length': 300,\n",
        "         'train_batch_size':16,\n",
        "         'valid_batch_size':16,\n",
        "         'epochs':30,\n",
        "         'learning_rate':1e-05,\n",
        "         'max_grad_norm':10,\n",
        "         'device': 'cuda' if cuda.is_available() else 'cpu'}"
      ],
      "metadata": {
        "id": "Qd1MUYGGBnOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some secondary dict comprehensions for converting str labels to nums."
      ],
      "metadata": {
        "id": "V8prP_GrtFUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_labels = {'B_LOC': 3,\n",
        " 'B_ORG': 1,\n",
        " 'B_PER': 5,\n",
        " 'I_LOC': 4,\n",
        " 'I_ORG': 2,\n",
        " 'I_PER': 6,\n",
        " 'O': 0}\n",
        "\n",
        "labels_to_ids = {v:k for k,v in enumerate(output_labels)}\n",
        "ids_to_labels = {k:v for k,v in enumerate(output_labels)}"
      ],
      "metadata": {
        "id": "LsJDiOMo6K52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Labels to ID ==> {labels_to_ids}\\nID to Labels ==> {ids_to_labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LlYkoP26x_d",
        "outputId": "c09bb603-2712-47b9-fde0-59c6fb14adbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels to ID ==> {'B_LOC': 0, 'B_ORG': 1, 'B_PER': 2, 'I_LOC': 3, 'I_ORG': 4, 'I_PER': 5, 'O': 6}\n",
            "ID to Labels ==> {0: 'B_LOC', 1: 'B_ORG', 2: 'B_PER', 3: 'I_LOC', 4: 'I_ORG', 5: 'I_PER', 6: 'O'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is my most problem in that task.  \n",
        "NER with BERT relies on wordpiece tokenization, rather than word tokenization. So we should also define the labels at the wordpiece-level.\n",
        "\n",
        "1. First approach train the model on the tag labels for the first word piece token of a word. I found discussion about that problem on [GitHub](https://github.com/huggingface/transformers/issues/64#issuecomment-443703063).\n",
        "\n",
        "2. Second approach is to propagate the original label of the word to all of its word pieces. I saw it in NER tutorial with BERT.  \n",
        "\n",
        "3. Third approach is to give the first wordpiece original word label, and then use the label “X” for all subsequent subwords.  \n",
        "***\n",
        "\n",
        "About my PyTorch dataset class.  \n",
        "* Tokenized each sentence;\n",
        "* Special BERT tokens add;\n",
        "* PAD tokens or truncat based on the max length of the model;\n",
        "* Attention mask creation;\n",
        "* Create labels;\n",
        "* Get rid of Word-pieces(tag them with \"-100\" default ignore_index of PyTorch's CrossEntropyLoss).\n"
      ],
      "metadata": {
        "id": "DhCNfRCqzLQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "  def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index].split(\",\")\n",
        "\n",
        "\n",
        "        # We'll use offsets_mapping\" for individual tokens\n",
        "        encoding = self.tokenizer(\n",
        "                             text=sentence,\n",
        "                             add_special_tokens=True,\n",
        "                             pad_to_max_length=True,\n",
        "                             return_attention_mask = True, \n",
        "                             #return_tensors = 'pt',  # off because we need some custom steps before\n",
        "                             return_offsets_mapping=True, \n",
        "                             truncation=True, \n",
        "                             max_length=self.max_len)\n",
        "                           \n",
        "        \n",
        "        labels = [labels_to_ids[label] for label in word_labels] \n",
        "\n",
        "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
        "\n",
        "        i = 0\n",
        "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
        "            if mapping[0] != 0 and mapping[0] != encoding['offset_mapping'][idx-1][1]:\n",
        "                try:\n",
        "                    encoded_labels[idx] = labels[i]\n",
        "                except:\n",
        "                    pass\n",
        "                i += 1\n",
        "            else:\n",
        "                if idx==1:\n",
        "                    encoded_labels[idx] = labels[i]\n",
        "                    i += 1\n",
        "\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.as_tensor(encoded_labels)\n",
        "        \n",
        "        return item\n",
        "\n",
        "  def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "65vzOSVl9r4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Legacy implementation of second aproach to wordpiece problem:"
      ],
      "metadata": {
        "id": "9nVv0_Oe5SYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_worpieces(sentence, text_labels, tokenizer):\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "metadata": {
        "id": "_Jmh3hY05APS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to remove sub-tokens from sentences:"
      ],
      "metadata": {
        "id": "dK__1ZsV6F2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def original_length(sentence, tags):\n",
        "   words = []\n",
        "   words_tags = []\n",
        "   for index, token in enumerate(tokenizer.tokenize(sentence)):\n",
        "       if token.startswith(\"##\"):\n",
        "           if words:\n",
        "               words[-1] = f\"{words[-1]}{token[2:]}\"\n",
        "       else:\n",
        "           words.append(token)\n",
        "           words_tags.append(tags[index])\n",
        "   return words_tags, words"
      ],
      "metadata": {
        "id": "byII7i7k5s52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define our tokenizer and model.\n",
        "My best results were on \"DeepPavlov\" pretrained model, so I leave it as main for me."
      ],
      "metadata": {
        "id": "LXsCRRYx6bdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")  #(\"sberbank-ai/bert-base-NER-reptile-5-datasets\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"DeepPavlov/rubert-base-cased\", num_labels=len(output_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsEz4h2n-dtp",
        "outputId": "8b4a06e5-df5d-4759-8a83-43fb0a65140c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#v = tokenizer.get_vocab()\n",
        "#print(len(v))\n",
        "tokenizer.add_tokens([\"лента.ру\", \"lenta.ru\", \".рф\", \"Кремль.рф\"])\n",
        "#v = tokenizer.get_vocab()\n",
        "#print(len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMO8hSkXCsZ2",
        "outputId": "03086a46-d40b-463b-9139-2f67038f410a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create 2 datasets, one for training and one for testing.\n",
        "That is the one of the last tries, so I'm not using part of train dataset fot evaluation."
      ],
      "metadata": {
        "id": "nfmofDF969mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_df[['sentence', 'word_labels']]\n",
        "train_size = 1\n",
        "train_dataset = data.sample(frac=train_size,random_state=300)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, config['max_length'])\n",
        "testing_set = dataset(test_dataset, tokenizer, config['max_length'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVYId1i0ADg0",
        "outputId": "bcd8cffc-0d1b-4e2d-9dd4-37c1b3189757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (2649, 2)\n",
            "TRAIN Dataset: (2649, 2)\n",
            "TEST Dataset: (0, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zoxC41r9ruqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define PyTorch dataloaders:"
      ],
      "metadata": {
        "id": "hRDCsG-G7sa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': config['train_batch_size'],\n",
        "                'shuffle': True,\n",
        "                'num_workers': 12,\n",
        "                'pin_memory':True\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': config['valid_batch_size'],\n",
        "                'shuffle': True,\n",
        "                'num_workers': 1,\n",
        "                'pin_memory':True\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "#testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "rojHnKDFBUx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d98aaeb-b134-4042-9338-e303e3c4909a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "EbvNGlZ298Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = config['device']"
      ],
      "metadata": {
        "id": "rAC5TjSLBiCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "aM5z6K9tBxAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform a sanity check.  \n",
        "Found that part form [Andrej Karpathy's](http://karpathy.github.io/2019/04/25/recipe/):"
      ],
      "metadata": {
        "id": "yK0OuN5W-N5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "inputs = training_set[2]\n",
        "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
        "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
        "labels = inputs[\"labels\"].unsqueeze(0)\n",
        "\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "outputs = model(input_ids, attention_mask=attention_mask, labels=labels,\n",
        "               return_dict=False)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKY0qe14BlqC",
        "outputId": "3cd1a937-0ee0-4f0e-df81-8741c4dd066e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2858, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define optimizer. I will use Adam."
      ],
      "metadata": {
        "id": "zL7_vLg2-ysI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=config['learning_rate'])"
      ],
      "metadata": {
        "id": "4oxSi2rJB3tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr = 1e-05, eps = 1e-05)"
      ],
      "metadata": {
        "id": "UysH0ja2u98k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define training function:"
      ],
      "metadata": {
        "id": "eMMRBQ3__T7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    model.train()\n",
        "    \n",
        "    for idx, batch in enumerate(training_loader):\n",
        "        \n",
        "        ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "        labels = batch['labels'].to(device, dtype = torch.long)\n",
        "\n",
        "        loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
        "                               return_dict=False)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += labels.size(0)\n",
        "        \n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "           \n",
        "\n",
        "        flattened_targets = labels.view(-1)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "        \n",
        "\n",
        "        active_accuracy = labels.view(-1) != -100\n",
        "        \n",
        "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "        \n",
        "        tr_labels.extend(labels)\n",
        "        tr_preds.extend(predictions)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "    \n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=config['max_grad_norm']\n",
        "        )\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    return epoch_loss, tr_accuracy"
      ],
      "metadata": {
        "id": "7puMvGpIB9pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(config['epochs']):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c94627e-2ed0-41ae-b33e-283604fcf699",
        "id": "d_gWT-BeiWH9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training epoch: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 2.142857551574707\n",
            "Training loss per 100 training steps: 0.5869576957556281\n",
            "Training loss epoch: 0.4213719781353531\n",
            "Training accuracy epoch: 0.8786288937960338\n",
            "Training epoch: 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.07570414245128632\n",
            "Training loss per 100 training steps: 0.0692364245394964\n",
            "Training loss epoch: 0.059170164246426286\n",
            "Training accuracy epoch: 0.9867749639998461\n",
            "Training epoch: 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.033516671508550644\n",
            "Training loss per 100 training steps: 0.026701452205935033\n",
            "Training loss epoch: 0.027839212930839824\n",
            "Training accuracy epoch: 0.9934227990264338\n",
            "Training epoch: 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.008107129484415054\n",
            "Training loss per 100 training steps: 0.01635831383766957\n",
            "Training loss epoch: 0.016972627445875882\n",
            "Training accuracy epoch: 0.9962467240993684\n",
            "Training epoch: 5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.005596899427473545\n",
            "Training loss per 100 training steps: 0.008514431659086137\n",
            "Training loss epoch: 0.009971523923232747\n",
            "Training accuracy epoch: 0.9979124835529326\n",
            "Training epoch: 6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0030499459244310856\n",
            "Training loss per 100 training steps: 0.009503750026797746\n",
            "Training loss epoch: 0.009653655840196165\n",
            "Training accuracy epoch: 0.9976486521217408\n",
            "Training epoch: 7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.00204307003878057\n",
            "Training loss per 100 training steps: 0.005708410087650144\n",
            "Training loss epoch: 0.006079365228266309\n",
            "Training accuracy epoch: 0.998549260309445\n",
            "Training epoch: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0012975574936717749\n",
            "Training loss per 100 training steps: 0.0038592338891663028\n",
            "Training loss epoch: 0.004296842350271048\n",
            "Training accuracy epoch: 0.9990953873132994\n",
            "Training epoch: 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0010179186938330531\n",
            "Training loss per 100 training steps: 0.00312651463526089\n",
            "Training loss epoch: 0.003762679398957505\n",
            "Training accuracy epoch: 0.9991335175338618\n",
            "Training epoch: 10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.001095602405257523\n",
            "Training loss per 100 training steps: 0.0031758587102009225\n",
            "Training loss epoch: 0.0030651621314337902\n",
            "Training accuracy epoch: 0.9994056684391236\n",
            "Training epoch: 11\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0012318568769842386\n",
            "Training loss per 100 training steps: 0.002409905872980852\n",
            "Training loss epoch: 0.0021562416629630128\n",
            "Training accuracy epoch: 0.999626453554027\n",
            "Training epoch: 12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0008079393301159143\n",
            "Training loss per 100 training steps: 0.0014346922804845848\n",
            "Training loss epoch: 0.0012665615576257683\n",
            "Training accuracy epoch: 0.9997390265911325\n",
            "Training epoch: 13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.000515105202794075\n",
            "Training loss per 100 training steps: 0.0016764144152103195\n",
            "Training loss epoch: 0.002153503906307181\n",
            "Training accuracy epoch: 0.9994194962375754\n",
            "Training epoch: 14\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.003394161118194461\n",
            "Training loss per 100 training steps: 0.0021703727696077103\n",
            "Training loss epoch: 0.0022878940048885635\n",
            "Training accuracy epoch: 0.9994693483005728\n",
            "Training epoch: 15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0007221511332318187\n",
            "Training loss per 100 training steps: 0.0014621642280466818\n",
            "Training loss epoch: 0.0012818266816804725\n",
            "Training accuracy epoch: 0.9997461586101973\n",
            "Training epoch: 16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss per 100 training steps: 0.0004776123387273401\n",
            "Training loss per 100 training steps: 0.0012350942628886919\n",
            "Training loss epoch: 0.001302669531348756\n",
            "Training accuracy epoch: 0.9997402899371767\n",
            "Training epoch: 17\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0006849098717793822\n",
            "Training loss per 100 training steps: 0.0018276977081930653\n",
            "Training loss epoch: 0.0015021323111379541\n",
            "Training accuracy epoch: 0.9997792638834755\n",
            "Training epoch: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00046599950292147696\n",
            "Training loss per 100 training steps: 0.001348892081872385\n",
            "Training loss epoch: 0.0013037331194367193\n",
            "Training accuracy epoch: 0.9997144204151251\n",
            "Training epoch: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00038463855162262917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65014f8c"
      },
      "outputs": [],
      "source": [
        "loss_values = []\n",
        "accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "a0ac37c9",
        "outputId": "57128e9b-3827-4bd8-a00a-c702bbca14d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 2.0693516731262207\n",
            "Training loss per 100 training steps: 0.5981796979904175\n",
            "Training loss epoch: 0.43251976523413715\n",
            "Training accuracy epoch: 0.8760758379784107\n",
            "Training epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.06934680789709091\n",
            "Training loss per 100 training steps: 0.06839838203522239\n",
            "Training loss epoch: 0.05977083123232945\n",
            "Training accuracy epoch: 0.9855307465329314\n",
            "Training epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.012506060302257538\n",
            "Training loss per 100 training steps: 0.023693597170127794\n",
            "Training loss epoch: 0.024376734311367016\n",
            "Training accuracy epoch: 0.9942736438403661\n",
            "Training epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.004397862125188112\n",
            "Training loss per 100 training steps: 0.015010371241755414\n",
            "Training loss epoch: 0.015104289069850311\n",
            "Training accuracy epoch: 0.9962865958970354\n",
            "Training epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.031136149540543556\n",
            "Training loss per 100 training steps: 0.010094946189230253\n",
            "Training loss epoch: 0.010187975880661867\n",
            "Training accuracy epoch: 0.9976298676051717\n",
            "Training epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.007388858124613762\n",
            "Training loss per 100 training steps: 0.006702840740857001\n",
            "Training loss epoch: 0.007847577963916427\n",
            "Training accuracy epoch: 0.9980455894863535\n",
            "Training epoch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0028694209177047014\n",
            "Training loss per 100 training steps: 0.00483088498522463\n",
            "Training loss epoch: 0.005122346743234399\n",
            "Training accuracy epoch: 0.9988793929730554\n",
            "Training epoch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0013701057760044932\n",
            "Training loss per 100 training steps: 0.006055873174377081\n",
            "Training loss epoch: 0.005670291106202583\n",
            "Training accuracy epoch: 0.9988267527173135\n",
            "Training epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.008607875555753708\n",
            "Training loss per 100 training steps: 0.004206501259261023\n",
            "Training loss epoch: 0.004625726830991299\n",
            "Training accuracy epoch: 0.9990922326942233\n",
            "Training epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.02879457361996174\n",
            "Training loss per 100 training steps: 0.003238685978322963\n",
            "Training loss epoch: 0.0035256846062418253\n",
            "Training accuracy epoch: 0.9992671510195006\n",
            "Training epoch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0008091614581644535\n",
            "Training loss per 100 training steps: 0.002223868531032032\n",
            "Training loss epoch: 0.0020036753735165618\n",
            "Training accuracy epoch: 0.9997364362163385\n",
            "Training epoch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0014063733397051692\n",
            "Training loss per 100 training steps: 0.0017711114389637468\n",
            "Training loss epoch: 0.0018290051517528426\n",
            "Training accuracy epoch: 0.9996735886637029\n",
            "Training epoch: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0003627391124609858\n",
            "Training loss per 100 training steps: 0.0013820694570457286\n",
            "Training loss epoch: 0.001270617123101333\n",
            "Training accuracy epoch: 0.9997881629585449\n",
            "Training epoch: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00047057316987775266\n",
            "Training loss per 100 training steps: 0.0006570631818555407\n",
            "Training loss epoch: 0.0007679700840570325\n",
            "Training accuracy epoch: 0.9999038794039387\n",
            "Training epoch: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00038015752215869725\n",
            "Training loss per 100 training steps: 0.0014479443105859773\n",
            "Training loss epoch: 0.0013880392493391186\n",
            "Training accuracy epoch: 0.9997062210279722\n",
            "Training epoch: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00033261990756727755\n",
            "Training loss per 100 training steps: 0.0016682479893074067\n",
            "Training loss epoch: 0.001813911555506042\n",
            "Training accuracy epoch: 0.9995646763591785\n",
            "Training epoch: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.02699955925345421\n",
            "Training loss per 100 training steps: 0.001630095115201179\n",
            "Training loss epoch: 0.0016164649232341178\n",
            "Training accuracy epoch: 0.9996097117454276\n",
            "Training epoch: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0005031801993027329\n",
            "Training loss per 100 training steps: 0.000967228710236452\n",
            "Training loss epoch: 0.0008624007888397774\n",
            "Training accuracy epoch: 0.9998083655927499\n",
            "Training epoch: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00029619017732329667\n",
            "Training loss per 100 training steps: 0.0006590041147238381\n",
            "Training loss epoch: 0.0006120303261419197\n",
            "Training accuracy epoch: 0.9999176341242355\n",
            "Training epoch: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00033778726356104016\n",
            "Training loss per 100 training steps: 0.0009227801368763154\n",
            "Training loss epoch: 0.0012211944414015174\n",
            "Training accuracy epoch: 0.9997083930129431\n",
            "Training epoch: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.047631651163101196\n",
            "Training loss per 100 training steps: 0.002344596767504146\n",
            "Training loss epoch: 0.002357884568087925\n",
            "Training accuracy epoch: 0.9993884164013079\n",
            "Training epoch: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0005888501764275134\n",
            "Training loss per 100 training steps: 0.000988919175250714\n",
            "Training loss epoch: 0.0009343663693569791\n",
            "Training accuracy epoch: 0.999819251267043\n",
            "Training epoch: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00040885619819164276\n",
            "Training loss per 100 training steps: 0.0010429899662670835\n",
            "Training loss epoch: 0.0014998680434725527\n",
            "Training accuracy epoch: 0.9996736658210643\n",
            "Training epoch: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00029570472543127835\n",
            "Training loss per 100 training steps: 0.002884106932866092\n",
            "Training loss epoch: 0.002046217308071139\n",
            "Training accuracy epoch: 0.9994983254786052\n",
            "Training epoch: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00027435473748482764\n",
            "Training loss per 100 training steps: 0.0007236668620187107\n",
            "Training loss epoch: 0.0005952661267218057\n",
            "Training accuracy epoch: 0.9998123096581215\n",
            "Training epoch: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00021494242537301034\n",
            "Training loss per 100 training steps: 0.0007990364734219424\n",
            "Training loss epoch: 0.0007677176055226318\n",
            "Training accuracy epoch: 0.9998276005748317\n",
            "Training epoch: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00016681330453138798\n",
            "Training loss per 100 training steps: 0.0008980918449169892\n",
            "Training loss epoch: 0.0008868896772352844\n",
            "Training accuracy epoch: 0.999852877453913\n",
            "Training epoch: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.00025006523355841637\n",
            "Training loss per 100 training steps: 0.001100345579261827\n",
            "Training loss epoch: 0.0011054190557382732\n",
            "Training accuracy epoch: 0.9997671369234887\n",
            "Training epoch: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.001253685331903398\n",
            "Training loss per 100 training steps: 0.00113993421822814\n",
            "Training loss epoch: 0.0011378392330490064\n",
            "Training accuracy epoch: 0.9996531912146578\n",
            "Training epoch: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss per 100 training steps: 0.0015457600820809603\n",
            "Training loss per 100 training steps: 0.0011696905374012905\n",
            "Training loss epoch: 0.0008474284040858038\n",
            "Training accuracy epoch: 0.9998380040104198\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(config['epochs']):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    epoch_loss,tr_accuracy =  train(epoch)\n",
        "    loss_values.append(epoch_loss)\n",
        "    accuracies.append(tr_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8s0NCzRX1_Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "076e6443",
        "outputId": "eaa7733b-fd7f-4427-8c07-e27eaa02db8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(loss_values[5:], 'b-o', label=\"training loss\")\n",
        "\n",
        "plt.title(\"Learning curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "371f9960",
        "outputId": "a714d8fc-fa29-4170-ab9a-510621d5f209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(accuracies[5:], 'r-o', label=\"accuracy\")\n",
        "\n",
        "plt.title(\"Learning curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "ESgCyGxqAgH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['labels'].to(device, dtype = torch.long)\n",
        "            \n",
        "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
        "                                     return_dict=False)\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            flattened_targets = labels.view(-1)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "            \n",
        "\n",
        "            active_accuracy = labels.view(-1) != -100\n",
        "        \n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
        "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "tfq5Yb0CbmLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92EJs6m07aPl"
      },
      "source": [
        "Nice accuracy, but we know that we have lots of \"O\" labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29208b93-807c-43a3-ac67-71c0bfc69e0a",
        "id": "zZtOJAc87aPl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss per 100 evaluation steps: 0.038575027137994766\n",
            "Validation Loss: 0.0726628828989832\n",
            "Validation Accuracy: 0.9767107205138064\n"
          ]
        }
      ],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocehoBG97aPl"
      },
      "outputs": [],
      "source": [
        "valid_df = pd.DataFrame(predictions, index = np.arange(len(labels)), columns=['pred'])\n",
        "valid_true_df = pd.DataFrame(labels, index = np.arange(len(labels)), columns=['true'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f008537b-5226-481d-d1ed-96517a93c485",
        "id": "-C9533IK7aPl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(O        5177\n",
              " B_LOC     204\n",
              " I_ORG     169\n",
              " B_ORG     138\n",
              " B_PER     129\n",
              " I_PER      88\n",
              " I_LOC      26\n",
              " Name: pred, dtype: int64, O        5157\n",
              " B_LOC     201\n",
              " I_ORG     183\n",
              " B_ORG     137\n",
              " B_PER     126\n",
              " I_PER      85\n",
              " I_LOC      42\n",
              " Name: true, dtype: int64)"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "freqs_pred = valid_df.pred.value_counts()\n",
        "freqs_true = valid_true_df.true.value_counts()\n",
        "freqs_pred, freqs_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwd-VtGD7aPl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g41mzNv7aPl"
      },
      "source": [
        "Some metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448b2cbf-0bc3-4e99-d25d-f40e1cfaf200",
        "id": "oGnFxuS77aPm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8640048567884966"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(labels, predictions, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwXf3JBN7aPm"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels, predictions, labels=['B_LOC', 'B_ORG', 'B_PER', 'I_LOC', 'I_ORG', 'I_PER', 'O'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "4edcc8dd-18a1-41f8-cfe6-d0301022d996",
        "id": "LjzBWG3l7aPm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe4627e60d0>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "ax= plt.subplot()\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "#sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix');\n",
        "sn.heatmap(cm, annot=True, fmt='g', ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLxVk8tP7aPm"
      },
      "source": [
        "By label perfomance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5b86ed-8b73-4291-f305-faf2f4c31bfa",
        "id": "XvA3J0o87aPm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B_LOC       0.92      0.93      0.92       201\n",
            "       B_ORG       0.83      0.84      0.84       137\n",
            "       B_PER       0.96      0.98      0.97       126\n",
            "       I_LOC       0.69      0.43      0.53        42\n",
            "       I_ORG       0.86      0.79      0.82       183\n",
            "       I_PER       0.95      0.99      0.97        85\n",
            "           O       0.99      0.99      0.99      5157\n",
            "\n",
            "    accuracy                           0.98      5931\n",
            "   macro avg       0.89      0.85      0.86      5931\n",
            "weighted avg       0.98      0.98      0.98      5931\n",
            "\n"
          ]
        }
      ],
      "source": [
        "a = classification_report(labels, predictions, target_names=['B_LOC', 'B_ORG', 'B_PER', 'I_LOC', 'I_ORG', 'I_PER', 'O'])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "3pPi8m_LCg_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, lets define inference function and get our submission."
      ],
      "metadata": {
        "id": "bNToAIBzEMCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "def inference(sentence):\n",
        "    inputs = tokenizer(sentence,\n",
        "#                         is_split_into_words=True, \n",
        "                        return_offsets_mapping=True, \n",
        "                        padding='max_length', \n",
        "                        truncation=True, \n",
        "                        max_length=config['max_length'],\n",
        "                        return_tensors=\"pt\")\n",
        "\n",
        "    ids = inputs[\"input_ids\"].to(device)\n",
        "    mask = inputs[\"attention_mask\"].to(device)\n",
        "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
        "    logits = outputs[0]\n",
        "\n",
        "    active_logits = logits.view(-1, model.num_labels)\n",
        "    flattened_predictions = torch.argmax(active_logits, axis=1)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
        "    wp_preds = list(zip(tokens, token_predictions))\n",
        "\n",
        "    prediction = []\n",
        "    out_str = []\n",
        "    off_list = inputs[\"offset_mapping\"].squeeze().tolist()\n",
        "    for idx, mapping in enumerate(off_list):\n",
        "\n",
        "\n",
        "#         only predictions on first word pieces are important\n",
        "        if mapping[0] != 0 and mapping[0] != off_list[idx-1][1]:\n",
        "            prediction.append(wp_preds[idx][1])\n",
        "            out_str.append(wp_preds[idx][0])\n",
        "        else:\n",
        "            if idx == 1:\n",
        "                prediction.append(wp_preds[idx][1])\n",
        "                out_str.append(wp_preds[idx][0])\n",
        "            continue\n",
        "    return prediction, out_str"
      ],
      "metadata": {
        "id": "s_TGbOzecRBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading our test data:"
      ],
      "metadata": {
        "id": "zgjEDLLWEo-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = pd.read_csv(\"/content/drive/MyDrive/kaggle HW2/test.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "4lYDfCsjz4rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kLxUOOtR0Fts",
        "outputId": "c895fbc2-73e7-43a4-86b7-1efcfe9afc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf\n",
              "0                                  Александр Вертинский  False\n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False\n",
              "2                Слишком много « пустого » пространства   True\n",
              "3                  И он научился заполнять его вымыслом   True\n",
              "4     Создал собственный театр с безумным множеством...   True\n",
              "...                                                 ...    ...\n",
              "2709  В частности , мы исключили большинство эксперт...   True\n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True\n",
              "2711  Также один из законов , который принят в этом ...  False\n",
              "2712    Там соответственно тоже все поручения выполнены   True\n",
              "2713                                 В . Путин : Хорошо  False\n",
              "\n",
              "[2714 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a00430fc-601b-4b0f-8ec6-091a71cd8d36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a00430fc-601b-4b0f-8ec6-091a71cd8d36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a00430fc-601b-4b0f-8ec6-091a71cd8d36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a00430fc-601b-4b0f-8ec6-091a71cd8d36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['predict'] = test_texts['text'].apply(inference)"
      ],
      "metadata": {
        "id": "aNU4tj4S6-xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame(test_texts['predict'].to_list(), columns=['pred_labels','pred_words'])"
      ],
      "metadata": {
        "id": "s0LGekPV-YUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at our predictions:"
      ],
      "metadata": {
        "id": "iXp2x0CQEyMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fmSbpraZ-FUo",
        "outputId": "833283bd-73cd-4190-a879-56b1b63268f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            pred_labels  \\\n",
              "0                                        [B_PER, I_PER]   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2                                    [O, O, O, O, O, O]   \n",
              "3                                    [O, O, O, O, O, O]   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "...                                                 ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2712                                 [O, O, O, O, O, O]   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]   \n",
              "\n",
              "                                             pred_words  \n",
              "0                                     [Александр, Верт]  \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...  \n",
              "2         [Слишком, много, «, пустого, », пространства]  \n",
              "3                 [И, он, научился, заполня, его, вымы]  \n",
              "4     [Создал, собственный, театр, с, безум, множест...  \n",
              "...                                                 ...  \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...  \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...  \n",
              "2711  [Также, один, из, законов, ,, который, принят,...  \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...  \n",
              "2713                           [В, ., Путин, :, Хорошо]  \n",
              "\n",
              "[2714 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7281245-db66-46f1-ba15-6e6180bc7ef8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_labels</th>\n",
              "      <th>pred_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>[Александр, Верт]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>[И, он, научился, заполня, его, вымы]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[Создал, собственный, театр, с, безум, множест...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7281245-db66-46f1-ba15-6e6180bc7ef8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7281245-db66-46f1-ba15-6e6180bc7ef8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7281245-db66-46f1-ba15-6e6180bc7ef8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing for kaggle submission"
      ],
      "metadata": {
        "id": "jXbSqyXxE_yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['predicted_labels'] = df3['pred_labels']\n",
        "#test_texts['predicted_words'] = df3['pred_labels']"
      ],
      "metadata": {
        "id": "GUcuSowYBONC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "jKGMqqIGBh3b",
        "outputId": "170b9ca8-5e1b-473e-befd-362867a07d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  \n",
              "0                                        [B_PER, I_PER]  \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "2                                    [O, O, O, O, O, O]  \n",
              "3                                    [O, O, O, O, O, O]  \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "...                                                 ...  \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "2712                                 [O, O, O, O, O, O]  \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]  \n",
              "\n",
              "[2714 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6228a4e4-2310-4216-8237-5c3f05cab03b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6228a4e4-2310-4216-8237-5c3f05cab03b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6228a4e4-2310-4216-8237-5c3f05cab03b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6228a4e4-2310-4216-8237-5c3f05cab03b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['lbs_len'] = test_texts['predicted_labels'].str.len()\n",
        "test_texts['st_text'] = test_texts['text'].str.split()\n",
        "test_texts['st_len'] = test_texts['st_text'].str.len()\n",
        "#train['lb_len'] = train['lbs'].str.len()\n",
        "#train['pos_len'] = train['pos'].str.len()\n",
        "#train['lemm_len'] = train['lemm'].str.len()"
      ],
      "metadata": {
        "id": "078FPTT44ulk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wFscZu215i9i",
        "outputId": "185df8c5-0d26-4be5-f7d1-987e118a3251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  lbs_len  \\\n",
              "0                                        [B_PER, I_PER]        2   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       46   \n",
              "2                                    [O, O, O, O, O, O]        6   \n",
              "3                                    [O, O, O, O, O, O]        6   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "...                                                 ...      ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       25   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       23   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "2712                                 [O, O, O, O, O, O]        6   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]        5   \n",
              "\n",
              "                                                st_text  st_len  \n",
              "0                               [Александр, Вертинский]       2  \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...      46  \n",
              "2         [Слишком, много, «, пустого, », пространства]       6  \n",
              "3           [И, он, научился, заполнять, его, вымыслом]       6  \n",
              "4     [Создал, собственный, театр, с, безумным, множ...      28  \n",
              "...                                                 ...     ...  \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...      25  \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...      23  \n",
              "2711  [Также, один, из, законов, ,, который, принят,...      28  \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...       6  \n",
              "2713                           [В, ., Путин, :, Хорошо]       5  \n",
              "\n",
              "[2714 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff6949c7-4f3b-48e6-ab8d-03d874ef7954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>lbs_len</th>\n",
              "      <th>st_text</th>\n",
              "      <th>st_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff6949c7-4f3b-48e6-ab8d-03d874ef7954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff6949c7-4f3b-48e6-ab8d-03d874ef7954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff6949c7-4f3b-48e6-ab8d-03d874ef7954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['preds_str'] = test_texts['predicted_labels'].apply(\" \".join)"
      ],
      "metadata": {
        "id": "3Wr_sJNf6v-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "nWrgBOjw7DJl",
        "outputId": "4a73d4bc-cab4-4e8d-c4dc-8d7cc1837e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  lbs_len  \\\n",
              "0                                        [B_PER, I_PER]        2   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       46   \n",
              "2                                    [O, O, O, O, O, O]        6   \n",
              "3                                    [O, O, O, O, O, O]        6   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "...                                                 ...      ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       25   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       23   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "2712                                 [O, O, O, O, O, O]        6   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]        5   \n",
              "\n",
              "                                                st_text  st_len  \\\n",
              "0                               [Александр, Вертинский]       2   \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...      46   \n",
              "2         [Слишком, много, «, пустого, », пространства]       6   \n",
              "3           [И, он, научился, заполнять, его, вымыслом]       6   \n",
              "4     [Создал, собственный, театр, с, безумным, множ...      28   \n",
              "...                                                 ...     ...   \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...      25   \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...      23   \n",
              "2711  [Также, один, из, законов, ,, который, принят,...      28   \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...       6   \n",
              "2713                           [В, ., Путин, :, Хорошо]       5   \n",
              "\n",
              "                                              preds_str  \n",
              "0                                           B_PER I_PER  \n",
              "1     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2                                           O O O O O O  \n",
              "3                                           O O O O O O  \n",
              "4     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "...                                                 ...  \n",
              "2709  O O O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2710      O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2711  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2712                                        O O O O O O  \n",
              "2713                              B_PER I_PER I_PER O O  \n",
              "\n",
              "[2714 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-377250ed-74f5-40d9-8145-3e097c5aa4c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>lbs_len</th>\n",
              "      <th>st_text</th>\n",
              "      <th>st_len</th>\n",
              "      <th>preds_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "      <td>B_PER I_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "      <td>B_PER I_PER I_PER O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-377250ed-74f5-40d9-8145-3e097c5aa4c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-377250ed-74f5-40d9-8145-3e097c5aa4c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-377250ed-74f5-40d9-8145-3e097c5aa4c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = test_texts.text.str.split(expand=True).stack()\n",
        "labels = test_texts.preds_str.str.split(expand=True).stack()\n",
        "\n",
        "s = pd.DataFrame({\n",
        "    'Sentence': words.index.get_level_values(0) + 1, \n",
        "    'Word': words.values,\n",
        "    'Label': labels.values,\n",
        "})\n",
        "s.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ms_yhBN-B35s",
        "outputId": "c7fade72-bc4d-4bb3-8f49-4a43259fe4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence        Word  Label\n",
              "0         1   Александр  B_PER\n",
              "1         1  Вертинский  I_PER\n",
              "2         2           «      O\n",
              "3         2           Я      O\n",
              "4         2          не      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9bacd44-4a2b-4b69-9e85-1aabe9c714dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Александр</td>\n",
              "      <td>B_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Вертинский</td>\n",
              "      <td>I_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>«</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Я</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>не</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9bacd44-4a2b-4b69-9e85-1aabe9c714dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9bacd44-4a2b-4b69-9e85-1aabe9c714dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9bacd44-4a2b-4b69-9e85-1aabe9c714dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.to_csv(\"my_submission.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "PWI7tqEoEpur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['len_labels'] = test_texts['predicted_labels'].str.len()"
      ],
      "metadata": {
        "id": "nLTIHuuwCahY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['word_sent'] = test_texts['text'].str.split()"
      ],
      "metadata": {
        "id": "YiE4zHZCDB4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['len_sentence'] = test_texts['word_sent'].str.len()\n",
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "zod1965WDaBY",
        "outputId": "606adf59-171d-485f-94f4-7dd2ef38fcfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  lbs_len  \\\n",
              "0                                        [B_PER, I_PER]        2   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       46   \n",
              "2                                    [O, O, O, O, O, O]        6   \n",
              "3                                    [O, O, O, O, O, O]        6   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "...                                                 ...      ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       25   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       23   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "2712                                 [O, O, O, O, O, O]        6   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]        5   \n",
              "\n",
              "                                                st_text  st_len  \\\n",
              "0                               [Александр, Вертинский]       2   \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...      46   \n",
              "2         [Слишком, много, «, пустого, », пространства]       6   \n",
              "3           [И, он, научился, заполнять, его, вымыслом]       6   \n",
              "4     [Создал, собственный, театр, с, безумным, множ...      28   \n",
              "...                                                 ...     ...   \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...      25   \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...      23   \n",
              "2711  [Также, один, из, законов, ,, который, принят,...      28   \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...       6   \n",
              "2713                           [В, ., Путин, :, Хорошо]       5   \n",
              "\n",
              "                                              preds_str  len_labels  \\\n",
              "0                                           B_PER I_PER           2   \n",
              "1     O O O O O O O O O O O O O O O O O O O O O O O ...          46   \n",
              "2                                           O O O O O O           6   \n",
              "3                                           O O O O O O           6   \n",
              "4     O O O O O O O O O O O O O O O O O O O O O O O ...          28   \n",
              "...                                                 ...         ...   \n",
              "2709  O O O O O O O O O O O O O O O O O O O O O O O O O          25   \n",
              "2710      O O O O O O O O O O O O O O O O O O O O O O O          23   \n",
              "2711  O O O O O O O O O O O O O O O O O O O O O O O ...          28   \n",
              "2712                                        O O O O O O           6   \n",
              "2713                              B_PER I_PER I_PER O O           5   \n",
              "\n",
              "                                              word_sent  len_sentence  \n",
              "0                               [Александр, Вертинский]             2  \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...            46  \n",
              "2         [Слишком, много, «, пустого, », пространства]             6  \n",
              "3           [И, он, научился, заполнять, его, вымыслом]             6  \n",
              "4     [Создал, собственный, театр, с, безумным, множ...            28  \n",
              "...                                                 ...           ...  \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...            25  \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...            23  \n",
              "2711  [Также, один, из, законов, ,, который, принят,...            28  \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...             6  \n",
              "2713                           [В, ., Путин, :, Хорошо]             5  \n",
              "\n",
              "[2714 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9d204bd-65ee-43f3-9ed6-a0f5a1c751f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>lbs_len</th>\n",
              "      <th>st_text</th>\n",
              "      <th>st_len</th>\n",
              "      <th>preds_str</th>\n",
              "      <th>len_labels</th>\n",
              "      <th>word_sent</th>\n",
              "      <th>len_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "      <td>B_PER I_PER</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "      <td>B_PER I_PER I_PER O O</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9d204bd-65ee-43f3-9ed6-a0f5a1c751f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9d204bd-65ee-43f3-9ed6-a0f5a1c751f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9d204bd-65ee-43f3-9ed6-a0f5a1c751f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = test_texts[(test_texts['len_sentence'] != test_texts['len_labels'])]"
      ],
      "metadata": {
        "id": "i8sFn06BEOq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "bLsR4IpHFVte",
        "outputId": "a9c164f1-35b2-476f-9dfb-59488ecb3333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, clf, predict, predicted_labels, len_labels, word_sent, len_sentence]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5294311-7d72-40a5-b5eb-17ec95cf2001\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>len_labels</th>\n",
              "      <th>word_sent</th>\n",
              "      <th>len_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5294311-7d72-40a5-b5eb-17ec95cf2001')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5294311-7d72-40a5-b5eb-17ec95cf2001 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5294311-7d72-40a5-b5eb-17ec95cf2001');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['str_pred_labels'] = test_texts['predicted_labels'].apply(\" \".join)"
      ],
      "metadata": {
        "id": "g4_0Uxt3DSz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "3PKjlQNxD_E-",
        "outputId": "788d89ec-d362-413b-9dac-6650f959b8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  lbs_len  \\\n",
              "0                                        [B_PER, I_PER]        2   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       46   \n",
              "2                                    [O, O, O, O, O, O]        6   \n",
              "3                                    [O, O, O, O, O, O]        6   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "...                                                 ...      ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       25   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       23   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...       28   \n",
              "2712                                 [O, O, O, O, O, O]        6   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]        5   \n",
              "\n",
              "                                                st_text  st_len  \\\n",
              "0                               [Александр, Вертинский]       2   \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...      46   \n",
              "2         [Слишком, много, «, пустого, », пространства]       6   \n",
              "3           [И, он, научился, заполнять, его, вымыслом]       6   \n",
              "4     [Создал, собственный, театр, с, безумным, множ...      28   \n",
              "...                                                 ...     ...   \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...      25   \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...      23   \n",
              "2711  [Также, один, из, законов, ,, который, принят,...      28   \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...       6   \n",
              "2713                           [В, ., Путин, :, Хорошо]       5   \n",
              "\n",
              "                                              preds_str  len_labels  \\\n",
              "0                                           B_PER I_PER           2   \n",
              "1     O O O O O O O O O O O O O O O O O O O O O O O ...          46   \n",
              "2                                           O O O O O O           6   \n",
              "3                                           O O O O O O           6   \n",
              "4     O O O O O O O O O O O O O O O O O O O O O O O ...          28   \n",
              "...                                                 ...         ...   \n",
              "2709  O O O O O O O O O O O O O O O O O O O O O O O O O          25   \n",
              "2710      O O O O O O O O O O O O O O O O O O O O O O O          23   \n",
              "2711  O O O O O O O O O O O O O O O O O O O O O O O ...          28   \n",
              "2712                                        O O O O O O           6   \n",
              "2713                              B_PER I_PER I_PER O O           5   \n",
              "\n",
              "                                              word_sent  len_sentence  \\\n",
              "0                               [Александр, Вертинский]             2   \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...            46   \n",
              "2         [Слишком, много, «, пустого, », пространства]             6   \n",
              "3           [И, он, научился, заполнять, его, вымыслом]             6   \n",
              "4     [Создал, собственный, театр, с, безумным, множ...            28   \n",
              "...                                                 ...           ...   \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...            25   \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...            23   \n",
              "2711  [Также, один, из, законов, ,, который, принят,...            28   \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...             6   \n",
              "2713                           [В, ., Путин, :, Хорошо]             5   \n",
              "\n",
              "                                        str_pred_labels  \n",
              "0                                           B_PER I_PER  \n",
              "1     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2                                           O O O O O O  \n",
              "3                                           O O O O O O  \n",
              "4     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "...                                                 ...  \n",
              "2709  O O O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2710      O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2711  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2712                                        O O O O O O  \n",
              "2713                              B_PER I_PER I_PER O O  \n",
              "\n",
              "[2714 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3c8b12f-f34b-4904-bb62-782bbb5bec86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>lbs_len</th>\n",
              "      <th>st_text</th>\n",
              "      <th>st_len</th>\n",
              "      <th>preds_str</th>\n",
              "      <th>len_labels</th>\n",
              "      <th>word_sent</th>\n",
              "      <th>len_sentence</th>\n",
              "      <th>str_pred_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "      <td>B_PER I_PER</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "      <td>B_PER I_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "      <td>B_PER I_PER I_PER O O</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "      <td>B_PER I_PER I_PER O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3c8b12f-f34b-4904-bb62-782bbb5bec86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3c8b12f-f34b-4904-bb62-782bbb5bec86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3c8b12f-f34b-4904-bb62-782bbb5bec86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define encode function for submission."
      ],
      "metadata": {
        "id": "LC3T2pNHv90e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(sentence):\n",
        "    labels_dict = {\n",
        "    'O': 1,\n",
        "    'B_ORG': 2,\n",
        "    'I_ORG': 3,\n",
        "    'B_LOC': 4,\n",
        "    'I_LOC': 5,\n",
        "    'B_PER': 6,\n",
        "    'I_PER': 7\n",
        "}\n",
        "    return labels_dict[sentence]"
      ],
      "metadata": {
        "id": "o4QJ0cardct-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(\"my_submission.csv\", sep=\"\\t\")\n",
        "sub['Predicted'] = sub['Label'].apply(encode)\n",
        "sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tOMvyHDYcPMq",
        "outputId": "fb0c1c47-b139-47f0-8f4f-524a8c7525b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  Sentence        Word  Label  Predicted\n",
              "0               0         1   Александр  B_PER          6\n",
              "1               1         1  Вертинский  I_PER          7\n",
              "2               2         2           «      O          1\n",
              "3               3         2           Я      O          1\n",
              "4               4         2          не      O          1\n",
              "...           ...       ...         ...    ...        ...\n",
              "56404       56404      2714           В  B_PER          6\n",
              "56405       56405      2714           .  I_PER          7\n",
              "56406       56406      2714       Путин  I_PER          7\n",
              "56407       56407      2714           :      O          1\n",
              "56408       56408      2714      Хорошо      O          1\n",
              "\n",
              "[56409 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfd20e77-b633-45f2-8fa8-c8e56f51aa89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Александр</td>\n",
              "      <td>B_PER</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Вертинский</td>\n",
              "      <td>I_PER</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>«</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Я</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>не</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56404</th>\n",
              "      <td>56404</td>\n",
              "      <td>2714</td>\n",
              "      <td>В</td>\n",
              "      <td>B_PER</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56405</th>\n",
              "      <td>56405</td>\n",
              "      <td>2714</td>\n",
              "      <td>.</td>\n",
              "      <td>I_PER</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56406</th>\n",
              "      <td>56406</td>\n",
              "      <td>2714</td>\n",
              "      <td>Путин</td>\n",
              "      <td>I_PER</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56407</th>\n",
              "      <td>56407</td>\n",
              "      <td>2714</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56408</th>\n",
              "      <td>56408</td>\n",
              "      <td>2714</td>\n",
              "      <td>Хорошо</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56409 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfd20e77-b633-45f2-8fa8-c8e56f51aa89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfd20e77-b633-45f2-8fa8-c8e56f51aa89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfd20e77-b633-45f2-8fa8-c8e56f51aa89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_alfa = sub['Predicted']"
      ],
      "metadata": {
        "id": "6uTAdtaaeZjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_alfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEYEZpu8elfx",
        "outputId": "2ea969f3-82fc-4dcb-9ef9-86938bb4383c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        6\n",
              "1        7\n",
              "2        1\n",
              "3        1\n",
              "4        1\n",
              "        ..\n",
              "56404    6\n",
              "56405    7\n",
              "56406    7\n",
              "56407    1\n",
              "56408    1\n",
              "Name: Predicted, Length: 56409, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_alfa.to_csv(\"sample_submission_eps.csv\", sep=\",\", index_label=\"Id\")\n"
      ],
      "metadata": {
        "id": "-HO4g-treYw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"/content/sample_submission.csv\", sep=\",\")"
      ],
      "metadata": {
        "id": "PnjAz9qdfINY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cwi9KbMsfSek",
        "outputId": "49d6d414-f4b0-4808-df04-d61be2cc2c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Id  Predicted\n",
              "0          0          6\n",
              "1          1          7\n",
              "2          2          1\n",
              "3          3          1\n",
              "4          4          1\n",
              "...      ...        ...\n",
              "56404  56404          6\n",
              "56405  56405          7\n",
              "56406  56406          7\n",
              "56407  56407          1\n",
              "56408  56408          1\n",
              "\n",
              "[56409 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-371f3ab5-54c0-49dd-8383-5c526faac603\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56404</th>\n",
              "      <td>56404</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56405</th>\n",
              "      <td>56405</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56406</th>\n",
              "      <td>56406</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56407</th>\n",
              "      <td>56407</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56408</th>\n",
              "      <td>56408</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56409 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-371f3ab5-54c0-49dd-8383-5c526faac603')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-371f3ab5-54c0-49dd-8383-5c526faac603 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-371f3ab5-54c0-49dd-8383-5c526faac603');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Legacy code"
      ],
      "metadata": {
        "id": "Ty7uVyma351k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XHf-YuBf38z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "            \n",
        "            ids = batch['input_ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['attention_mask'].to(device, dtype = torch.long)\n",
        "            labels = batch['labels'].to(device, dtype = torch.long)\n",
        "            \n",
        "            loss, eval_logits = model(input_ids=ids, attention_mask=mask, labels=labels,\n",
        "                                     return_dict=False)\n",
        "            \n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += labels.size(0)\n",
        "        \n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "              \n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = labels.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            \n",
        "            # only compute accuracy at active labels\n",
        "            active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "        \n",
        "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            \n",
        "            eval_labels.extend(labels)\n",
        "            eval_preds.extend(predictions)\n",
        "            \n",
        "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    labels = [ids_to_labels[id.item()] for id in eval_labels]\n",
        "    predictions = [ids_to_labels[id.item()] for id in eval_preds]\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "K0waBJr_39MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29208b93-807c-43a3-ac67-71c0bfc69e0a",
        "id": "mxQ80oTG39MA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.038575027137994766\n",
            "Validation Loss: 0.0726628828989832\n",
            "Validation Accuracy: 0.9767107205138064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df = pd.DataFrame(predictions, index = np.arange(len(labels)), columns=['pred'])\n",
        "valid_true_df = pd.DataFrame(labels, index = np.arange(len(labels)), columns=['true'])"
      ],
      "metadata": {
        "id": "1Hnk1TA239MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5fb255e5-279a-4cb3-edff-2aa49576b0d7",
        "id": "GqKWzl-L39MB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pred\n",
              "0         O\n",
              "1         O\n",
              "2     B_PER\n",
              "3         O\n",
              "4         O\n",
              "...     ...\n",
              "5926      O\n",
              "5927      O\n",
              "5928      O\n",
              "5929  B_PER\n",
              "5930  I_PER\n",
              "\n",
              "[5931 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36873323-2aa4-41e7-b86e-62a7c8e35bb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5926</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5927</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5928</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5929</th>\n",
              "      <td>B_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5930</th>\n",
              "      <td>I_PER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5931 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36873323-2aa4-41e7-b86e-62a7c8e35bb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36873323-2aa4-41e7-b86e-62a7c8e35bb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36873323-2aa4-41e7-b86e-62a7c8e35bb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs_pred = valid_df.pred.value_counts()\n",
        "freqs_true = valid_true_df.true.value_counts()\n",
        "freqs_pred, freqs_true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f008537b-5226-481d-d1ed-96517a93c485",
        "id": "fHU6M3WQ39MB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(O        5177\n",
              " B_LOC     204\n",
              " I_ORG     169\n",
              " B_ORG     138\n",
              " B_PER     129\n",
              " I_PER      88\n",
              " I_LOC      26\n",
              " Name: pred, dtype: int64, O        5157\n",
              " B_LOC     201\n",
              " I_ORG     183\n",
              " B_ORG     137\n",
              " B_PER     126\n",
              " I_PER      85\n",
              " I_LOC      42\n",
              " Name: true, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "nKuZRjZM39MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(labels, predictions, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448b2cbf-0bc3-4e99-d25d-f40e1cfaf200",
        "id": "MSZDxHkF39MB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8640048567884966"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(labels, predictions, labels=['B_LOC', 'B_ORG', 'B_PER', 'I_LOC', 'I_ORG', 'I_PER', 'O'])"
      ],
      "metadata": {
        "id": "3bHFt4T539MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "ax= plt.subplot()\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4) # for label size\n",
        "#sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix');\n",
        "sn.heatmap(cm, annot=True, fmt='g', ax=ax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "4edcc8dd-18a1-41f8-cfe6-d0301022d996",
        "id": "-aAML0Ma39MB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe4627e60d0>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEUCAYAAAAstV3AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd1iT1/uHb1ZAmeLAgaAiUBXqwlkVt3W2glVBXHVr1boHSqtV67Z8rXtvK2oduOrGqrjFOqoMRVHECQERwsjvj/xIjUEIMhLl3Nf1Xhc553nP+XCSPDnvc5aeXC6XIxAIBIJCg762BQgEAoGgYBGOXyAQCAoZwvELBAJBIUM4foFAIChkCMcvEAgEhQzh+AUCgaCQIRy/gLdv3+Ln50ejRo1wdnZm5syZeV5H8+bNmThxYp6X+ykj2kSgLQy1LUCg4NWrV6xdu5aTJ0/y+PFj5HI5dnZ2uLu707NnT2xsbPKt7nXr1rFjxw6GDBlChQoVcHBwyLe6CpqoqChatGgBwIgRIxg2bJiazeTJk9m1axcAd+/ezXEdp0+f5saNGwwfPjx3YgWCAkJPLODSPrdu3WLAgAHEx8fToUMHXF1d0dfX5+7duxw8eBArKyuOHDmSb/X36dOH2NhY9uzZk291yGQy9PT0MDIyyrc6MiPD8RsbG2Nra8vBgwfVdDVs2BCZTEZycvJHOf7p06ezZcuWHN+rrTYRCESPX8vEx8cre6G7d+/G0dFRJX/06NGsWrUqXzW8fPkSKyurfK1DIpHka/nZ4e7uzl9//cXt27epWrWqMv3UqVO8efOGFi1acPTo0XzXIZfLSU5OxsTEROttIii8iBi/ltm+fTvR0dFMmDBBzekDmJubM3r0aJW0I0eO4OHhwZdffkm9evUYPXo0T548UbGZOHEirq6uxMTEMHToUGrWrEn9+vWZM2cOaWlpAFy4cAFnZ2fu3bvHxYsXcXZ2xtnZmaioKHbv3q38+10y7rlw4YIyLTIykpEjR9KoUSNcXFxo1KgRw4cP59mzZ0qbzOLZr169YurUqXz11Ve4urrSoUMHduzYoWITFRWFs7MzK1euZMeOHbRs2RIXFxc8PT25ceOGxu3s6upKhQoV2L9/v0r6/v37qVu3LqVKlVK75/jx4wwePJgmTZrg4uJCs2bNmDNnDsnJySrtvGXLFgBl+73bbs7Ozvj5+XHw4EE6duyIq6ur8qnj/TaZOHEiLi4uak8OI0aMoGbNmjx8+FDj/1cgyArR49cyJ06cwNjYmLZt22pkv3fvXsaPH0+1atUYPXo0r1+/ZuPGjVy5coU///wTa2trpa1cLqd///64uroyfvx4zp8/z9q1aylfvjze3t44ODgwd+5cFi5cSNGiRRk8eDCAShnZkZKSQr9+/UhKSsLb25uSJUvy/Plzzpw5w7NnzzJ1qADJycn07t2biIgIvL29sbOz49ixY0ydOpXY2FgGDhyoYn/w4EESExPp1q0benp6rF69muHDh3Ps2DGNQyXt27dn586djBs3Dn19feLj4zl16hR+fn7cuXNHzX737t1IJBJ69uyJubk5ISEhbNiwgadPn7Jo0SIAunXrxrNnzzh79ixz585V3vtuG16+fJkjR47g4+NDiRIlqFSpUqb6fH19CQ4OZsKECQQEBGBkZMS+ffs4cuQIP/30E3Z2dhr9nwJBtsgFWqVOnTryTp06aWQrk8nkDRs2lLdt21b+9u1bZXpwcLDcyclJPnv2bGXahAkT5E5OTvLFixerlPHtt9/KO3furJLWvn17uY+Pj0rarl275E5OTvJHjx6ppGfUFRwcLJfL5fI7d+7InZyc5IcOHcpSe7NmzeQTJkxQvt6wYYPcyclJvnv3bmVaamqqvHfv3nIXFxf5q1ev5HK5XP7o0SO5k5OTvG7duvLY2Fil7bFjx+ROTk7yEydOZFlvxv0rVqyQh4eHy52cnOTnz5+Xy+VyeUBAgNzFxUUeFxcnnzZtmtzJyUnl3sTERLXyli1bJnd2dpY/efJEmZbZvRk4OTnJnZ2d5bdv3862TeRyufzcuXNyZ2dn+aJFi+RPnz6Vu7m5yfv27Zvl/ygQ5BQR6tEyCQkJmJqaamR78+ZNXrx4gZeXFyYmJsr0evXqUa1aNU6dOqV2T9euXVVe165dWy18kxsytP/9998kJiZqfN/p06extramU6dOyjQDAwN69+6NTCbj/PnzKvZt2rTB0tJS+drNzQ2AR48eaVxnpUqVqFatGoGBgQAEBgbStGlTLCwsMrUvUqQIAOnp6cTHx/Pq1Stq166NXC7n1q1bGtdbs2ZNqlSpopFtgwYN8PHxYdWqVQwZMgS5XM6sWbM0rksg0ATh+LWMmZkZb9680cg2I45fsWJFtTwHBwceP36skmZkZKQWarG0tCQuLu4j1apTvnx5+vbtS0BAAPXr16dPnz5s2LCB169fZ3nf48ePsbe3x8DAQCU9Yyrp+z9OZcqUUXmd8SMglUpzpLdDhw4cOXKEqKgoLly4QIcOHT5oe+/ePQYMGEDNmjVxc3NTOmVQ/GBrSk5DNGPHjqVkyZLcunWLSZMmUbp06RzdLxBkh3D8WqZSpUrcv38fmUyW52Xr6enl+b3p6elqaRMnTiQwMJBhw4aRlpbGnDlzaNu2LWFhYR9d//u8/wORgTyHs5Hbt29PQkICkyZNwtTUlGbNmmVqFx8fT69evQgPD2fUqFEsW7aMdevWMXv2bCDzdvgQxsbGOdJ49+5d5cD4vXv3cnSvQKAJwvFrmebNm5OcnMzhw4eztS1btiwA9+/fV8uLiIigXLlyeaYrI/wRHx+vkv7+U0UGjo6ODBo0iE2bNrF7927i4+NZv379B8svV64ckZGRyhlGGURERABga2ubC/UfxsbGBjc3Ny5evEirVq0+OKXywoULvH79mtmzZ9OnTx+aN29Ow4YNMx2szs0P7PskJSUxfvx4ypcvj4+PDxs3buTSpUt5Vr5AAMLxa53u3btjY2PDnDlzCA8PV8tPSEhQziBxcXGhRIkS/PHHHypTCi9fvszNmzdp2rRpnunKCE+863TS0tLUplsmJCSQmpqqkubg4ICxsXGWYZimTZvy6tUrlemV6enpbNy4EYlEQoMGDfLi38iUkSNH8sMPP9CnT58P2ujrK74a7z5RpKens27dOjXbjLGAvAihzZ8/n0ePHjFnzhwmTJiAg4MDkyZNytH4iUCQHWI6p5axsLBgyZIlDBw4kM6dO6us3A0NDSUwMBBLS0tGjRqFkZER48aNY8KECXh7e9OpUydevXrFpk2bsLGxYcCAAXmmy9HRkRo1arBw4ULi4uKwtLTk4MGDak4+ODiYadOm0aZNG+XYw8GDB3nz5g3t2rX7YPldu3Zlx44dTJkyhTt37lC+fHmOHTvG+fPnGTNmDMWKFcuz/+V93NzclIPDH6JWrVpYWVkxceJEfHx8MDQ05MiRI5k6YBcXF0CxgrdJkyYYGhrSrFkzihYtmiNdFy5cYPPmzQwYMIAaNWoAMGfOHLp27cqcOXOYNm1ajsoTCD6EcPw6gKurK4GBgcq9eg4cOIBcLsfe3p5u3brRs2dPpe23335LkSJFWLFiBfPnz6dIkSK4u7szduzYHM2/14T58+fj5+fHypUrsbCwoEuXLtSrV4++ffsqbZydnWnSpAlBQUEEBARgbGxM5cqVWbJkCS1btvxg2cbGxmzYsIGFCxeyf/9+pFIp9vb2/PLLL2ozkbSBlZUVK1euZPbs2SxevJiiRYvSunVrvLy8VGYiAbRu3ZrevXtz4MAB5Xt3/PjxHDn+jHEHR0dHlT1/qlWrxpAhQ1i8eDGtW7fmq6++yrP/UVB4EXv1CAQCQSFDxPgFAoGgkCEcv0AgEBQyhOMXCASCQoZw/AKBQFDIEI5fIBAIcknGNubvX9OnT1exO336NJ07d8bV1ZWWLVuyadOmTMtbs2YNzZs358svv8TDw0Nt7ypQzATz8/OjXr161KxZk8GDB2u8D5fWp3NamuneMX9vZEnaliAQCDIhVZb5ynFNSXkRobGtUYnMt8/OitWrV2Nubq58XaJECeXf165dY+jQoXzzzTdMmDCBq1evMmvWLAwNDfHy8lLarVmzhkWLFjFq1CiqVq1KQEAAAwcOJCAggC+++EJpN2bMGG7dusXUqVMxMzPjf//7H3369GH//v3KRYUfQuuOXyAQCAqM9LTsbXJBtWrVPrieZsmSJVStWlW522r9+vWJjo5myZIldOvWDX19fWQyGcuWLaNXr17069cPgLp169KxY0eWLVuGv78/ACEhIZw6dYqVK1fi7u4OgJOTE61atWL37t306NEjS50i1CMQCAoP8nTNrzxEJpMRHBystpq9Q4cOPH/+XLnN99WrV4mPj6d9+/ZKGwMDA9q2bUtQUJByC5HTp09jbm5O48aNlXZly5alVq1aBAUFZatHOH6BQFB4SE/X/PoIOnbsSJUqVWjevDm///67couThw8fkpKSotx2PIOM41YzNifM2K/rfbvKlSuTmJhITEyM0q5SpUrKPaXetcsoKytEqEcgEBQa5DnoyUul0kw3GrSwsFA7vKdkyZIMHz6cL7/8EgMDA4KCgli6dClRUVHMnj1buYHf+/dlvM7Il0qlSCQSlYOW4L/zJ2JjYyldujRSqVRlLOHd8jTZLFA4foFAUHhIS83e5v/ZsGEDv//+u1r6Dz/8oLKfEkDjxo1Vwi5fffUV5ubmLF68mKFDh3683nxCOH6BQFB4yMHgbu/evencubNa+oeO6nyftm3bsnjxYm7duqUM6bz/BJHxOqNHb2FhgUwmIzk5WeUAn4xevJWVldIuOjparU6pVKpyROmHEI5fIBAUHnIQ6skspPOx2NnZYWRkREREBE2aNFGmZ5xSV6mSYupoRmw/PDycqlWrKu3Cw8MxNTXFxsZGaXfu3DnkcrnKQUBhYWHKsrJCJwd3TU2LMsl3JAG71hD+4CJxCeGMGj0oU9tvO7fl2ImdREZd48HDK/x1LIDOHqoj5949PIlLCP/gNXZc/j+KeXl1JlX2mASp+mErBYmpaVF+8hvD/r0biX58g1TZY8aPG6ZVTQButavj/9sMQq6fIO51KBFhF9m2dTmOjjmfS52X6Gp7AUgkEmbNnETk/cvEx4Vx/mwgrVu5a1sWADVqVGP3rrXERN9EGhvGjZCTjB0zRNuy8n1w910OHDiAnp4eLi4uSCQS6tevz6FDh1RsAgMDKVmyJNWqVQMU50CYm5tz8OBBpU1aWhqHDh2icePGSifv7u6OVCrlzJkzSrvo6GiuXr2q8sPyIXSyx1+8eDEmThpBVFQ0N0Ju07xF40ztBg7uxbz5P3H0r9NM/3kehkZGdO3aifUbF1OsmCVr12wD4NzZiwzoN1rt/l59utK4cX2OHzujlpeXmJoWZfYsXxIS3mBomPnZsQVFiRLWTJ0ymkePnnD9+k1a6YijGDduGA0buLFzVyD//HOH0qVLMXRIHy5dOEyjJp24efNfrejS1fYCWLtmEZ4e7Vm8eA33QiPo1fM79u3dSOs23Qg6E6w1Xa1aNmHPn+u5fv0Ws371JyHhDZUq2WFrW1ZrmjLIyeBuTujXrx/16tXDyckJPT09zpw5w9atW+nSpQvly5cHYNiwYfj4+DBlyhQ6duzI1atXCQgIwM/PTzk7RyKRMGTIEBYtWoS1tbVyAdfDhw9ZsGCBsr7q1avTtGlTfH19mThxImZmZvj7+1OmTBk8PDyy1av1/fgzW7krkUiwtrbi6dNn2NmV45/bQfzsN5dFC1eo2F25dgypNJ5m7v/F4YyNJYTcPMXjqGhaNPP8YL16enrcuXcWqTSeurXbqOTl9crdWTMn0anT11y5EoKnR3vMLLS3WlkikVC8eDGio2Owt7clPPQCk31nMXfeEq1pAmhQ343LV0JISUlRplWuXJHrV4+xZ+9hfHpqp5etq+1Vx60G588dYNLkmcybvxRQHG4Tcu04r1/H0uCrDlrRZW5uxp1bZzgffJmu3QaS1+4ltyt3k0PPaWxr7NhQY9uZM2cSFBRETEwMqampVKhQAQ8PD3r37o2BwX+dvdOnT7Nw4ULCw8MpVaoUffr0oVevXmrlrVmzhs2bN/PixQscHR0ZN26c2nGkCQkJzJ07l8OHDyOTyahXrx5TpkxR/tBkhU72+GUyGU+fPsvWzsLSnLAw1YPHk5NlxMbGkfg2a+fdtGlDypSxYfWqLbnSmh2VK1dk5IgBdPmuP126dMzXujRBJpMRHR2jbRlqnA++rJYWFnafW7fvUaWKkxYUKdDV9vL0bE9aWhqrVv/3+U1OTmbd+u3MnDEJe3tbIiM127clL/Hq3pnSpUsx1W8OcrkcU9OiJCa+zfMfgI8mLSV7m4/A19cXX1/fbO3c3d2VK22zol+/fsqVux/CzMyM6dOnq+0HpAk6GePXlLN/X6BVa3eGDO2Dvb0tlRwqMG36eBwcKuC/aGWW93bt/i3p6ekE/LE3XzUunD+NU6fOcejwiXyt53PFplRJXr54pW0ZOkeN6i6ER0QSG6s6Z/vSpeuK/Bou2pBFixaNiYuTUq5sGW7dDCLudSixr+6xfNlcihQxyb6A/EZLK3d1DZ3s8WvKuLHTKF7cmtlzpzJ77lQA4uLi6f7dQI4f/3Dc3sTEmA4dWxEcfCVfe0Xt2ragVasm1HJrlW91fM54e3tga1uGX2Ys1LYUnaN0mVI8zeRJJPqpIq1sGZuClgQonnANDQ3ZvWsta9dtw3fKrzRqWJcRI/pTsmRxPLtk3YvNd/Jg0PZzQCPHHx4eTlBQEBEREcr5pJaWllSqVIkmTZqoLS8uKBLfvOXu3TBiYp5zIPAoEomE7/t5s37TYr7t1Jsrl0Myva99h1ZYWJizY3v+9faNjIyYP/9nVqzcxJ07oflWz+eKs7MDi/1nEhx8hXXrt2tbjs5RxMSE5GSZWnpSUrIiX0u9azPTopiaFmX5io2MGu0HwJ49ipksP/44kC+/rMqNG7e1og347HvympKl409KSsLX15eDBw9iZGSEnZ2dcl5rREQEe/fuZe7cubRr145Zs2apLDgoCDZs+h19fT08vu2rTNu96wAXLh1m/oKfVQZ936Vrt29ITk7mz90H8k3bjyMHUKJ4MaZNX5C9sUAFG5uS7Nuzkbi4eL7rNoB00UtT421SEsbGErV0ExPFd/BtNmNc+cXbJEW9f/yxRyV967bd/PjjQBo2qKNdxy8+S0A2jn/+/PmcPXuWefPm0bp1ayQS1Q+aTCbj6NGjzJgxg3nz5jFlypR8FfsuFSqUp1Vrd0b/OFUlPSUlhaNHTzNwUE9MTIyVPaAMrIsXo0XLxhw+fJLYWPV9OPICCwtzJk8ayfIVG7CwMMPCwgwAMzNT9PT0sLe3JTHxLc+fv8yX+j9lLCzMCdy/GSsrS5o276yTA6u6wNPoZ9jZ26qllymtCPE80VK7RT+JwaXaF8Q8e6GSnvG6WLHsV5XmJ/L0/Bnc/dTIcnD3wIEDTJo0iQ4dOqg5fVBMdWvfvj0TJkzgwIH86z1nRslSigMODAzVf7sMDQ3Q19dXmUaVgYdne4yMjPhj25/5pq1YMUvMzc0YN3YY4aEXlJenR3uMjY0JD73A6pUibv0+xsbG7P1zPU6Olfjm294iRJYFISG3cKhkj5WVqiOtW7emMl8bXL12A4ByZUurpNuWKwOg/c5OAS7g0mWydPxJSUkqJ8h8iBIlSpCUVLCPluHhD0hLS8PTs4PKkmUzM1PatmtB6L0I3rxJVLuvW7dviH0dx5HDp/JN27NnL/Do8r3adfLkWWQyGR5dvmfWr/75Vv+niL6+Ptu2LqN+/dp09xpE8IUr2pak0+zafQADAwMG9P/vwA2JRELvXt24fCWEBw8eaUVXwM79APTt210lvV8/b9LS0jhx8m9tyPoPMasHyCbUU6tWLZYsWYKLi8sHN/6Ji4tj6dKluLm55amwAYN6YmlpgZWlYkyhcZP6yt79yuUbePXyNRs37KDv914cOrKdP/88iMTIiF59ulKuXBm+7/ujWpkVK9pRt14t1q/bjkymPjCWV7x9m8S+fUfU0r/p9DUN0mtnmleQDB3SBysrS2XbNnVviOH/t+3vS9YilcYXuKZ5c3+iU8c27A/8i2LWVnh7q64+3Lp1d4FrykAX2+vipWsE7NzP9GnjKVHcmtCw+/T06ULFiuX5uq1X9gXkE9ev32Ltum1839cLIyMjTp06x1df1cHby4PFv68hIiJSa9qAfD+B61Mhy5W7kZGR9OzZk/j4eBo0aEDlypWVe0DHx8cTHh7O+fPnsbCwYMOGDdjb2+dYwIfO3L1x6zT2mcQwAVyrNuHhw8fo6+vTp283evfpTsVK9hgaGnDzn3/x/20lBwKPqt03fuIP+E4ZRds23Tl39tIHNeXXmbtrVi+iW9dOWl25CxB2L5gKFTJf3efgWE8rC3+OHw3A3f3DKyUNJeUKUI0qutheoAiNTft5LN5eHlhbW3Hz1l1+/nkeh4+c1IqeDAwNDZk44Qf69O5O2bI2PHr0hNVrtjB/wbJcL+TK7crdpIsBGtua1P0uV3XpMtlu2RAfH8+2bds4c+YM4eHhym1ELSwscHBwoEmTJnTv3j3TQwE0QRy2LhAINCXXjj/4D41tTep3y1VduoxO7tWjbYTjFwh0k1w7/rOab9Fi8lXWB5Z/ynzSK3cFAoEgR3zms3U0RTh+gUBQaJDLxeAuCMcvEAgKE6LHDwjHLxAIChOf+fx8TRGOXyAQFB5Ejx8Qjl8gEBQm0lK1rUAnEI5fIBAUHkSoB9ABx6+rc+aNDLTeNJmSInosAsHHI0I9gA44fl1EV52+QCDIJcLxA8LxCwSCwoQI9QDC8QsEgsKECJUCwvELBILChAj1AMLxCwSCwoQI9QDC8QsEgsKE6PEDwvELBILChHD8gHD8AoGgMKHd40d0hiwPW9d13GpXx/+3GYRcP0Hc61Aiwi6ybetyHB0r5Ut9pqZFmTJlFH/+uZ6HD6/y9m0kY8cOUdflVp1Fi37h77/3ERt7j7dvI7GxKZlpmW/fRmZ6ZVZuXiCRSJg1cxKR9y8THxfG+bOBtG7lni91fQ66CvozlhN0oc1MTYvyk98Y9u/dSPTjG6TKHjN+3LBMbT09O3D2zH5ePLvNs6c3OXN6L126dCxQvaSman59xnzSjn/cuGF4dG7HiRN/M2q0H6vXbKFxo3pcunAYF5cv8ry+4sWt8fX9ERcXZ0JCbn3Qrk2bZvTr54WBgSGhofezLffkybP07fujynXgwLG8lK5k7ZpFjPpxEH/8sZdRo38iJSWVfXs30qRx/Xyp71PXVdCfsZygC21WooQ1U6eMxsWlCtev3/yg3bChfflj2wpev47Fd8pspv+yEAMDfbZvXc7AAT0LTC/ydM2vzxitH72Ym0O0G9R34/KVEFJSUpRplStX5PrVY+zZexifnpn3PLLjQyt3JRIJxYtbER39DDs7W+7ePcvUqbOZP3+Zil2pUiWQSuNJSkrG1/dHpkwZRYUKbsTEPFcr8+3bSFat2syIEb4aacvNlg113Gpw/twBJk2eybz5SwHFgd0h147z+nUsDb7q8NFl5wZd1QX59xnLLbrSZorvRDGio2Owt7clPPQCk31nMXfeEhW727fOEBcnpUHD9so0Y2NjQu+eIyrqCQ0badbzz+3Ri283TtLYtkivX3NVly7zSff4zwdfVvlCAoSF3efW7XtUqeKU5/XJZDKio59la/fs2QuSkpJzVLaxsTEmJsYfK00jPD3bk5aWxqrV/507mpyczLr126lTpyb29rb5Wv+npgsK/jOmKbrSZorvREy2dpYW5jyLeaGSlpyczOvYOBITC3C/Lrlc8+sjefPmDU2aNMHZ2Zl//vlHJW/Pnj18/fXXuLq60r59ew4ePKh2f0pKCgsWLKBRo0ZUr14dHx8f7ty5o2b3/PlzfvzxR2rXro2bmxtjx47l1atXGmn8pB3/h7ApVZKXLzRrAF3A29uDV6/+5fXre1y7dhwvr875Uk+N6i6ER0QSGxunkn7p0nVFfg2XfKk3O3RVV1Zo+zP2qbVZ0Jlgvv66GSOG96dChfJUrlyRX2dNxrFyReYvWFpwQtLTNb8+kt9//520NPUjHg8fPsyECRNo1aoVq1atokGDBowePZrTp0+r2P36669s2bKFESNGsHTpUoyMjOjTpw8xMf/9wKamptK/f3/u3bvHnDlzmDFjBteuXWPo0KFoEsT57Gb1eHt7YGtbhl9mLNS2FI04f/4yu3YF8uDBI8qUsWHQoF6sXfsbVlaWLFu2Pk/rKl2mFE8z6Z1FP1WklS1jk6f1aYqu6voQuvAZ+9TabOSPUyhR3JqFC6axcME0AOLipHzbuQ9/HT2dzd15SD5P57x37x7bt29n4sSJ+Pn5qeT5+/vz9ddfM2bMGADq169PREQEixcvxt1dMSgfExPD9u3b8fX1pWvXrgBUr16dFi1asGHDBsaPHw/AX3/9xb///ktgYCCOjo4AlCpVCi8vL4KCgpTlfYg86/E/efKEPXv25FVxH4WzswOL/WcSHHyFdeu3a1WLpjRv7smSJes4cOAYq1dvoWHDDty8+S8//TSGokWL5GldRUxMSE6WqaVnhKWKFDHJ0/o0RVd1ZYaufMY+pTYDePMmkTv/hrJt+5909x5M774juHXrLtu3raBunZoFpkOelqbx9TFMnz6dHj16UKFCBZX0R48eERERQfv27VXSO3TowD///KMM0fz999+kpaXRrl07pY2ZmRnNmjUjKChImXb69GmcnJyUTh+gVq1alCtXTu0JIjPyzPH/888/TJqk+cBJXmNjU5J9ezYSFxfPd90GkP6JLtRISUlh+fINWFpaULt29Twt+21SEsbGErX0jLGFt2+1czaCrup6H136jH0qbZbBH9tWUNmhAj17/cDOnfvZsmUXLVp9R0zMC/z9ZxSckByEeqRSKVFRUWqXVCrNtOg9e/YQGRnJkCHqU7EjIiIAcHBwUEmvXLmySn54eDglSpSgWLFianYPHjxQfubCw8OV975vl1FWVnwWMX4LC3MC92/GysqS9h17aDTYpIHchMgAACAASURBVMtERUUDYG1tlaflPo1+RulMQgBlSivSnmip3XRV17vo2mfsU2izDCpWtOPrr5uzd98RlfSUlBQOHzlB7VpfYmJSQE8oOZjOuWHDBlq0aKF2bdiwQa3Y+Ph45s2bx7hx4zA1NVXLj4tTjMVYWFiopFtaWqrkS6VSzM3N1e63tLQkJSWFxMTELO0sLCyUZWVFtjH+jh01m2b15s0bjezyGmNjY/b+uR4nx0q0+bo7d+6EakVHXlKxoh0AL168zNNyQ0Ju0azZV1hZWaoMCtatW1OZrw10VVcGuvgZ0/U2exebUorFi4aGBmp5hoaG6OvrY2BQQH3QdM1n6/Tu3ZvOndUnWrzvvAF+++037O3t6dSpU67kFRTZtnZERAT6+vq4uLhkednaFvyUO319fbZtXUb9+rXp7jWI4AtXClxDbihRwlotzczMlB9++J6XL19z+fKNPK1v1+4DGBgYMKB/D2WaRCKhd69uXL4SwoMHj/K0vk9dF+juZ0yX2+x9QsMiSEtLo1vXb9DT01Omm5mZ0rFDa+7eC+fNm8SCEZODUI+FhQW2trZq1/uOPzQ0lO3btzNy5EikUilSqVTZM09MTCQhIUHZs38/TJTRO8/It7CwID4+Xk12XFwcRkZGFC1aNEs7qVSqLCsrsu3xOzo6Ym9vz6+/Zr2Y4ciRI1y6dCnbCvOSeXN/olPHNuwP/Iti1lZ4e3uo5G/dujvP6xw8uDeWlhZYWSne/CZNGmDw/wu+li1bj1Qaj51dOby8FFoaNaoHwA8/fE9CQiIPH0axbdufAAwa1IuOHVtz8OBxHj16TOnSpejduyvly5djwIAxJCfnbC1Adly8dI2AnfuZPm08JYpbExp2n54+XahYsTxft/XK07o+B12gnc+YJuhSmw0d0gcrK0usLBXfiabuDTE0VHwnfl+ylpcvX7Nm7TYGDvDh1IndBOzcj0RixPffe2NrW4YePYcWnNiPHLTNisjISFJTU+nVq5daXq9evfjiiy/4/fffAUVH+t04f3h4OACVKim2AHFwcODly5fExsZiZWWlYlehQgX09fWVdpnN7Q8LC6Np06bZas525a6fnx9nzpzh5MmTWRZ05MgRRo4cyb///pttpe+Sm5W7x48G4O7eMM/LzurM3X///Rt7+/KZ5jk7f8XDh1E0blyfv/76I1OboKDztGnTHYDmzRsxatQgqlX7guLFrUhMfMvlyyEsWrSCEyf+zvT+3B62bmxszLSfx+Lt5YG1tRU3b93l55/ncfhI1u9vfqOruvLrM5YX6Eqbhd0LpkKFzL8TDo71iIyMQl9fn/79etCvnzeVHSpgaGjIjRu3mbdgKfvei/1nRW5X7iYuHKCxbdHRqzSye/XqFaGhquG/O3fu8OuvvzJt2jSqVauGq6srbdu25YsvvmDRokVKu379+hEXF8fOnTsBxXTOZs2aMXXqVLy8FD/gb968oXnz5nh6eiqncx48eJDRo0dz4MAB5Q/J9evX6datGytXrsx2Ome2jv/hw4eEhobSokWLLAtKSkri5cuXlCuXsy+CNr84H0KXD1vPreMXCD5lcu345/fX2Lbo2NUfXc+FCxfo1asXO3fuxNXVFYBDhw4xatQoBg0aRMOGDTl+/DgbN25kxYoVKo56+vTp7N27l4kTJ1K2bFnWrl3LzZs32bdvHzY2isH71NRUPD09SU1NZfTo0aSlpTF37lxKlCjBtm3bVEJqmZGth7Ozs8POzi7bf9TExCTHTl8gEAgKFC1uvta2bVuSkpJYvnw5a9aswc7OjgULFqj1zidNmkTRokX57bffiI+Px9XVlXXr1imdPigGxVevXs3MmTMZN24cenp6NG3aFF9f32ydPnzim7TlF6LHLxDoJrnu8c/pq7Ft0QnrclWXLqO7Hk4gEAjyGPknurAzrxGOXyAQFB7yYVbPp4hw/AKBoPCQgwVcnzPC8QsEgsKDCPUAwvELBILChOjxA8LxCwSCwsRnfpaupgjHnwm6PGXS2NBI2xIyJTk1JXsjgUDbiB4/IBy/QCAoRMhTxaweEI5fIBAUJkSPHxCOXyAQFCZEjB8Qjl8gEBQmRI8fEI5fIBAUIuTC8QPC8QsEgsKEGNwFhOMXCASFCdHjB4TjFwgEhQnh+AENDlvXdSQSCbNmTiLy/mXi48I4fzaQ1q2yPnbsc9NlaloU3ymj2P3nOh5EXuFN4gPGjBmiYqOnp4ePTxd2BKzi7r1zPHt+m0uXjjB+wg8YGxtnWX7Fina8fHWXN4kPqFOnZr78D7r6PoLuajM1LcpPfmPYv3cj0Y9vkCp7zPhxw7QtS2d1Acjlco2vz5lP3vGvXbOIUT8O4o8/9jJq9E+kpKSyb+9GmjSuX2h0FS9uzeTJI6lWzZkbIbcytSlatAgrVs6nRInirF69hfHjp3P5SghTpoxiz94NWZY/Z+5UUlPzdzWzrr6PuqytRAlrpk4ZjYtLFa5fv6lVLe+iq7oARY9f0+sz5pMO9dRxq0H3bt8yafJM5s1fCsCmzTsJuXacObOn0OCrDoVC19Onz3BwqMvT6GfY2dly51/1g9plshSaN/PgwoWryrT167YTGRnF1KmjadmyCceOBand17JlE1q2bMKiRSuYOHFEnurOQFffR13XFh39jPL2tYiOjsHe3pbw0Ata0/IuuqoL+OwduqZ80j1+T8/2pKWlsWr1FmVacnIy69Zvp06dmtjb2xYKXTKZjKfRz7K0SUlJUXH6GezfdwSAL75wVMszNDRk7ryfWLpkHfcjHuaN2EzQ1fdR17XJZDKio2O0Vv+H0FVdAPLUdI2vz5lP2vHXqO5CeEQksbFxKumXLl1X5Ndw0YYsndWVGTY2JQF4+fKVWt4PP3xPMSsL5sz5PV816HJ76bI2wUeQnoPrM+aTDvWULlOKp5n0LKKfKtLKlrFRyysIdFVXZowaNQipNJ4jR06qpNvYlGTCxOFMnjyL+PiEfNWgy+2ly9oEOUcs4FKgUY8/JSWFFy9efHCkOyEhgUuXLuWpME0oYmJCcrJMLT0pKVmRX8SkoCUp6tVRXe8zdtxQmrdojJ/fHF69ilXJ++WXiTx48Ij167bnuw5dbi9d1ib4CMTgLpCN45fL5cybN486derQuHFjGjRowIoVK0h778Di8PBwevXqla9CM+NtUhLGxhK1dBMTxfTEt2+TClqSol4d1fUunp4d+Omnsaxfv51VKzer5NWpUxMv785MGP9LgUxr0+X20mVtgo9AhHqAbEI927dvZ8OGDfj4+FClShUuX77M4sWLCQoKYunSpVhaWhaUzkx5Gv0Mu0wG18qUVjx+P9HSAJOu6sqgefNGrFq9gMOHTzBiuK9a/oyZEzl79hIPHjzCzk7xfxQvXgxQhD5sbcsSFfUkz/TocnvpsjZBzhGhHgVZOv5t27YxaNAghg8fDsA333xD165dGTFiBD169GD16tWULl26QIRmRkjILZo1+worK0uVwbe6dWsq84UuVdzq1GDb9hVcvfoPPX2GqT29AZQvXw57+8ynhW7fvoKEhDfYlKqWZ5p0ub10WZsg58hTheOHbEI9jx49ol69eipprq6u7NixA0NDQ7p160ZoaGi+CsyKXbsPYGBgwID+PZRpEomE3r26cflKCA8ePBK63sHZ2YFdu9byMDKKLp7fK+PU7zP8h0l06zZQ5Vq6dB0AU3x/pXfv4XmqS1fbS9e1CT4CEeoBsunxW1pa8uLFC7X0kiVLsnnzZgYPHoyPjw+DBg3KN4FZcfHSNQJ27mf6tPGUKG5NaNh9evp0oWLF8nzd1ksrmrSla9DgXlhaWmBlaQFAkyYNMDA0AGD5sg2kp6ezd99GihWzxP+3lXz9dXOV+yMiHnLxomKe//HjZ9TKzyj3778vcunStTzVrqvvo65rAxg6pA9WVpbK96epe0MMDRVf69+XrEUqjRe63kGcw6JAT57F6N2wYcMwNjZm4cKFmebLZDJGjBjBqVOn0NPT486dOzkWYCgpl+N73sXY2JhpP4/F28sDa2srbt66y88/z+Pwe9MTC5r80vWhw9Zv3/n7g4uJqnzRCCDT0E0GmzftZNCgsR/M9/HpwoqV82nq3jlTx5/bw9Z19X3UdW1h94KpUKF8pnkOjvWIjIwqYEUK8ktXquxxbmTxsr3meywVP3A6V3XpMlk6/kOHDrF+/XqWL19OsWLFMrVJS0tj2rRp/P3335w4cSLHAnLr+AsbH3L82ia3jl8g0ITcOv4XbTV3/CUOFVLHXxAIx58zhOMXFGZy6/if52BX1ZJHNXf8f/31F+vWrSMiIoLExERsbGxo1aoVQ4cOxdzcXGl3+vRpfvvtN8LCwrCxsaF379707NlTrbw1a9awZcsWXrx4QeXKlRk3bhwNGjRQsUlISGDu3LkcOXIEmUxGvXr1mDJlCra22W8j8klv2SAQCAQ5QZ6u+ZUT4uLiqFOnDr/88gurV6+mV69e7Nq1i5EjRyptrl27xtChQ6lSpQqrVq3Cw8ODWbNmsW3bNpWy1qxZw6JFi+jRowcrVqygQoUKDBw4kH///VfFbsyYMZw4cYKpU6eyaNEinj17Rp8+fXj79m22ekWP/xND9PgFhZnc9vhjmmne47c5mbtQzx9//IGfnx9BQUHY2NjQv39/4uLiCAgIUNpMnTqVkydPEhQUhL6+PjKZjIYNG9K1a1fGjx8PKMLpHTt2xNHREX9/fwBCQkLo2rUrK1euxN1d8T89efKEVq1aMXnyZHr06KEu6B1Ej18gEBQe5HqaX7kkY1w0JSUFmUxGcHAw7dq1U7Hp0KEDz58/59YtxXqQq1evEh8fT/v27ZU2BgYGtG3blqCgIOVK+tOnT2Nubk7jxo2VdmXLlqVWrVoEBalvr/4+wvELBIJCQ36FejJIS0sjOTmZmzdvsmTJEpo3b46trS0PHz4kJSUFBwcHFXtHR8V26BEREYBi+xtAza5y5cokJiYSExOjtKtUqRL6+vpqdhllZcUnvTunQCAQ5AR5uuY9ealUilQqVUu3sLDAwsIi03vq1atHfLxijULjxo1ZsGABoBgDyLj3/bLezZdKpUgkEkxMVDf/y9geJzY2ltKlSyOVSlUGjd8tL6OsrBCOXyAQFBrS0zR3/Bs2bOD339XPovjhhx+U29i8z6ZNm3j79i2hoaEsW7aMwYMHs27duo/Wm18Ixy8QCAoNOQnh9O7dm86dO6ulf6i3D1ClShUAatWqRbVq1fD09OTo0aNUrlwZQO0JIuN1Ro/ewsICmUxGcnIyxsbGSruMXryVlZXSLjo6Wq1+qVSq0eaZIsYvEAgKDfJ0PY0vCwsLbG1t1a6sHP+7VKlSBX19fR4+fIidnR1GRkZq8fewsDAAKlWqBPwX28+I9WcQHh6OqakpNjY2Srv79++rbZseFhamLCsrhOP/xEhOTdHJSyD4FJDLNb9yy7Vr10hPT8fW1haJREL9+vU5dOiQik1gYCAlS5akWjXFbre1atXC3NycgwcPKm3S0tI4dOgQjRs3Rk9PEapyd3dHKpVy5sx/+2pFR0dz9epVmjRpkq02EeoRCASFhpwM7uaEfv36Ub9+fRwdHTE2NubOnTusWbMGZ2dnWrZsCSj2PvPx8WHKlCl07NiRq1evEhAQgJ+fn3J2jkQiYciQISxatAhra2uqVq1KQEAADx8+VA4UA1SvXp2mTZvi6+vLxIkTMTMzw9/fnzJlyuDh4ZGtXrGASyAQfDLkdgHX/eqtNLatGHJUY9vffvuN48ePExWl2HzO1taW1q1b07dvX8zMzJR2p0+fZuHChYSHh1OqVCn69OmT6emFa9asYfPmzbx48QJHR8cst2w4fPiwypYN5ctnvjneuwjHLxAIPhly6/gjXFtrbFvpn79yVZcuI0I9AoGg0CDPgxW5nwPC8QsEgkKDOIhFgXD8AoGg0JAuevyAcPwCgaAQIUI9Cj7pefw1a7gQsGMVYfeCiY8LI/rxDU4c20n7di21LQ2JRMKsmZOIvH+Z+Lgwzp8NpHUODoHIL0xNi/KT3xj2791I9OMbpMoeM37cMJ3V4OnZgbNn9vPi2W2ePb3JmdN76dKlo1Z11XGrwf/8Z3L+3AHexEeQKnuMjU3JfNH0IdxqV8f/txmEXD9B3OtQIsIusm3rchwds1+8k5+sWb2IVNnjD14NG7hpVV96mp7G1+fMJ93jr1jJHmOJMes3bOfJkxhMTYvi0bkde/dsYOiwiaxctUlr2tauWYSnR3sWL17DvdAIevX8jn17N9K6TTeCzgRrTVeJEtZMnTKaR4+ecP36TVpp4cdIUw3DhvbF/7cZHD58At8pszEyMsTbqzPbty5naDGrPH9/NdXVtm1zBvTvwc1bd7kXGoGrS5U81aEJ48YNo2EDN3buCuSff+5QunQphg7pw6ULh2nUpBM3b/6bfSH5wKpVmzl+4oxa+rw5fhgaGnLpcogWVP1Hfs3j/9T47KZz6uvrc/HCYUyLFqVKtUZ5Wram1HGrwflzB5g0eSbz5i8FFAd2h1w7zuvXsTT4qoNWdIHiSaR48WJER8dgb29LeOgFJvvOYu68JTqn4fatM8TFSWnQ8L+9yY2NjQm9e46oqCc0bJS3PX9NdZUqVQKpNIGkpCT8po7Gb+oYypWvQUzM8zzVkxUN6rtx+UoIKSn/rZquXLki168eY8/ew/j0LNinuKz44ovK3LxxmhUrNzHsh4m5Kiu30zlvVtL8u+cSEZirunSZTzrUkxnp6ek8jorGykqz/TTyA0/P9qSlpbFq9RZlWnJyMuvWb6dOnZrY22d/JmZ+IZPJiI6O0Vr9OdFgaWHOs5gXKmnJycm8jo0jMTFJa7qePXtBUlLe158TzgdfVnH6AGFh97l1+x5VqjhpSVXm9PD2BGDr1l1aVqKI8Wt6fc580qGeDExNi2JiYoyVlSWdOrahTZumBOzcrzU9Naq7EB4RSWys6r7Yly5dV+TXcCEyMkob0j4pgs4E49G5HSOG92ff/iMYGhrS73svHCtXZMKEX7QtTyexKVWSe/fCszcsQLp3+5aIiEjOnrukbSl5sgfP58Bn4fiXLpmt7FWkpaXx555DDB/hqzU9pcuU4mkmPcfop4q0smVsClrSJ8nIH6dQorg1CxdMY+GCaQDExUn5tnMf/jqau/NQP0e8vT2wtS3DLzMWaluKkq8a1qFiRTtmzvpN21IAMZ0zA40c//Pnz0lJSaFs2bIAyOVyjh49SmRkJHZ2drRo0QJDQ+39hsyZ+zsbNwZQpqwN3bt+g6GhAcbGEq3pKWJiQnKyTC09KSlZkV/ERC1PoM6bN4nc+TeUpzHP2LvvCMbGEgYN6Mn2bSv4uq0XFy9d07ZEncHZ2YHF/jMJDr7CuvXbtS1Hiff/d8i2bN2tZSUK0sXgLpCN409ISGDkyJGcO3cOgBYtWjB//nwGDRrEhQsX0NfXJz09nSpVqrB582ZMTU0LRPT73L59j9u37wGwefNODh/cxp7d67Q2iPo2KSnTHx4TE8XBCm/fajc+/Knwx7YV6Ovr065DD2Xajh37uHH9JP7+M1QGfQszNjYl2bdnI3Fx8XzXbQDp6bqxPNXIyIgunh24dPm6zoSfRI9fQZaDu0uWLOHmzZtMmzYNf39/oqKiGDFiBA8fPmTXrl3cvHmTzZs38/z5c9avX19AkrNn565A6tSpiZOTQ/bG+cDT6GeUziScU6a0Iu2JlgdXPwUqVrTj66+bs3ffEZX0lJQUDh85Qe1aX6qdS1oYsbAwJ3D/ZqysLGnfsYfWB+7fpW3b5hQvXoytOtLbBzG4m0GWjv/YsWMMHz6crl270rp1a2bMmEFQUBBDhw6lWrVq6Ovr4+bmxvfff8+RI0eyKqpAyQilWFqoH0ZcEISE3MKhkj1WVqpHoNWtW1OZL8gam1KKBVGGhgZqeYaGhujr62Ng8NlNSssRxsbG7P1zPU6Olfjm297cuROqbUkqeHt5kJKSwvY/9mhbipJ0uZ7G1+dMlt+cmJgYnJ2dla+dnBTTxBwdHVXsqlSpwuPHuZtf+zGULFlcLc3IyIiePb8jMfEtt+/cK3BNALt2H8DAwIAB/f8LUUgkEnr36sblKyE8ePBIK7o+JULDIkhLS6Nb12+Upw4BmJmZ0rFDa+7eC+fNm0QtKtQu+vr6bNu6jPr1a9PdaxDBF65oW5IKFhbmtG/XgmPHgnj+/KW25SiR5+D6nMkyxl+0aFHlIb+g6GmZm5urPWLLZOoDmQXB1s3LSE5O5nzwFaKjYyhb1gZvb0+cHCsxdtw0rTmGi5euEbBzP9OnjadEcWtCw+7T06cLFSuW5+u2XlrR9C5Dh/TBysoSK0vFWoem7g2Vg/O/L1mLVBqvdQ0vX75mzdptDBzgw6kTuwnYuR+JxIjvv/fG1rYMPXoO1YouqTQeO7ty+PToAkDjRvUBGDmiPwkJiUQ+jGLLlvyfrz5v7k906tiG/YF/UczaCm9v1VOXtB1e8fRoT5EiRdiyTXfCPABp6YX7KTGDLFfuent7U6dOHUaNGpVlIatXr2b//v3s3bs3xwJys3K3d6+u9PT5jipVHLG2tkIqTeDq1RssWbaOwEDNT8/JD4yNjZn281i8vTywtrbi5q27/PzzPA4fOalVXQBh94KpUCHzU3ocHOsVyBoDTTTo6+vTv18P+vXzprJDBQwNDblx4zbzFixl3778CS1qosu9SQOOH9uZqc3p0+do0eq7fNH2LsePBuDu3vCD+do+4OjokR24uVWnrG31PJ3MkNuVu2dKd9HYtvHTzN/jz4EsHf/Ro0eJjY3lu++y/iD369eP6tWrM2LEiBwL0PYHVCAQfDrk1vEHldb8R7nJ04Bc1aXLfHZ79QgEgs+X3Dr+UzaaO/6mMZ+v4/8sVu4KBAKBJqTzec/W0RTh+AUCQaFBLhw/IBy/QCAoRKQJxw8Ixy8QCAoRurGZhfYRjl8gEBQahONXIBy/QCAoNIgYvwLh+AUCQaFB7MqsQDh+gUBQaBDTORUIxy/4rDEx1N6BPNmRlKqdPa6y43N2jWnaFqAjCMcvEAgKDel6n/PPmuYIxy8QCAoNn/t2y5oi9igVCASFhvQcXDnh0KFDDB06FHd3d2rUqEHHjh3ZunWr2jGYp0+fpnPnzri6utKyZUs2bdqUaXlr1qyhefPmfPnll3h4eHD+/Hk1m4SEBPz8/KhXrx41a9Zk8ODBREVptrOucPwCgaDQkK6n+ZUT1q1bh0QiYfz48SxfvpyWLVsyc+ZM5s2bp7S5du0aQ4cOpUqVKqxatQoPDw9mzZrFtm3bVMpas2YNixYtokePHqxYsYIKFSowcOBA/v33XxW7MWPGcOLECaZOncqiRYt49uwZffr04e3bt9nqFbtzCj5rxOBuztHlKHhKLnfn3FzWR2NbnyebNbZ99eoV1tbWKmm//vor27Zt4/Lly0gkEvr3709cXBwBAf/t+jl16lROnjxJUFAQ+vr6yGQyGjZsSNeuXRk/fjwAaWlpdOzYEUdHR/z9/QEICQmha9eurFy5End3dwCePHlCq1atmDx5Mj169CArRI9fIBAUGvKrx/++0wfFkbTJycnExsYik8kIDg6mXbt2KjYdOnTg+fPn3LqlOIf76tWrxMfH0759e6WNgYEBbdu2JSgoiIx++unTpzE3N6dx48ZKu7Jly1KrVi2CgoKy1SsGdwUCQaEhJ7F7qVSKVCpVS7ewsMDCwiLb+69cuYKVlRXFixfn/v37pKSk4ODgoGKTcX55REQErq6uhIeHA6jZVa5cmcTERGJiYihdujTh4eFUqlQJfX19Nbu///47W22fdI/fvUkDUmWPM73q1a2lbXkqeHl1JlX2mARpuFZ1SCQSZs2cROT9y8THhXH+bCCtW7lrVVMGNWpUY/eutcRE30QaG8aNkJOMHTMkX+oyNS2K75Qf2fXnWh5EXiYh8T6jxwzO9r59+zeRkHgf///NUMtLSLyf6aVJuR+Dtt9Lt9rV8f9tBtevnyD2dSjhYRfZunU5jo6VVOyGDe3LyRO7eRwVQkJ8BPfunmfVygXY29sWmNYMcnLY+oYNG2jRooXatWHDhmzr+eeff9i9eze9e/fGwMBAeXb5+z8YGa8z8qVSKRKJRO1cc0tLSwBiY2OVdubm5mr1WlhYqJyT/iE+ix7/kqXruHDxqkpaWPh9LalRx9S0KLNn+ZKQ8AZDQwOtalm7ZhGeHu1ZvHgN90Ij6NXzO/bt3UjrNt0IOhOsNV2tWjZhz5/ruX79FrN+9Sch4Q2VKtlha1s2X+orXrwYkyaPJCrqCSEht2nRsnG293T6pg1169XM0ubUybNs2qR6VuuNkFu50vohtP1ejh03jIYN3Ni1K5B//rmDTelSDB3Sh4sXDtO4SSdu3lQMRtas6UpoaAR79x0h9nUsFSra0e97bzp0aE1tt1Y8efI037VmkJMQTu/evencubNaena9/efPnzNixAhcXV0ZMGBATiUWCJ+F4z977iI7duzTtowP4jt5JPEJbzh1+hyeHu2zvyGfqONWg+7dvmXS5JnMm78UgE2bdxJy7ThzZk+hwVcdtKLL3NyMdWv9OXjoOF27DaQg5hs8ffqcyg71eBr9DDu7ctz+N+vHY2NjCbN+9WXRwhVM9Rv9Qbvw8Af8sX1PXstVQxfeS//fVtKz5zBSUlKUaQEB+7h29RgTJgynZ89hAPQfoN5e+/Ye5sKFw/Tq1ZXZs/+X71ozyEmoR9OQzrvEx8czYMAATExMWLZsGUZGRsB/Pfb3Q0cZrzPyLSwskMlkJCcnY2xsrLTL6MVbWVkp7aKjo9Xql0qlyrKy4pMO9byLqWlRDAy025vOjMqVKzJyxADGjZtGaqp2F4x7erYnLS2NVau3KNOSk5NZt347derU1MqjN4BX986ULl2KqX5zkMvlmJoWRS+fV1jKZDKeRj/T2H7U6EHo6+vjQx3FNAAAIABJREFU/9vKbG2NjSWYmBhna5cbdOG9PB98WcXpA4SF3ef27XtUreKU5b2RDxXzza0sc+ZYc0uanuZXTklOTmbIkCG8fPmS1atXU6xYMWWenZ0dRkZGREREqNwTFhYGQKVKivBYRmw/I9afQXh4OKamptjY2Cjt7t+/r9ZJCgsLU5aVFZ+F41+xbB5xr0N5Ex/B8aMB1HGroW1JShbOn8apU+c4dPiEtqVQo7oL4RGRxMaqxgAvXbquyK/hog1ZtGjRmLg4KeXKluHWzSDiXocS++oey5fNpUgRk+wLyGdsbcsyeswQ/KbMJikpOUvb7l6def7yDi9e/cuVq0fp7qUeKsgLdPW9BChVqiQvXrxSSy9evBilSpWgjlsN1qz+DYBjx7OfgZKX5NcCrtTUVEaOHMndu3dZtWoV5cqpTlOXSCTUr1+fQ4cOqaQHBgZSsmRJqlWrBkCtWrUwNzfn4MGDSpu0tDQOHTpE48aNlR0id3d3pFIpZ86cUdpFR0dz9epVmjRpkq3ejw71vHnzBh8fH2bMmKEUXdDIZCns2n2AQ4eO8+LlK6pWcWL0qMGcPLGLps08uHwlRCu6MmjXtgWtWjWhllsrrerIoHSZUjyNjlFLj36qSCtbxqagJQGKpyJDQ0N271rL2nXb8J3yK40a1mXEiP6ULFkczy79tKIrg19n+xIScoudOwOztDt//jJ/7jrAg8goypQpxcCBPVm9ZiFWlhYsX579gGBO0NX30tvbA1vbMsyYsVAl3cDAgKfRN5WvX7x4xY8/TuHYsYJ3/PnB9OnTOXnyJOPGjSMpKYnr168r8ypXroyZmRnDhg3Dx8eHKVOm0LFjR65evUpAQAB+fn7K2TkSiYQhQ4awaNEirK2tqVq1KgEBATx8+JAFCxYoy6xevTpNmzbF19eXiRMnYmZmhr+/P2XKlMHDwyNbvVk6/oy5pZmRmJjInTt3uH37tjKtoH8Azgdf5nz3y8rXgYFH2bX7ANeuHGPmjEm0adu9QPW8i5GREfPn/8yKlZu4cydUazrepYiJCcnJ6ouGMnqx2updm5kWxdS0KMtXbGTUaD8A9uxR9Ix+/HEgX35ZlRs3bmdVRL7RpEl9vvn2a5q6Z99zb9XiO5XXGzcE8PfZfUz9aTQbN+4gMTH7FZWaoovvpbOzA//zn0lw8BXWrd+ukpeWlkabr7sjkRhRpYojPbw9KWpatMA15tfoUcYUyndX6mawceNG5bYKS5cuZeHChezZs4dSpUoxadIkvLy8VOz79VN0dDZt2sSLFy9wdHRk5cqVfPHFFyp2CxYsYO7cuUybNg2ZTEa9evXw9/enSJEi2erN0vF7enoqHy3kcnmmcVc/Pz9l3p07d7KtML8JD3/Avv1H8OjcDkNDQ1JTU7Wi48eRAyhRvBjTpi/I3riAeJuUhLGx+krWjHj027dJBS1JUW+Sot4//lAdFN26bTc//jiQhg3qaMXxGxgYMG/+T2zb+idXr9zI8f0pKSmsWLGR/y2eRe3aX3LmzIU806Zr76WNTUn27tlIXFw8XbsNUNujBuDECUVY4vDhE+zf/xdXrxzlTcIbli5bX2A68+sglhMnNAvluru7K1faZkW/fv2UPwAfwszMjOnTpzN9+nSN6n6XLB1/qVKlSE9PZ+TIkdjb26vkvXnzhiFDhjBx4kSqVKmS44rzk6ioJ0gkEszNzXj9OrbA67ewMGfypJEsX7EBCwszLCzMADAzM0VPTw97e1sSE9/y/PnLAtX1NPoZdpkM+pUprQgLPMkkdFAQRD+JwaXaF8Q8e6GSnvG6WLHsZynkB949PHB0qsSI4b7Y2anGbM3MTLGzK8fz5y+zdLJRUYqZF8WsrfJUmy69lxYW5gTu34yVlSXNmncmWoO6w8Luc/36Lby8PArW8RdYTbpNloO7hw8fpmPHjvz666+cPXsWV1dX6tatS926dXFzcwOgatWqyjRdoWJFe5KTk5FK47VSf7FilpibmzFu7DDCQ/+vvfsOi+Lq2zj+FRSwUMSGWDCKYkOsAWJERewdzWOL2BtGfY010Wg0IpYYNGJITDCWBHmiYo/tMYppEkVBIUpVsIBdF0MT2PePjZvgUhZhdwY4n1x7xT1z2LmZ1d/Onpk5E6J+DHPvj7GxMXExIXyz9bPCX6iEhYdH0qSxDRYWuQvpm2+2Uy+XwqXLqr3petZWudrr16sLoPcPyJcaNLDGyMiI02f28ef1X9QPgBEjh/Dn9V/o3bt7ga/xxhsNAXj4QPNgZ3HI5b00NjbmwP7tNG3amCFDxhVpWLNyZRPMzDUvQtKl7CI8yrICC3+VKlVYtGgRgYGBXLp0iT59+nD06FF9ZStUzZqa82O0adOSgQN6cvr0L2RnS/P23b//EPfhEzUeZ878SmZmJu7DJ7Lae5Pec+0LOoqhoSFTJv8zgZORkRHjPEZwMTScmzdv6T0TwJ69hwGYMCH3MZlJk0aTnZ3NT2cKvwRdF/buOczIEVM1HgCnTgUzcsRUzoeEAnn/XaxWrSqeMyfw6NETQkv4RAM5vJcGBgYEBPjh5NSBkaOmqbfFvxkbG1OtWlWNdifHDrRu3fy1htCKQ1dz9ZQ2Wp3V06xZM3bt2sWBAwfw9vYmMDCQ2bNn6/xc68Ls/v5L0tLS+f38Re7ff0jLFs2YPHkMaWnpLP5Q85J6fUlLS+fQoRMa7YMH9cE5p0Oey/ThjwuX2bP3MCtXLKRmDUtiYm8w9t3hvPFGA/r0HVX4C+hIWFgk277dzcQJo6hUqRJnz/5G586dGD3Knc2+/sTHJ+hkvdOme2Bubob53+eSu7g4U7Gi6p/El347iI6OJzo6Ps+fTUy4zZHDp9TPp04by4CBvTj242lu3bqLlVUtxnr8hwYNrJk2dUGeB2KLQw7v5fp1yxk0sDeHj5zE0tKC0aNzn00SEBCElVUtLl44yZ49h7l+PYaMjEzs7Vswduw7PHuWgtfqjXrJ+pIY6lEp0umcQ4YMwc3NDR8fHyZMmKCrTFo7eOg4o0cN5f/mTMXMrBoPHz7mwMFjfLLKh9hY+UzZICfjJ8xhxcfzGT3KHUtLCyIioxgydDxng3+TNJfnzMUkJt5m/LiRDB7Um1u37vLBh158usFPZ+ucPWdKrgud3Hq64NZTdQ504O79RRoq/P33UBwdOzBu/AgsLS1ITU0n9GI47838gDM/6eYbi9TvpYNDSwAGDujFwAG9NJYHBATx6NETAgKCcOnqzIgRgzExMebOnWR27w5itfcmEhOLN81yUYk7cKm89nz8sbGx3Lx5k44dO6ovI34dYj5+QZfEfPxFJ+dRjuLOx+9lU/A89f+2JOH7wjuVUq99AZetrS22trYlmUUQBEGnyvpBW22ViUnaBEEQtCHG+FVE4RcEodwo62fraEsUfkEQyo0ccXgXEIVfEIRyRJR9FVH4BUEoN8QYv4oo/IIglBvZYp8fEIVfEIRyROzxq4jCLwhCuSEO7qqIwi+UaXK9OhagooH87hENkJVTdi9zEmVfRRR+QRDKDTHUoyIKvyAI5YY4uKsiCr8gCOWGGONXEYVfEIRyQ5R9FVH4BUEoN8Qev4oo/IIglBvi4K6KKPyCIJQbSrHHDxRys/XSwMjIiNVeH5Bw4yIpz2L5/dcj9OrZVepYss1VtWoVli+bx+GDO0m6c4WszDssXDBT6liy3V4gj2xNmjRi587NxMae5/HjKK5ePcsnnyxS3y84L0ePfk96eiKbN6/WY1J5bK/8ZKPU+lGWlfrCv83fh7n/N43//vcgc99fzosXWRw6uBOXLk4iVx5q1rTko6Xv07p1C8LCIiTN8m9y3V5yyFa/fl1++eUwzs4d2bp1F/Pnf0xw8O/MnTuNgwd35Pkzgwf3wdGxvV7yvUrq7VWQnCI8yrLXvuduSSnOPXc7dWzL778d5YMPvVj/6RcAGBsbE375NE+ePMW584CSilkmcoFqb6xGjeokJd3DxqY+cTEhfLhkNevWb5Esk5y3ly6zaXvl7sKFM1m5chEdOvQkMjJK3b527UfMmTMFBwdXoqJi1e3GxsaEh59mx44fWL58Pl9//R2zZn2oda7iXLmr6/cyq5j33B1r4651310JQcVal5yV6j3+YcP6k52dzdff/HNT5IyMDL7dHkinTu2wsakvcr0iMzOTpKR7kq0/L3LeXnLIZmamGs5JTr6fq/3l87S0tFzt8+ZNx8DAAB+fr3Se7VVy2F4FURbhUZaV6sLf1qE1cfEJPH36LFf7hQthquVtW0sRS7a55ErO20sO2X7++TwAW7duoG3b1tSrZ8WgQb2ZO3cau3cHkZj4z15wgwbWzJ/vyZIl3qSnZ+g826vksL0KkoNS60dZVqrP6rGqW5vkPPZek5JVbdZ16+g7EiDfXHIl5+0lh2wnTpxh5coNzJ/vSf/+bur2L7/cwdy5y3L1XbPmI8LDI9mz57DOc+VFDturIOKsHpXXKvy3bt3izz//BKBVq1bUry/N17fKJiZkZGjOvvhyT6dyZRN9R1KtV6a55ErO20su2W7cSOT8+VD27/+R5OT7uLg4M2PGOP76K40lS1Rn7XTt6szQoX3p0mWQXjLlRS7bKz9ZOir8CQkJ+Pv7Ex4eTkxMDI0bN+bIkSMa/YKDg9m4cSOxsbHUqVOHcePGMXbsWI1+/v7+fP/99zx8+BBbW1sWLFiAs7Nzrj7Pnz9n3bp1nDhxgszMTBwdHVm6dKlW9bjAwr9q1SomTpyItbU1ANnZ2SxdupQDBw7w8piwgYEBw4cPZ8WKFVSooN9b2Kelp2NsbKTRbmJirFqelq7XPC/JNZdcyXl7ySHbO+8MxM9vLW3b9uDmzVsAHD58kpSUFBYvnk1AwD6uX49lw4YVBAQEERp6ReeZ8iOH7VUQXe3xx8TEEBwcjIODAzk5OeR1zszly5fx9PRk8ODBLFq0iEuXLrF69WoqVqzIqFGj1P38/f3x8fFh7ty5tGzZkj179jB16lT27NlD8+bN1f3mzZtHZGQkH330EdWqVePzzz9n/PjxHD58mMqVKxeYt8Ax/pefOC/5+flx6NAhZs6cydGjRzl69CjTp09n37597NiR92llupScdB+rPL461rVStd2V6CCmXHPJlZy3lxyyTZvmwZUr19RF/6VDh05iYGCAs3Mn3n13GM2aNeabb77Hxqa++gFgaloVG5v6etnblsP2KoiuTud0dXUlODiYzz//nFatWuXZZ8uWLbRs2ZLVq1fj5OSEp6cnw4cPZ8uWLeTkqNaYmZmJn58fHh4eTJo0CWdnZ9avX0+DBg3w8/NTv1Z4eDhnz57Fy8uLAQMG0K1bN3x9fUlKSiIoqPCzkQos/K9+au3fvx8PDw/ee+89mjRpQpMmTZg9ezajRo1i3759ha6spIWHR9KksQ0WFua52t98s516uRTkmkuu5Ly95JCtdu2aVKyo+eW8YkVD9f8bNKiHkZERZ8/uJyrqN/UDYOTIoURF/UafPq46zyqH7VUQpVKp9aMoDAwKPk8mMzOT8+fP069fv1ztAwYM4MGDB0RGqrbLpUuXSElJoX///uo+hoaG9O3bl3PnzqlzBQcHY2pqSpcuXdT9rK2tad++PefOnSs8r9a/GZCUlISLi4tGu4uLCwkJCUV5qRKxL+gohoaGTJk8Rt1mZGTEOI8RXAwN19hDKu+55ErO20sO2aKj47G3b06LFs1ytY8apTon/fLlq/zwwyHeeWeyxgPg5MmzvPPOZM6fD9V5Vjlsr4JIdVZPYmIiL168oEmTJrnamzZtCkB8fDwAcXFxABr9bG1tSU1N5d69e+p+jRs31vjAsbW1Vb9WQQo9uPv8+XOePn0KgKWlJdnZmhd3KJVKDA31fxu5Py5cZs/ew6xcsZCaNSyJib3B2HeH88YbDejTd1ThL1DOcr3kOWM8FhbmWPx9uX+3rm+p9yh9t2xDoUjRax45by85ZPPx+Yrevbtx6tQPfPnlDpKTH9Ct21sMHz6AU6eCCQm5BEB0dFyeP5+QcJvDh0/qJasctldBijIVg0KhQKFQaLSbmZmpr63Q1rNnz9Q/++pr/Xu5QqHAyMgIE5Pcw3Lm5qpvUE+fPsXKygqFQoGpqWme2V6+VkEKLfyTJk1S/1mpVHLlyhXefvvtXH2io6OxsrIqdGW6MH7CHFZ8PJ/Ro9yxtLQgIjKKIUPHczb4N0nyyD0XwPtzp9OoUQP18169utGrVzcAvg/Yp/fCD/LeXlJn+/XXP3BxGcLSpXMZP34ktWvX4O7dZNav/wIvLx+9ZCgKqbdXQYqyJ79jxw58fX012t977z1mzZpVkrH0rsDC7+3trdFWq1Ytjbbz58/nOQSkDxkZGSz+wIvFH3hJsv78yDUXgG0z6edMeZWct5ccsl2+fJVhwyYW+edMTBrqIE3B5LC98lOUsftx48YxdOhQjfai7u3DP3vsr36DePn85XIzMzMyMzPJyMjA2NhY3e/lXryFhYW6X1JSksZ6FAqF+rUKUmDhz+uXzou/v79W/QRBEKRUlLN1XmdIJz8NGzakUqVKxMfH59pJjo1VzbHUuHFj4J+x/bi4OFq2bKnuFxcXR9WqValTp46632+//YZSqcx1Gn1sbKz6tQpSqqdsEARBKAplEf4rSUZGRjg5OXHs2LFc7UeOHKFWrVrqU0Dbt2+PqakpP/74o7pPdnY2x44do0uXLuoi37VrVxQKBT///LO6X1JSEpcuXdJq9KVUT9kgCIJQFLqagyctLY3g4GAA7ty5w/Pnzzl+/DgA9vb21KtXj5kzZ/Luu++ydOlSBg4cyKVLl9izZw/Lli1Tn51jZGTEjBkz8PHxwdLSUn0BV2JiIhs2bFCvz8HBgW7durFkyRIWL15MtWrV2LRpE3Xr1sXdvfAZSEv1tMyCUJppOy2zvhVnWmZdK+60zN3r99S675nbp7Tue/v2bXr06JHnMm9vb3UxDg4O5rPPPiMuLo7atWszfvx4PDw8NH7G39+f7777jocPH9K0adMCp2w4fvx4rikbGjRooPF6rxKFXxAkIgp/0RW38Her71Z4p7+dvf2/Yq1LzsRQjyAI5UaOtPu5siEKvyAI5YYo+yqi8AuCUG6U9RusaEsUfkEQyg1R+FVE4RcEicj1IGra3Z8L71RKZSuLOuFy2SQKvyAI5Ya49aKKKPyCIJQbEp+9Lhui8AuCUG6IMX4VUfgFQSg3xB6/iij8giCUG9lFvptu2SQKvyAI5Ya4cldFFH5BEMoNcVaPSqmej9//Gx+yMu/k+3jLuaPOM1StWoXly+Zx+OBOku5cISvzDgsXzNQ6a8TVYJ1nfKljBwc2bVxFeNhPPHsSQ3zsH+wO+JKmTQu/cYOuGRkZsdrrAxJuXCTlWSy//3qEXj276jWDtu8lQPPmthw5tIsnj6K4nxzBzh2bqV27pmzzasvExJDWnfvm+QiPuKbu92tIKMu8N+I+zhMHl/607z4oz9eLT7jFhi3+DBs3kzfd3Ok2aDQz5i8j4lq0Rt9TZ39l3kfe9HlnAh1dhzBg5GTWb/4aRcrzYv1O/5ajVGr9KMtK9R7/119/x+mfNC82Wb92GRUrVuTCxXCdZ6hZ05KPlr7PrVt3CQuLoGcBxSozM5PJU+flalM809/9bRcsmMlbzh3Zu+8IV69ew8qqNp4zxnMh5DhvuwwiIuK63rK8apu/D8Pc+7N5sz/RMfF4jH2HQwd30qv3CM79fF4vGbR9L+vVq8uZ00EoFCl8tGwtVatWYd7707G3b4GTc38yMjJklfd1jHIfSJvWzXO1Naxvrf7zj6fOcux0MM1tG2NtVYd7Dx7m+Tr7Dh9n/5GTuHXtzEj3/qQ8T2XPwR8ZM20ufp9+wltvtlf3XbHuc2rVtGRAr+5Y1alNTPxNAvYd4txvf/DDt5up/MoNyF+H2ONXKdWF/3xIKOdDQnO1NW9uS506tfhq6y5evHih8wxJSfdpYNOepKR72NjUJy4mJN++OTk5BAQE6TxTfjZu3Mq7Y2fm2i4/7DlE2KX/sXjRLN4dW7y9xdfVqWNbRo4YwgcferH+0y8A2PXdXsIvn2btmqU4dx6glxzavpeLF83C1LQqjs59SUxUTRN88WI4J44HMmH8SL78aoes8r6Odg4t6efWLd/lc6aN5+NFs6lUqRJLVm3g2Om8v7n2c+vGzInvUqVKZXWb+4BeDBo9lS3f7MpV+D9btYQ327fJ9fMt7WxZsmoDh4//xH+G9CveL4UY43+pVA/15GXM6GEABATs08v6MjMzSUq6p3X/ChUqUK1aVR0myt/v5y9qfBjGxt4g8s9oWrRoJkkmgGHD+pOdnc3X33yvbsvIyODb7YF06tQOG5v6esmh7XvpPrQfx47/pC76AKd/+pmo6DjeGa6fDyko+t+9okpNTSMrK+9pJWrXqkGlSpUKfY1WzZvmKvoAFuZmtHdoTdzNxFztrxZ9ADeXtwA0+r6ubGWO1o+yrMwV/pEjhhAfn8Cvv12QOooGIyMjnjyK4unjaB7ci8R3s7dkHwL/Vqd2LR49fCzZ+ts6tCYuPoGnT5/lar9wIUy1vG1rKWLlydraijp1ahEaekVj2YULYbLKWhwfr/mcN3u608F1EOPfW8jVP6NK9PUfPn6ChXnhNzJ/+PgJANW16KsNqe65KzeleqjnVZ3f6sQbbzTEa/VGqaNoSE6+x6cbvuDS5QgMDCrQu1d3pk/zoK1DK7q5upOVlSVJrtGj3alfvy6frPpMkvUDWNWtTXIee65Jyao267p19B0pX3WtagPkuaednHwPc3MzqlSpTGpqmr6jlQilUknPbp3p4tyJ6ubmxN1MZPvufYybuYAdX6zHvoVdsdcRGhZBeMQ1Jo/9T6F9/b/bg4GBAb1cuxR7vQDKMr4nr60CC//Tp0/JzMykdu3a6ra7d+/i7+9PdHQ0mZmZtG7dmvHjx2t1n0ddG/33MM/3Eo6j52fJ0jW5nv/wwyFiYuJZ9cli/vOfQZKM/dvZNWHzJi/Onw/l2+2Bel//S5VNTMjIyNRoT09XHSStXLn4B/VKysssGZkF5y2thT8jIwcfr6Xq5927ONGr+9u4e3iy6cvtfLPJu1iv/+jJUxauWEu9unWYMnZEgX2PnjxD0JETTBg9nMY2JVNfxJQNKgUO9cybNw9/f3/18wsXLtCvXz+OHz+OqakpNWrU4NixYwwePJg///xT52ELUqlSJYYPG8CFi2FER8dJmkVbGzd9TXZ2Nj1KaG+mKOrUqcWhAzt59iyFd0ZMISdHuj2htPR0jI2NNNpNTIxVy9PS9R0pXy+zGBuVjrwloWF9a7p3ceJiWAQvivHNNDUtnZkLlpOamsbmtcs1xv7/LTQsgmXeG+ns2IE508a/9jpfpVQqtX6UZQXu8UdERDB69Gj183Xr1tGuXTv8/Pww+fvUqtTUVKZNm8a6devYvn27TsMWpG9fV2rUqM4qLx/JMhRVeno6jx49wdLSQq/rNTMz5cjh77CwMKeb61CdHiDURnLSfRrmcQC3rpVqiOeuxPn+LSn5PgB18xh+srKqw7NnilK7t18Qq9q1yMrKIjU1DXMz0yL//IsXL/i/Dz8hOu4GX322iqaNG+Xb93pMPLMWr8C2sQ0+q5ZQsWLJ3ZRe7PGrFLjHn56ejpnZPwdVrl27xqRJk9RFH6BKlSpMnDiRsLAw3aXUwuhR7rx48YLA/x6QNEdRVKtWlZo1LXnw4JHe1mlsbMzB/dtp1rQxg4eM49q1GL2tOz/h4ZE0aWyDhYV5rvY332ynXi4Xd+8mc//+Qzp00DwDpVOntrLKWpJu302iUqWKVK1Spcg/m5OTwweffEpIaBhrly+iUzvNbfdS4u27TJ+3FEsLc/w+XVngt4LXkZ2To/WjLCuw8Ddp0oTLly+rn1tYWPDXX39p9EtNTcXY2Ljk02nJzMyU/v168L//ndNrEdWWsbFxnmfvLF3yfxgYGHDi5Fm95DAwMGB3gB9OTh0YOWqaxjUQUtkXdBRDQ0OmTB6jbjMyMmKcxwguhoZz8+YtCdNpCtr/I337uNKwYT11m2v3t7Fr1oS9+45ImKz4DPKoCNdj4jnzSwhOHdu91t73ah8/jp8+x9J5M+nZrXO+/R4+eszUuUswqGDAVz5eWFYv+W/C4qwelQKHejw8PFi5ciV2dnZ07dqVMWPGsGHDBho1aoSdnero/rVr19i4cSOurq56CZyXYe79qVy5Mt/vluagrueM8VhYmKtPT+vW9S0qVlRtWt8t26he3ZyLf5wg8L8HiYqKBaBXz27069eDU6eCCQo6qpec69ctZ9DA3hw+cpLqlhaMHu2ea7lUF5f9ceEye/YeZuWKhdSsYUlM7A3GvjucN95oQJ++o/SapbD3UqFIYc3azQwfNoBTJ35gs68/VapUZt77M4j8Mwr/bbtll7corGqbMGP+Mtrat6BGdQvibiSy99AxTIyNmOc5Sd0vKvYGZ39RXVEdHXeDnOwcvtqu+t3tbN+g29tOAOz6734Cg47g0LoFJiYmHD7xU6719XB5iyp/HzCf9v5H3L6bzMQxw7l0JZJLV/759lSjukWui71eV1kfu9dWBWUhW8LPz48tW7ZQr1497Ozs+OWXX0hLS8PCQvVp/PTpU+zt7dm6dau6rSgqGtUrvFMhTp34gY4dHbCu7yDJgbXY6PM0apT3WQdNmjry9KmCTRtX4fhme6yt62BoaEBs3E0CAw+w4bMv9XKFMcDpU3vo2vWtfJeXxHvxuoyNjVnx8XxGj3LH0tKCiMgoPv54PcdPnNFrjsLey4SE2wC0bNmM9WuX0bnzm7x48YLjJ84wf8EK7t17oM+4WufVlrlZJbp3aUPi7bv89VcqFhZmOHZoi+fEMdg0+Ofvx4Gjp1i6Ou9TgAf3dcNrqWpqkiWrNnDw2P/yXd+Jvdup9/fxktad++bbr2M7e7b7rqNSzeLNK1XLXPsxgSfqAAAIWklEQVTTUR88K9lrF+Sk0MIPEB8fT1BQEOHh4Tx8+JCcnBzMzc2xtbWle/fuuLm5UaFChdcKIGWxEQRBk5xvtl7cwl/TTPsr1B8qNCeSKyu0Kvy6JAq/IMhLWS781avZat33yfPYYq1LzsrUlbuCIAgFEadzqojCLwhCuSEO7qqIwi8IQrkhpmVWKXOzcwqCIORHl+fx37x5k0mTJtGuXTucnJz45JNPSEuT51XcYo9fEIRyQ1d7/AqFAg8PD6ytrdm0aROPHz/G29ubx48f4+Mjv2lkROEXBKHcyNHRtMyBgYEoFAoOHDiApaUlAIaGhsyfPx9PT0+aNm2qk/W+LjHUIwhCuaGr2TnPnTuHk5OTuugD9O7dGyMjI86dO1fSv0axiT1+QRDKjaIUdIVCgUKh0Gg3MzPLNXklQFxcHMOGDcvVZmRkRMOGDYmPj3+9sDokeeHPyrxTeCdBEIQS8KII9Wbz5s34+vpqtL/33nvMmjUrV5tCodD4MADVh8SzZ8802qUmeeEXBEGQo3HjxjF06FCN9rwKfGkjCr8gCEIe8hrSKahvXsNCCoWCxo2LN82ELoiDu4IgCMXUpEkT4uJy3/I1MzOTxMREUfgFQRDKIhcXF86fP8+TJ0/UbadOnSIzM5OuXbtKmCxvks/OKQiCUNopFAoGDBhAvXr18PT05NGjR6xZswZnZ2dZXsAlCr8gCEIJuHHjBqtWrSI0NBRjY2P69+/PggULqFy5ZO8bXBJE4RcEQShnxBi/IAhCOSMKvyAIQjlT6gu/XKdCTUhIYNmyZQwePJiWLVsyYMAAqSMBcOzYMTw9PenatStt27Zl4MCBBAQEkJOjm8mrtHXy5ElGjRqFo6Mj9vb2uLm5sXbtWlJSUiTN9aq//voLFxcX7OzsuHr1qmQ5goKCsLOz03isXLlSskyvOnDgAO7u7rRp0wZHR0cmTJjA48ePpY4lUMov4JLzVKgxMTEEBwfj4OBATk6ObO788+2332Jtbc3ChQupUaMGISEheHl5cevWLRYtWiRZrmfPntGpUycmTJiAubk5UVFR+Pr6EhUVxbZt2yTL9SpfX1+ys7OljqH2zTffYGpqqn5es2ZNCdP8w8/Pj61btzJ16lQWLVpESkoKISEhvHjxQupoAoCyFPvqq6+UDg4OykePHqnbDh06pGzWrJkyOjpawmRKZXZ2tvrPixYtUvbv31/CNP/497Z6afXq1Up7e3tlRkaGBInyFxgYqGzWrJkyOTlZ6ihKpVKpjIqKUrZt21ad68qVK5Jl2bdvn7JZs2Z5vp9Si4uLU7Zs2VL5008/SR1FyEepHuqR81SoBgby3LT/3lYvtWjRgoyMDJ4+fSpBovxVr14dQDZ7iStXrmTMmDE0atRI6iiyFhQUhLW1Nd27d5c6ipAPeVYnLcXFxWFra5urTc5TocpVaGgoFhYW1KhRQ+ooZGdnk5GRQUREBFu2bMHV1ZX69etLHYsDBw6QkJDAjBkzpI6Sy8CBA2nRogWurq74+vqSlZUldSTCw8Oxs7Pjiy++oHPnzrRq1Yrhw4fzxx9/SB1N+FupH+MvTVOhytHVq1cJCgpi5syZGBoaSh0HR0dH9QHdLl26sGHDBokTQUpKCuvXr2fRokVUrVpV6jgA1KpVi1mzZtGmTRsMDQ05d+4cX3zxBbdv32bNmjWSZnvw4AERERFcv36dJUuWUK1aNbZt28bkyZP58ccfZfFBXt6V6sIvFM+DBw+YPXs29vb2TJkyReo4AOzatYu0tDRiYmLw8/Nj+vTpfPvtt5J+KG3cuBEbGxsGDRokWYZXdenShS5duqifd+7cGVNTUzZv3oynpycNGzaULJtSqSQ1NZWAgABatGgBQKdOnejRowf+/v4sX75csmyCSqke6iloKlRzc3MJEpUeKSkpTJkyBRMTE/z8/KhUqZLUkQDV8Yb27dszYsQIfH19CQkJ4dSpU5LliYmJITAwkDlz5qjvyJSamgpAamoqz58/lyzbq/r27QtAZGSkpDnMzMywsLBQF32AypUr4+DgQExMjITJhJdK9R5/QVOhuru7S5RK/jIyMpgxYwaPHj0iMDBQfRBVblq0aIGBgQGJiYmSZUhISCArKwsPDw+NZR4eHjRv3pyDBw9KkEy+bG1t833PMjIy9JxGyEupLvwuLi74+fnx5MkTdfGS81SocpCVlcWcOXOIiopi165d1KtXT+pI+bp8+TI5OTmSjgm3b9+enTt35mq7du0a3t7erFixglatWkmUTNPRo0epUKECrVu3ljRH9+7dCQoKIjIyUr19UlNTCQsLo3fv3pJmE1RKdeEfOXIk3333HZ6enrmmQu3Xr5/G2T76lpaWRnBwMAB37tzh+fPnHD9+HAB7e3vJCu7KlSs5c+YMCxYsID09nbCwMPUyW1tbqlWrJkmuSZMm4eTkRNOmTTE2NubatWv4+/tjZ2eHm5ubJJlAdfqro6NjnstatWqFvb29nhOpTJo0CUdHR5o1a0aFChX4+eefCQgIYPjw4TRo0ECSTC+5ubnRpk0bZs+ezdy5c6latSrbtm0jPT2dCRMmSJpNUCn1s3PKdSrU27dv06NHjzyXeXt7SzYU5erqyp07ed9weufOnfkWOV3buHEjp0+f5vbt2wDUr1+fXr16MWHCBMk+jPITEhKCh4cHe/fulazwe3l5ce7cOe7du0dWVhaNGjXC3d2dcePGyeLsrMePH7Nu3TpOnz5NRkYGDg4OLFy4ULLtJeRW6gu/IAiCUDSl+qweQRAEoehE4RcEQShnROEXBEEoZ0ThFwRBKGdE4RcEQShnROEXBEEoZ0ThFwRBKGdE4RcEQShnROEXBEEoZ/4fLs2uyp107GUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = classification_report(labels, predictions, target_names=['B_LOC', 'B_ORG', 'B_PER', 'I_LOC', 'I_ORG', 'I_PER', 'O'])\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5b86ed-8b73-4291-f305-faf2f4c31bfa",
        "id": "DgQts1vr39MB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B_LOC       0.92      0.93      0.92       201\n",
            "       B_ORG       0.83      0.84      0.84       137\n",
            "       B_PER       0.96      0.98      0.97       126\n",
            "       I_LOC       0.69      0.43      0.53        42\n",
            "       I_ORG       0.86      0.79      0.82       183\n",
            "       I_PER       0.95      0.99      0.97        85\n",
            "           O       0.99      0.99      0.99      5157\n",
            "\n",
            "    accuracy                           0.98      5931\n",
            "   macro avg       0.89      0.85      0.86      5931\n",
            "weighted avg       0.98      0.98      0.98      5931\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence = \"Николай вчера был в Москве\"\n",
        "model.eval()\n",
        "def inference(sentence):\n",
        "    inputs = tokenizer(sentence,\n",
        "#                         is_split_into_words=True, \n",
        "                        return_offsets_mapping=True, \n",
        "                        padding='max_length', \n",
        "                        truncation=True, \n",
        "                        max_length=config['max_length'],\n",
        "                        return_tensors=\"pt\")\n",
        "\n",
        "    # move to gpu\n",
        "    ids = inputs[\"input_ids\"].to(device)\n",
        "    mask = inputs[\"attention_mask\"].to(device)\n",
        "    # forward pass\n",
        "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
        "    logits = outputs[0]\n",
        "\n",
        "    active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "    token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
        "    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "    prediction = []\n",
        "    out_str = []\n",
        "    off_list = inputs[\"offset_mapping\"].squeeze().tolist()\n",
        "    for idx, mapping in enumerate(off_list):\n",
        "#         print(mapping, token_pred[1], token_pred[0],\"####\")\n",
        "\n",
        "#         only predictions on first word pieces are important\n",
        "        if mapping[0] != 0 and mapping[0] != off_list[idx-1][1]:\n",
        "#             print(mapping, token_pred[1], token_pred[0])\n",
        "            prediction.append(wp_preds[idx][1])\n",
        "            out_str.append(wp_preds[idx][0])\n",
        "        else:\n",
        "            if idx == 1:\n",
        "                prediction.append(wp_preds[idx][1])\n",
        "                out_str.append(wp_preds[idx][0])\n",
        "            continue\n",
        "    return prediction, out_str"
      ],
      "metadata": {
        "id": "ISl4nJlF39MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = pd.read_csv(\"/content/drive/MyDrive/kaggle HW2/test.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "ynHIu78f39MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "afd3f2a1-2411-4146-f73c-ab3287296acc",
        "id": "A1SLn1ho39MC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf\n",
              "0                                  Александр Вертинский  False\n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False\n",
              "2                Слишком много « пустого » пространства   True\n",
              "3                  И он научился заполнять его вымыслом   True\n",
              "4     Создал собственный театр с безумным множеством...   True\n",
              "...                                                 ...    ...\n",
              "2709  В частности , мы исключили большинство эксперт...   True\n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True\n",
              "2711  Также один из законов , который принят в этом ...  False\n",
              "2712    Там соответственно тоже все поручения выполнены   True\n",
              "2713                                 В . Путин : Хорошо  False\n",
              "\n",
              "[2714 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5455801a-df55-4b45-9801-d3899a5f8398\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5455801a-df55-4b45-9801-d3899a5f8398')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5455801a-df55-4b45-9801-d3899a5f8398 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5455801a-df55-4b45-9801-d3899a5f8398');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['predict'] = test_texts['text'].apply(inference)"
      ],
      "metadata": {
        "id": "KHxc2lPI39MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame(test_texts['predict'].to_list(), columns=['pred_labels','pred_words'])"
      ],
      "metadata": {
        "id": "pUgWQIOa39MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "b6432b49-b2c2-404d-ac22-96d1f743eb5c",
        "id": "w02zYc5p39MC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            pred_labels  \\\n",
              "0                                        [B_PER, I_PER]   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2                                    [O, O, O, O, O, O]   \n",
              "3                                    [O, O, O, O, O, O]   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "...                                                 ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2712                                 [O, O, O, O, O, O]   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]   \n",
              "\n",
              "                                             pred_words  \n",
              "0                                     [Александр, Верт]  \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...  \n",
              "2         [Слишком, много, «, пустого, », пространства]  \n",
              "3                 [И, он, научился, заполня, его, вымы]  \n",
              "4     [Создал, собственный, театр, с, безум, множест...  \n",
              "...                                                 ...  \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...  \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...  \n",
              "2711  [Также, один, из, законов, ,, который, принят,...  \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...  \n",
              "2713                           [В, ., Путин, :, Хорошо]  \n",
              "\n",
              "[2714 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c74d852-694e-446c-bb4f-9a981feaf10a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_labels</th>\n",
              "      <th>pred_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>[Александр, Верт]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>[И, он, научился, заполня, его, вымы]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[Создал, собственный, театр, с, безум, множест...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c74d852-694e-446c-bb4f-9a981feaf10a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c74d852-694e-446c-bb4f-9a981feaf10a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c74d852-694e-446c-bb4f-9a981feaf10a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['predicted_labels'] = df3['pred_labels'].apply(\" \".join)"
      ],
      "metadata": {
        "id": "yJAfsiQY39MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "6300281b-d7a5-42f7-f5a1-5da8bb95ec1b",
        "id": "CtwJxwjb39MC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  \n",
              "0                                           B_PER I_PER  \n",
              "1     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2                                           O O O O O O  \n",
              "3                                           O O O O O O  \n",
              "4     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "...                                                 ...  \n",
              "2709  O O O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2710      O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2711  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2712                                        O O O O O O  \n",
              "2713                              B_PER I_PER I_PER O O  \n",
              "\n",
              "[2714 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-304cbd0f-6ba2-451c-ad80-b11d12f92df9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>B_PER I_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>B_PER I_PER I_PER O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-304cbd0f-6ba2-451c-ad80-b11d12f92df9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-304cbd0f-6ba2-451c-ad80-b11d12f92df9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-304cbd0f-6ba2-451c-ad80-b11d12f92df9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = test_texts.text.str.split(expand=True).stack()\n",
        "labels = test_texts.predicted_labels.str.split(expand=True).stack()\n",
        "\n",
        "s = pd.DataFrame({\n",
        "    'Sentence': words.index.get_level_values(0) + 1, \n",
        "    'Word': words.values,\n",
        "    'Label': labels.values,\n",
        "})\n",
        "s.head(5)\n",
        "frequencies = s.Label.value_counts()\n",
        "frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a222c8-ae06-4dbb-d573-485095296c23",
        "id": "thlFYgPI39MC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        49708\n",
              "B_ORG     1621\n",
              "I_ORG     1528\n",
              "B_PER     1309\n",
              "B_LOC     1206\n",
              "I_PER      810\n",
              "I_LOC      227\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LPSZyw84P8Af",
        "outputId": "3287eb43-96fc-4fef-db18-00e428f34ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sentence        Word  Label\n",
              "0         1   Александр  B_PER\n",
              "1         1  Вертинский  I_PER\n",
              "2         2           «      O\n",
              "3         2           Я      O\n",
              "4         2          не      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c67509b-197b-42c1-ab52-ebe601141986\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Александр</td>\n",
              "      <td>B_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Вертинский</td>\n",
              "      <td>I_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>«</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Я</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>не</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c67509b-197b-42c1-ab52-ebe601141986')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c67509b-197b-42c1-ab52-ebe601141986 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c67509b-197b-42c1-ab52-ebe601141986');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.to_csv(\"my_submission.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "hge0mks539MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['len_labels'] = test_texts['predicted_labels'].str.len()"
      ],
      "metadata": {
        "id": "xqvIROfG39MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['word_sent'] = test_texts['text'].str.split()"
      ],
      "metadata": {
        "id": "omplSYdK39MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['len_sentence'] = test_texts['word_sent'].str.len()\n",
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8d86dffc-9694-4b43-8319-19202c7b8c1d",
        "id": "t4JtaxdS39MC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  len_labels  \\\n",
              "0                                        [B_PER, I_PER]           2   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          46   \n",
              "2                                    [O, O, O, O, O, O]           6   \n",
              "3                                    [O, O, O, O, O, O]           6   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          28   \n",
              "...                                                 ...         ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          25   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          23   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          28   \n",
              "2712                                 [O, O, O, O, O, O]           6   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]           5   \n",
              "\n",
              "                                              word_sent  len_sentence  \n",
              "0                               [Александр, Вертинский]             2  \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...            46  \n",
              "2         [Слишком, много, «, пустого, », пространства]             6  \n",
              "3           [И, он, научился, заполнять, его, вымыслом]             6  \n",
              "4     [Создал, собственный, театр, с, безумным, множ...            28  \n",
              "...                                                 ...           ...  \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...            25  \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...            23  \n",
              "2711  [Также, один, из, законов, ,, который, принят,...            28  \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...             6  \n",
              "2713                           [В, ., Путин, :, Хорошо]             5  \n",
              "\n",
              "[2714 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56e180cb-6bb6-4483-879d-78a57925adba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>len_labels</th>\n",
              "      <th>word_sent</th>\n",
              "      <th>len_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56e180cb-6bb6-4483-879d-78a57925adba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56e180cb-6bb6-4483-879d-78a57925adba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56e180cb-6bb6-4483-879d-78a57925adba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = test_texts[(test_texts['len_sentence'] != test_texts['len_labels'])]"
      ],
      "metadata": {
        "id": "rFNsj6ku39MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a9c164f1-35b2-476f-9dfb-59488ecb3333",
        "id": "dPJGGesu39MD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [text, clf, predict, predicted_labels, len_labels, word_sent, len_sentence]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5294311-7d72-40a5-b5eb-17ec95cf2001\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>len_labels</th>\n",
              "      <th>word_sent</th>\n",
              "      <th>len_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5294311-7d72-40a5-b5eb-17ec95cf2001')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5294311-7d72-40a5-b5eb-17ec95cf2001 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5294311-7d72-40a5-b5eb-17ec95cf2001');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts['str_pred_labels'] = test_texts['predicted_labels'].apply(\" \".join)"
      ],
      "metadata": {
        "id": "LjVq5ZdH39MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "787c9412-b1f2-4db6-c5cb-0814165f4e4a",
        "id": "wGGSWl9o39MD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text    clf  \\\n",
              "0                                  Александр Вертинский  False   \n",
              "1     « Я не знаю , зачем и кому это нужно … » 21 ма...  False   \n",
              "2                Слишком много « пустого » пространства   True   \n",
              "3                  И он научился заполнять его вымыслом   True   \n",
              "4     Создал собственный театр с безумным множеством...   True   \n",
              "...                                                 ...    ...   \n",
              "2709  В частности , мы исключили большинство эксперт...   True   \n",
              "2710  На наш взгляд , это очень важно , особенно , у...   True   \n",
              "2711  Также один из законов , который принят в этом ...  False   \n",
              "2712    Там соответственно тоже все поручения выполнены   True   \n",
              "2713                                 В . Путин : Хорошо  False   \n",
              "\n",
              "                                                predict  \\\n",
              "0                   ([B_PER, I_PER], [Александр, Верт])   \n",
              "1     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2     ([O, O, O, O, O, O], [Слишком, много, «, пусто...   \n",
              "3     ([O, O, O, O, O, O], [И, он, научился, заполня...   \n",
              "4     ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "...                                                 ...   \n",
              "2709  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2710  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2711  ([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...   \n",
              "2712  ([O, O, O, O, O, O], [Там, соответственно, тож...   \n",
              "2713  ([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...   \n",
              "\n",
              "                                       predicted_labels  len_labels  \\\n",
              "0                                        [B_PER, I_PER]           2   \n",
              "1     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          46   \n",
              "2                                    [O, O, O, O, O, O]           6   \n",
              "3                                    [O, O, O, O, O, O]           6   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          28   \n",
              "...                                                 ...         ...   \n",
              "2709  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          25   \n",
              "2710  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          23   \n",
              "2711  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...          28   \n",
              "2712                                 [O, O, O, O, O, O]           6   \n",
              "2713                        [B_PER, I_PER, I_PER, O, O]           5   \n",
              "\n",
              "                                              word_sent  len_sentence  \\\n",
              "0                               [Александр, Вертинский]             2   \n",
              "1     [«, Я, не, знаю, ,, зачем, и, кому, это, нужно...            46   \n",
              "2         [Слишком, много, «, пустого, », пространства]             6   \n",
              "3           [И, он, научился, заполнять, его, вымыслом]             6   \n",
              "4     [Создал, собственный, театр, с, безумным, множ...            28   \n",
              "...                                                 ...           ...   \n",
              "2709  [В, частности, ,, мы, исключили, большинство, ...            25   \n",
              "2710  [На, наш, взгляд, ,, это, очень, важно, ,, осо...            23   \n",
              "2711  [Также, один, из, законов, ,, который, принят,...            28   \n",
              "2712  [Там, соответственно, тоже, все, поручения, вы...             6   \n",
              "2713                           [В, ., Путин, :, Хорошо]             5   \n",
              "\n",
              "                                        str_pred_labels  \n",
              "0                                           B_PER I_PER  \n",
              "1     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2                                           O O O O O O  \n",
              "3                                           O O O O O O  \n",
              "4     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "...                                                 ...  \n",
              "2709  O O O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2710      O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "2711  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2712                                        O O O O O O  \n",
              "2713                              B_PER I_PER I_PER O O  \n",
              "\n",
              "[2714 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dda09f52-730e-4aa1-a430-1f3e48c5c791\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>predict</th>\n",
              "      <th>predicted_labels</th>\n",
              "      <th>len_labels</th>\n",
              "      <th>word_sent</th>\n",
              "      <th>len_sentence</th>\n",
              "      <th>str_pred_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Александр Вертинский</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER], [Александр, Верт])</td>\n",
              "      <td>[B_PER, I_PER]</td>\n",
              "      <td>2</td>\n",
              "      <td>[Александр, Вертинский]</td>\n",
              "      <td>2</td>\n",
              "      <td>B_PER I_PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>« Я не знаю , зачем и кому это нужно … » 21 ма...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>46</td>\n",
              "      <td>[«, Я, не, знаю, ,, зачем, и, кому, это, нужно...</td>\n",
              "      <td>46</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Слишком много « пустого » пространства</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Слишком, много, «, пусто...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Слишком, много, «, пустого, », пространства]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>И он научился заполнять его вымыслом</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [И, он, научился, заполня...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[И, он, научился, заполнять, его, вымыслом]</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Создал собственный театр с безумным множеством...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Создал, собственный, театр, с, безумным, множ...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2709</th>\n",
              "      <td>В частности , мы исключили большинство эксперт...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>[В, частности, ,, мы, исключили, большинство, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>На наш взгляд , это очень важно , особенно , у...</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>23</td>\n",
              "      <td>[На, наш, взгляд, ,, это, очень, важно, ,, осо...</td>\n",
              "      <td>23</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>Также один из законов , который принят в этом ...</td>\n",
              "      <td>False</td>\n",
              "      <td>([O, O, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>28</td>\n",
              "      <td>[Также, один, из, законов, ,, который, принят,...</td>\n",
              "      <td>28</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>Там соответственно тоже все поручения выполнены</td>\n",
              "      <td>True</td>\n",
              "      <td>([O, O, O, O, O, O], [Там, соответственно, тож...</td>\n",
              "      <td>[O, O, O, O, O, O]</td>\n",
              "      <td>6</td>\n",
              "      <td>[Там, соответственно, тоже, все, поручения, вы...</td>\n",
              "      <td>6</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>В . Путин : Хорошо</td>\n",
              "      <td>False</td>\n",
              "      <td>([B_PER, I_PER, I_PER, O, O], [В, ., Путин, :,...</td>\n",
              "      <td>[B_PER, I_PER, I_PER, O, O]</td>\n",
              "      <td>5</td>\n",
              "      <td>[В, ., Путин, :, Хорошо]</td>\n",
              "      <td>5</td>\n",
              "      <td>B_PER I_PER I_PER O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2714 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dda09f52-730e-4aa1-a430-1f3e48c5c791')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dda09f52-730e-4aa1-a430-1f3e48c5c791 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dda09f52-730e-4aa1-a430-1f3e48c5c791');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(sentence):\n",
        "    labels_dict = {\n",
        "    'O': 1,\n",
        "    'B_ORG': 2,\n",
        "    'I_ORG': 3,\n",
        "    'B_LOC': 4,\n",
        "    'I_LOC': 5,\n",
        "    'B_PER': 6,\n",
        "    'I_PER': 7\n",
        "}\n",
        "    return labels_dict[sentence]"
      ],
      "metadata": {
        "id": "8p4GhGvX39MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv(\"/content/my_submission.csv\", sep=\"\\t\")\n",
        "sub['Predicted'] = sub['Label'].apply(encode)\n",
        "sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c39beda1-dbb3-4867-af1f-12852027fed7",
        "id": "UvLTW91M39MD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  Sentence        Word  Label  Predicted\n",
              "0               0         1   Александр  B_PER          6\n",
              "1               1         1  Вертинский  I_PER          7\n",
              "2               2         2           «      O          1\n",
              "3               3         2           Я      O          1\n",
              "4               4         2          не      O          1\n",
              "...           ...       ...         ...    ...        ...\n",
              "56404       56404      2714           В  B_PER          6\n",
              "56405       56405      2714           .  I_PER          7\n",
              "56406       56406      2714       Путин  I_PER          7\n",
              "56407       56407      2714           :      O          1\n",
              "56408       56408      2714      Хорошо      O          1\n",
              "\n",
              "[56409 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f92d7a3-eae6-47d3-b86f-57bf15760ec6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Александр</td>\n",
              "      <td>B_PER</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Вертинский</td>\n",
              "      <td>I_PER</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>«</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Я</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>не</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56404</th>\n",
              "      <td>56404</td>\n",
              "      <td>2714</td>\n",
              "      <td>В</td>\n",
              "      <td>B_PER</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56405</th>\n",
              "      <td>56405</td>\n",
              "      <td>2714</td>\n",
              "      <td>.</td>\n",
              "      <td>I_PER</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56406</th>\n",
              "      <td>56406</td>\n",
              "      <td>2714</td>\n",
              "      <td>Путин</td>\n",
              "      <td>I_PER</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56407</th>\n",
              "      <td>56407</td>\n",
              "      <td>2714</td>\n",
              "      <td>:</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56408</th>\n",
              "      <td>56408</td>\n",
              "      <td>2714</td>\n",
              "      <td>Хорошо</td>\n",
              "      <td>O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56409 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f92d7a3-eae6-47d3-b86f-57bf15760ec6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f92d7a3-eae6-47d3-b86f-57bf15760ec6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f92d7a3-eae6-47d3-b86f-57bf15760ec6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_alfa = sub['Predicted']"
      ],
      "metadata": {
        "id": "AQ82cLTx39MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_alfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db07f07-44e4-40a5-9c57-7483cf8379d0",
        "id": "tOe3brwb39MD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        6\n",
              "1        7\n",
              "2        1\n",
              "3        1\n",
              "4        1\n",
              "        ..\n",
              "56404    6\n",
              "56405    7\n",
              "56406    7\n",
              "56407    1\n",
              "56408    1\n",
              "Name: Predicted, Length: 56409, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_submission_alfa.to_csv(\"sample_submission.csv\", sep=\",\", index_label=\"Id\")\n"
      ],
      "metadata": {
        "id": "46bPpJ_Q39MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"/content/sample_submission.csv\", sep=\",\")"
      ],
      "metadata": {
        "id": "cGx0SrWq39MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "49d6d414-f4b0-4808-df04-d61be2cc2c5d",
        "id": "J92tc5WH39ME"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Id  Predicted\n",
              "0          0          6\n",
              "1          1          7\n",
              "2          2          1\n",
              "3          3          1\n",
              "4          4          1\n",
              "...      ...        ...\n",
              "56404  56404          6\n",
              "56405  56405          7\n",
              "56406  56406          7\n",
              "56407  56407          1\n",
              "56408  56408          1\n",
              "\n",
              "[56409 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-371f3ab5-54c0-49dd-8383-5c526faac603\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56404</th>\n",
              "      <td>56404</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56405</th>\n",
              "      <td>56405</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56406</th>\n",
              "      <td>56406</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56407</th>\n",
              "      <td>56407</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56408</th>\n",
              "      <td>56408</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56409 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-371f3ab5-54c0-49dd-8383-5c526faac603')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-371f3ab5-54c0-49dd-8383-5c526faac603 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-371f3ab5-54c0-49dd-8383-5c526faac603');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_ids(data_df[\"sentence\"][0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLmJiS26d_wF",
        "outputId": "84650c85-bfd1-4300-ab01-6b9eeab3a90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[781,\n",
              " 14310,\n",
              " 7147,\n",
              " 6088,\n",
              " 875,\n",
              " 11680,\n",
              " 36122,\n",
              " 9310,\n",
              " 1469,\n",
              " 23038,\n",
              " 12261,\n",
              " 13715,\n",
              " 61355,\n",
              " 100,\n",
              " 28761,\n",
              " 18006,\n",
              " 304,\n",
              " 18740,\n",
              " 60809,\n",
              " 326,\n",
              " 128,\n",
              " 845,\n",
              " 7011,\n",
              " 2226,\n",
              " 66938,\n",
              " 128,\n",
              " 11615,\n",
              " 7363,\n",
              " 128,\n",
              " 3972,\n",
              " 14744,\n",
              " 26477,\n",
              " 851,\n",
              " 76373,\n",
              " 15082]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_tokens([\"лента.ру\", \"lenta.ru\", \".рф\", \"Кремль.рф\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1AaY904fVgx",
        "outputId": "ebfa04ab-197e-4631-c101-f3fb5c7b1267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_ids(\".рф\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TongGt1jfHV7",
        "outputId": "f3f1075b-3b06-494c-8bcb-82c3ac345cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119549"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad(data_df[\"sentence\"][0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "bGKNJA-WgUwr",
        "outputId": "89e4d644-93c9-4c8f-987b-df12b29bb661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d0fa0bd360cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2782\u001b[0;31m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m                 \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ab-huUMghb8T",
        "outputId": "3b6e4624-ef03-4836-a919-2accfa0dbebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentence #                                           sentence  \\\n",
              "0              0  В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1              1  Среди требований , выдвигаемых организаторами ...   \n",
              "2              2  Участникам акции предлагалось принести с собой...   \n",
              "3              3  Начало акции было намечено на 19 часов ; подчё...   \n",
              "4              4  Освещающие акцию блоггеры сообщили , что автоб...   \n",
              "...          ...                                                ...   \n",
              "1514        1514  Сделка способствует укреплений растущих связей...   \n",
              "1515        1515  Председатель КНР Ху Цзиньтао и российский през...   \n",
              "1516        1516  Новые поставки нефти почти вдвое увеличат объе...   \n",
              "1517        1517  До сих пор доставка сырой нефти осуществлялись...   \n",
              "1518        1518  По договору между двумя странами о нефтепровод...   \n",
              "\n",
              "                                            word_labels  \n",
              "0     O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...  \n",
              "1     O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...  \n",
              "2     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...  \n",
              "3                     O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "4     O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...  \n",
              "...                                                 ...  \n",
              "1514                                      O,O,O,O,O,O,O  \n",
              "1515  O,B_LOC,B_PER,I_PER,O,O,O,B_PER,I_PER,O,O,O,O,...  \n",
              "1516            O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,B_LOC  \n",
              "1517            O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC  \n",
              "1518  O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,O,O,O,O,O,O,O,O,...  \n",
              "\n",
              "[1519 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b408847-1656-43c5-a551-b755dcca4ca0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O,O,O,O,O,O,B_ORG,I_ORG,O,B_LOC,I_LOC,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,B_PER,I_PER,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B_PER,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>1514</td>\n",
              "      <td>Сделка способствует укреплений растущих связей...</td>\n",
              "      <td>O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>1515</td>\n",
              "      <td>Председатель КНР Ху Цзиньтао и российский през...</td>\n",
              "      <td>O,B_LOC,B_PER,I_PER,O,O,O,B_PER,I_PER,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>1516</td>\n",
              "      <td>Новые поставки нефти почти вдвое увеличат объе...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,B_LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1517</td>\n",
              "      <td>До сих пор доставка сырой нефти осуществлялись...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,I_LOC,I_LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>1518</td>\n",
              "      <td>По договору между двумя странами о нефтепровод...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B_LOC,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1519 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b408847-1656-43c5-a551-b755dcca4ca0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b408847-1656-43c5-a551-b755dcca4ca0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b408847-1656-43c5-a551-b755dcca4ca0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "sentences = data_df.sentence.values\n",
        "labels = data_df.word_labels.values"
      ],
      "metadata": {
        "id": "d7Tsemiyg6kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.convert_tokens_to_ids(sent.split())\n",
        "    input_ids.append(encoded_sent)"
      ],
      "metadata": {
        "id": "hQFOIPC-hmil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "qfeKLxTtigIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 200\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "riNXVJ_piWpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "H2excEwjiix5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "for sent in labels:\n",
        "    encoded_sent = sent.split(\",\")\n",
        "    train_labels.append(encoded_sent)"
      ],
      "metadata": {
        "id": "g8VlqbcDizU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict = {\n",
        "    'O': 1,\n",
        "    'B_ORG': 2,\n",
        "    'I_ORG': 3,\n",
        "    'B_LOC': 4,\n",
        "    'I_LOC': 5,\n",
        "    'B_PER': 6,\n",
        "    'I_PER': 7\n",
        "}"
      ],
      "metadata": {
        "id": "E7w2zmu5nOQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_labels =[]\n",
        "for i in train_labels:\n",
        "   res = []\n",
        "   for j in i:\n",
        "      res.append(labels_dict[j])\n",
        "   id_labels.append(res)"
      ],
      "metadata": {
        "id": "08WgH2yrmRnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = max(map(len, id_labels))\n",
        "y=np.array([xi+[-100]*(length-len(xi)) for xi in id_labels])\n",
        "y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf4Awgflncqx",
        "outputId": "d79439aa-5bfa-4acb-fb89-204b31f71c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,    1,    1,    1,    1,    1,    2,    3,    1,    4,    5,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "       -100, -100, -100, -100, -100, -100, -100, -100])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 200\n",
        "id_labels_pad = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=-100, truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "a5ruDpQCoXvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quKyG7pDpN7I",
        "outputId": "f14b266c-156c-4fd5-f231-7d72f5da906a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   781,  14310,   7147, ...,      0,      0,      0],\n",
              "       [ 10408,  25004,    128, ...,      0,      0,      0],\n",
              "       [117188,  14056,  46157, ...,      0,      0,      0],\n",
              "       ...,\n",
              "       [ 22906,  22137,  15284, ...,      0,      0,      0],\n",
              "       [  8819,  14591,   5206, ...,      0,      0,      0],\n",
              "       [  3099,  30642,   5190, ...,      0,      0,      0]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_labels = np.array(id_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7YorZpHpTLt",
        "outputId": "f1ecaa50-0a86-482c-9cd8-353ae92ee69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHJzacUWpcgq",
        "outputId": "b46c11e6-d9b7-473b-dbac-e1a33889bf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 1, 1, 1, 1, 1, 2, 3, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 6, 7, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 2, 3, 3, 3, 3, 3,\n",
              "        6, 7, 1, 1, 1, 6, 7, 1, 1, 2, 3, 3, 3, 3, 6, 7]),\n",
              " array([1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 2, 3, 3, 1, 2, 1, 1, 2, 3, 3, 3, 3,\n",
              "        1, 1, 2, 3, 1, 1, 2, 3, 3, 1, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 1,\n",
              "        1, 2, 3, 3, 3, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 6,\n",
              "        1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([6, 7, 1, 1, 4, 5, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        4, 5]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 3, 1]),\n",
              " array([1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 4, 5, 6, 7, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([2, 3, 3, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4]),\n",
              " array([1, 1, 2, 3, 3, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1]),\n",
              " array([1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 4, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 2, 1,\n",
              "        4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 4, 6, 7, 7, 1, 1, 1, 1, 1, 4, 1, 1, 1, 6, 7, 1, 1, 1, 1,\n",
              "        1, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 4,\n",
              "        1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5,\n",
              "        5, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 4, 6,\n",
              "        7, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 2, 3, 3, 1, 1, 1, 4, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 6, 7, 1,\n",
              "        1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 6, 7, 1,\n",
              "        4, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 6, 7, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 4,\n",
              "        5, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 6, 7, 1, 4,\n",
              "        1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 4, 5, 5, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 4, 5, 1, 1, 1, 1, 6, 7, 2, 3, 3, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 4, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 7, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 7, 1, 2, 3, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1,\n",
              "        1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 5, 1, 1, 1, 1, 2, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 5, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 3, 3,\n",
              "        3, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 5, 1, 1, 1, 2, 3, 3, 3, 1, 1,\n",
              "        1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 6, 1, 6, 7, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 6, 7, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1,\n",
              "        1, 1, 1, 1, 1, 2, 3, 1, 2, 3, 3, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 6, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 6, 7, 1, 1, 2, 3, 3, 3, 3,\n",
              "        3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 4, 5, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 2, 3, 3, 1, 2, 1, 1, 2, 3, 3, 3, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6, 7, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 2, 1, 1, 1, 1, 2, 6, 7, 1, 6, 7, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 6, 7, 1, 6, 7, 1, 1, 1, 1,\n",
              "        2, 6, 7, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 4, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 6, 7, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 5, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 2, 3, 3, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3,\n",
              "        3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 2, 3, 1, 1, 1, 2, 4, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 5, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 4]),\n",
              " array([1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 2, 3, 3, 3, 6, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 7, 4, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6, 7, 7, 2]),\n",
              " array([1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 6, 7, 7, 6, 7, 7]),\n",
              " array([6, 7, 1, 1, 1, 1, 4, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 6, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3,\n",
              "        1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 1, 1, 4, 1, 1, 4, 5, 1, 4, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([2, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 2, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        4]),\n",
              " array([6, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3]),\n",
              " array([1, 6, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 3, 6, 7]),\n",
              " array([1, 2, 3, 3, 6, 7, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 6, 7, 1]),\n",
              " array([1, 1, 1, 6, 7, 1, 1, 6, 7, 1, 1, 4, 5, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 2, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1,\n",
              "        1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([2, 3, 1, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 4, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        5, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 5, 1, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 5, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 5]),\n",
              " array([1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 2, 3, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 2, 1]),\n",
              " array([2, 3, 3, 3, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 2, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 2, 3, 1, 1, 2, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 2, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 1, 4, 5, 5, 5, 1, 4, 5, 5, 5, 5, 5, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 4, 5, 1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 7, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 7, 1, 4, 1, 1, 4, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 6, 7,\n",
              "        1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 6, 7, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 6, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2,\n",
              "        3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 3, 3, 3, 3]),\n",
              " array([1, 1, 1, 1]),\n",
              " array([2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1,\n",
              "        1, 1, 1, 2, 3, 3, 1, 4, 1, 4, 1, 1, 6, 7, 1, 1, 2, 3, 3, 1, 4, 1,\n",
              "        1, 6, 7, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 1, 4, 1, 1, 6, 7, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3, 1, 4, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 2, 3, 3, 1, 6, 7,\n",
              "        1, 1, 2, 3, 3, 1, 6, 7, 1, 1, 2, 3, 3, 3, 3, 1, 6, 7, 1, 1]),\n",
              " array([2, 3, 3, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 3]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 4]),\n",
              " array([1, 4, 1, 4, 6, 7, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 6, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 6, 7, 1, 1, 1, 2, 3, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 7, 1, 4, 1, 4, 6, 7, 7, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 2, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 4]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 1, 1, 1, 4,\n",
              "        1, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 4, 5, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3]),\n",
              " array([2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3]),\n",
              " array([1, 1, 6, 7, 1, 1, 2, 3, 3, 3, 1, 1, 6, 7, 1, 1, 2, 3, 3, 3, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 2,\n",
              "        3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 6, 7, 1, 1, 2, 3, 6, 7, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 5, 5, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 4, 5]),\n",
              " array([6, 7, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 5, 5, 1, 6, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1,\n",
              "        1, 6, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([2, 3, 3, 3, 1, 1, 1, 6]),\n",
              " array([1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 6, 7, 1, 6, 7, 1, 1, 1, 2, 3, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 2, 3, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 2, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 4, 1, 1, 6, 7, 1, 6, 7, 1, 1, 1, 1,\n",
              "        1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 4]),\n",
              " array([1, 2, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 2,\n",
              "        3, 3, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 5, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6, 7]),\n",
              " array([1, 1, 1, 1, 4, 5, 6, 7, 7, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 4, 5, 5, 6, 7, 1, 1, 2, 3, 1, 1, 2, 3, 3, 1, 6, 7, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 7, 7, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 4, 6, 7, 1, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 4, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 5]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 4, 6, 7, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 3, 6, 7, 1, 1, 2, 3, 3, 6, 7, 1, 1, 2, 6, 7, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 2, 3, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1,\n",
              "        1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1,\n",
              "        1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 3, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 6, 7, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 2, 3, 3, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 2, 3, 3, 3, 1, 2, 3, 3, 1, 1, 6, 7, 1, 6, 7, 1, 6, 7, 1, 1,\n",
              "        1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 2, 1, 2, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 2, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1]),\n",
              " array([1, 2, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1,\n",
              "        1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 6, 7]),\n",
              " array([1, 2, 3, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1,\n",
              "        1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 6, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 2, 3, 3, 3, 3, 6, 7]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 4, 1, 6, 7, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 6, 7, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
              "        1, 1, 4, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 5, 1, 4, 5, 5, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 5, 5, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3]),\n",
              " array([1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 2, 1, 2, 3,\n",
              "        3, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1]),\n",
              " array([1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3,\n",
              "        6, 7]),\n",
              " array([6, 7, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 3, 3, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([2, 3, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 6]),\n",
              " array([6, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 4, 5, 6, 7, 1, 1, 2, 1, 2, 3, 3, 3, 1, 1, 2, 3, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 2, 1, 1, 2]),\n",
              " array([1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 3, 1, 1, 4, 1, 1, 1, 1, 1, 2, 3, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 3, 3, 3, 1, 1, 1, 2, 3, 3, 3, 3, 1,\n",
              "        1, 1, 1, 2, 3, 3]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1, 2, 3, 3, 3, 3, 6, 7]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 3, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1,\n",
              "        4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 1, 4, 5, 5, 5, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 4, 5, 5, 5, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        2]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
              "        2, 6, 7, 7]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 4, 1,\n",
              "        4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([2, 3, 3, 3, 3, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 6, 7, 1, 6, 7, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 6, 7, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 6, 7, 1, 6, 7, 1, 6, 7, 1, 6, 7, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 6, 7]),\n",
              " array([1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 6, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 2, 3, 6, 7, 1, 1, 4, 5, 1,\n",
              "        1, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 4, 1, 4, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 5,\n",
              "        1, 4, 5, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]),\n",
              " array([1]),\n",
              " array([4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 1, 1, 6, 7, 1, 2, 1, 1, 1, 1, 1, 4, 1, 4, 5, 1, 1, 1, 1,\n",
              "        1, 1, 1, 4, 5, 1]),\n",
              " array([1, 1, 2, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1]),\n",
              " array([2, 3, 3, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3,\n",
              "        3, 3, 3, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 1, 1, 1, 1, 2, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1,\n",
              "        1, 2, 3, 3, 3, 3, 3]),\n",
              " array([1, 1, 4, 6, 7, 1, 1, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 4, 1, 1, 1, 2]),\n",
              " array([1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 2, 1, 6, 1,\n",
              "        1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "        1, 1, 1, 1, 1, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 3, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 6, 7, 1, 6, 7, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1,\n",
              "        1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1]),\n",
              " array([6, 7, 7, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 6, 7, 7, 1,\n",
              "        1, 2, 3, 3, 3]),\n",
              " array([1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 7, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 6, 7, 7, 1, 1, 2, 3, 6, 7, 7, 7, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 5, 5, 5, 1, 4, 1,\n",
              "        6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 2, 1, 6, 7, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1,\n",
              "        1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 1, 2, 3, 3, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 3, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1]),\n",
              " array([1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 6, 7, 1, 1, 1, 4, 6, 7,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1,\n",
              "        1, 1, 2, 3, 6, 7, 1, 1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 6, 7, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 4, 1,\n",
              "        1, 1, 4, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 3, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([4, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 6, 7, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3,\n",
              "        3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 2]),\n",
              " array([2, 3, 3, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 4, 6, 7, 1, 1, 1, 2, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 2, 3, 3, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 1, 1, 1, 1, 2, 1]),\n",
              " array([1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 2, 6, 7, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 7, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 6, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 2, 3, 3, 1, 6, 1, 1, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1,\n",
              "        1]),\n",
              " array([4, 1, 6]),\n",
              " array([1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 4]),\n",
              " array([1, 2, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n",
              "        4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1,\n",
              "        4, 1, 4, 1, 4, 1, 4, 1, 4, 5, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4,\n",
              "        1, 4, 1, 4, 1, 4, 1, 4, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        4, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 3, 3, 6, 7, 1, 1, 6, 7, 1, 1, 1, 1, 1, 4, 5]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 6, 7, 1, 1, 6, 7, 1, 1, 4,\n",
              "        1, 6, 7]),\n",
              " array([1, 1, 1, 4, 5, 5, 1, 4, 1, 4, 5, 5, 1, 4, 1, 1, 4, 5, 5, 1, 4]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 2, 3, 3, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6, 7, 1, 4, 1, 1,\n",
              "        1, 4, 1, 1, 6, 7, 7, 7, 1, 4, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 6, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6, 7]),\n",
              " array([1, 1, 6, 7, 1, 6, 7, 1, 1, 6, 7, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1]),\n",
              " array([1, 1, 1, 1, 1, 2, 3, 3, 1, 6, 7, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([6, 7, 1, 6, 7, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 6]),\n",
              " array([1, 6, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 2, 3, 3, 3, 1, 4, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        6]),\n",
              " array([1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 6,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([6, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]),\n",
              " array([1, 6, 7, 1, 1, 1, 6, 7]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1, 6, 7, 1, 1, 1, 1,\n",
              "        6, 7, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 1, 1, 2,\n",
              "        3, 1]),\n",
              " array([1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 3, 3, 3, 3, 3, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 7, 1, 1, 1, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 4]),\n",
              " array([6, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
              "        1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 4, 1, 4, 1, 4, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 1, 1,\n",
              "        1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 3,\n",
              "        3, 3, 3, 3, 3, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 1, 4]),\n",
              " array([1, 2, 3, 1, 1, 1, 1, 1, 1, 4, 6, 7]),\n",
              " array([1, 6, 1, 1, 1, 1, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 6, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4,\n",
              "        1, 4]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " array([1, 4, 1, 1, 1, 1, 6, 7, 1, 4, 1, 1, 6, 7, 1, 4, 1, 1, 6, 7, 1, 4,\n",
              "        1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1]),\n",
              " array([1, 1, 1, 4, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1]),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3IP1VhzgpQQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = torch.tensor(input_ids)\n",
        "\n",
        "train_labels = torch.tensor(y)\n",
        "\n",
        "\n",
        "train_masks = torch.tensor(attention_masks)\n"
      ],
      "metadata": {
        "id": "jALC_nHUn3hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "c-U8VBSHYwNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/final_data_NER.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "RXN6h8ZdYwbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Zn2fHIqOZATV",
        "outputId": "57008b98-cf0b-4ed3-a180-0b42984d2f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
              "0              0             0               0   \n",
              "1              1             1               1   \n",
              "2              2             2               2   \n",
              "3              3             3               3   \n",
              "4              4             4               4   \n",
              "...          ...           ...             ...   \n",
              "1514        1514          1514            1514   \n",
              "1515        1515          1515            1515   \n",
              "1516        1516          1516            1516   \n",
              "1517        1517          1517            1517   \n",
              "1518        1518          1518            1518   \n",
              "\n",
              "                                                 labels  \\\n",
              "0     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...   \n",
              "1     O O O O O O O O O O O B_LOC B_PER I_PER O O O ...   \n",
              "2     O O O O O O O O O O O O O O O O O O O O B_PER ...   \n",
              "3                     O O O O O O O O O O O O O O O O O   \n",
              "4     O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...   \n",
              "...                                                 ...   \n",
              "1514                                      O O O O O O O   \n",
              "1515  O B_LOC B_PER I_PER O O O B_PER I_PER O O O O ...   \n",
              "1516            O O O O O O O O O O O O O B_LOC O B_LOC   \n",
              "1517            O O O O O O O O O O O B_LOC I_LOC I_LOC   \n",
              "1518  O O O O O O O O O O O B_LOC O O O O O O O O O ...   \n",
              "\n",
              "                                                   text    clf  \\\n",
              "0     В понедельник 28 июня у здания мэрии Москвы на...  False   \n",
              "1     Среди требований , выдвигаемых организаторами ...  False   \n",
              "2     Участникам акции предлагалось принести с собой...  False   \n",
              "3     Начало акции было намечено на 19 часов ; подчё...   True   \n",
              "4     Освещающие акцию блоггеры сообщили , что автоб...  False   \n",
              "...                                                 ...    ...   \n",
              "1514  Сделка способствует укреплений растущих связей...   True   \n",
              "1515  Председатель КНР Ху Цзиньтао и российский през...  False   \n",
              "1516  Новые поставки нефти почти вдвое увеличат объе...  False   \n",
              "1517  До сих пор доставка сырой нефти осуществлялись...  False   \n",
              "1518  По договору между двумя странами о нефтепровод...  False   \n",
              "\n",
              "                                                pos_str  \\\n",
              "0     ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...   \n",
              "1     ADP NOUN PUNCT VERB NOUN NOUN PUNCT PUNCT ADJ ...   \n",
              "2     NOUN NOUN VERB VERB ADP PRON NOUN NOUN CCONJ N...   \n",
              "3     NOUN NOUN AUX VERB ADP NUM NOUN PUNCT VERB PUN...   \n",
              "4     ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...   \n",
              "...                                                 ...   \n",
              "1514                  NOUN VERB NOUN VERB NOUN ADP NOUN   \n",
              "1515  NOUN PROPN PROPN PROPN CCONJ ADJ NOUN PROPN PR...   \n",
              "1516  ADJ NOUN NOUN ADV ADV VERB NOUN PUNCT ADJ NOUN...   \n",
              "1517  ADP DET NOUN NOUN ADJ NOUN VERB ADP ADJ NOUN A...   \n",
              "1518  ADP NOUN ADP NUM NOUN ADP NOUN ADP ADJ NOUN PU...   \n",
              "\n",
              "                                               lemm_srt  \n",
              "0     в понедельник 28 июнь у здание мэрия москва на...  \n",
              "1     среди требование , выдвигать организатор акция...  \n",
              "2     участник акция предлагаться принести с себя ли...  \n",
              "3     начало акция быть наметить на 19 час ; подчерк...  \n",
              "4     освещать акция блогер сообщить , что автобус с...  \n",
              "...                                                 ...  \n",
              "1514  сделка способствовать укрепление расти связь м...  \n",
              "1515  председатель кнр ху цзиньтао и российский през...  \n",
              "1516  новый поставка нефть почти вдвое увеличить объ...  \n",
              "1517  до сей пора доставка сырой нефть осуществлятьс...  \n",
              "1518  по договор между два страна о нефтепровод от 2...  \n",
              "\n",
              "[1519 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c158f917-d029-48bf-9e35-bbe8eab34fbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>pos_str</th>\n",
              "      <th>lemm_srt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...</td>\n",
              "      <td>в понедельник 28 июнь у здание мэрия москва на...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>O O O O O O O O O O O B_LOC B_PER I_PER O O O ...</td>\n",
              "      <td>Среди требований , выдвигаемых организаторами ...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN PUNCT VERB NOUN NOUN PUNCT PUNCT ADJ ...</td>\n",
              "      <td>среди требование , выдвигать организатор акция...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_PER ...</td>\n",
              "      <td>Участникам акции предлагалось принести с собой...</td>\n",
              "      <td>False</td>\n",
              "      <td>NOUN NOUN VERB VERB ADP PRON NOUN NOUN CCONJ N...</td>\n",
              "      <td>участник акция предлагаться принести с себя ли...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>Начало акции было намечено на 19 часов ; подчё...</td>\n",
              "      <td>True</td>\n",
              "      <td>NOUN NOUN AUX VERB ADP NUM NOUN PUNCT VERB PUN...</td>\n",
              "      <td>начало акция быть наметить на 19 час ; подчерк...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...</td>\n",
              "      <td>освещать акция блогер сообщить , что автобус с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1514</th>\n",
              "      <td>1514</td>\n",
              "      <td>1514</td>\n",
              "      <td>1514</td>\n",
              "      <td>O O O O O O O</td>\n",
              "      <td>Сделка способствует укреплений растущих связей...</td>\n",
              "      <td>True</td>\n",
              "      <td>NOUN VERB NOUN VERB NOUN ADP NOUN</td>\n",
              "      <td>сделка способствовать укрепление расти связь м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>1515</td>\n",
              "      <td>1515</td>\n",
              "      <td>1515</td>\n",
              "      <td>O B_LOC B_PER I_PER O O O B_PER I_PER O O O O ...</td>\n",
              "      <td>Председатель КНР Ху Цзиньтао и российский през...</td>\n",
              "      <td>False</td>\n",
              "      <td>NOUN PROPN PROPN PROPN CCONJ ADJ NOUN PROPN PR...</td>\n",
              "      <td>председатель кнр ху цзиньтао и российский през...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>1516</td>\n",
              "      <td>1516</td>\n",
              "      <td>1516</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC O B_LOC</td>\n",
              "      <td>Новые поставки нефти почти вдвое увеличат объе...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN NOUN ADV ADV VERB NOUN PUNCT ADJ NOUN...</td>\n",
              "      <td>новый поставка нефть почти вдвое увеличить объ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1517</td>\n",
              "      <td>1517</td>\n",
              "      <td>1517</td>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC I_LOC</td>\n",
              "      <td>До сих пор доставка сырой нефти осуществлялись...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP DET NOUN NOUN ADJ NOUN VERB ADP ADJ NOUN A...</td>\n",
              "      <td>до сей пора доставка сырой нефть осуществлятьс...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>1518</td>\n",
              "      <td>1518</td>\n",
              "      <td>1518</td>\n",
              "      <td>O O O O O O O O O O O B_LOC O O O O O O O O O ...</td>\n",
              "      <td>По договору между двумя странами о нефтепровод...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADP NUM NOUN ADP NOUN ADP ADJ NOUN PU...</td>\n",
              "      <td>по договор между два страна о нефтепровод от 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1519 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c158f917-d029-48bf-9e35-bbe8eab34fbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c158f917-d029-48bf-9e35-bbe8eab34fbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c158f917-d029-48bf-9e35-bbe8eab34fbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = train_df[train_df['labels'].str.contains(\"I_LOC\")]"
      ],
      "metadata": {
        "id": "6NDWewjbZpLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s[\"labels_split\"] = s['labels'].str.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htv4_-pJaDKt",
        "outputId": "f7571618-75de-4aef-e4ad-8835c0ded22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[\"words_split\"] = s['text'].str.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOUbJdGJaYfT",
        "outputId": "ed96a13d-5cb3-4288-f921-86345b04ccdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "RcZHcKmAadL_",
        "outputId": "fb8d5f73-1340-41eb-8726-45d8e08391a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
              "0              0             0               0   \n",
              "4              4             4               4   \n",
              "30            30            30              30   \n",
              "32            32            32              32   \n",
              "38            38            38              38   \n",
              "...          ...           ...             ...   \n",
              "1473        1473          1473            1473   \n",
              "1501        1501          1501            1501   \n",
              "1505        1505          1505            1505   \n",
              "1512        1512          1512            1512   \n",
              "1517        1517          1517            1517   \n",
              "\n",
              "                                                 labels  \\\n",
              "0     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...   \n",
              "4     O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...   \n",
              "30        B_PER I_PER O O B_LOC I_LOC O O O B_PER I_PER   \n",
              "32    O O O O O O O O O O O B_ORG O B_LOC O O O B_LO...   \n",
              "38    O O B_PER I_PER O O O O O O O O O O O B_LOC I_LOC   \n",
              "...                                                 ...   \n",
              "1473  O O O O O O B_LOC I_LOC I_LOC O O O O O O B_PE...   \n",
              "1501  B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...   \n",
              "1505  B_ORG I_ORG O O O O O O O O O O O O O O O B_LO...   \n",
              "1512  O O O O O O O O O O O O O O O O O O O O B_LOC ...   \n",
              "1517            O O O O O O O O O O O B_LOC I_LOC I_LOC   \n",
              "\n",
              "                                                   text    clf  \\\n",
              "0     В понедельник 28 июня у здания мэрии Москвы на...  False   \n",
              "4     Освещающие акцию блоггеры сообщили , что автоб...  False   \n",
              "30    Барак Обама принимает в Белом доме своего фран...  False   \n",
              "32    В частности , лидеры намерены обменяться мнени...  False   \n",
              "38    В понедельник Джаред Лофнер в наручниках и в с...  False   \n",
              "...                                                 ...    ...   \n",
              "1473  Напомним , что причиной беспорядков в лондонск...  False   \n",
              "1501  Федеральное авиационное управление пояснило , ...  False   \n",
              "1505  Авиационное управление сообщило , что связь с ...  False   \n",
              "1512  На заре первого дня Нового года нефть начали к...  False   \n",
              "1517  До сих пор доставка сырой нефти осуществлялись...  False   \n",
              "\n",
              "                                                pos_str  \\\n",
              "0     ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...   \n",
              "4     ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...   \n",
              "30    PROPN PROPN VERB ADP ADJ NOUN DET ADJ NOUN PRO...   \n",
              "32    ADP NOUN PUNCT NOUN ADJ VERB NOUN ADP NOUN ADJ...   \n",
              "38    ADP NOUN PROPN PROPN ADP NOUN CCONJ ADP NOUN N...   \n",
              "...                                                 ...   \n",
              "1473  VERB PUNCT SCONJ NOUN NOUN ADP ADJ NOUN PROPN ...   \n",
              "1501  ADJ ADJ NOUN VERB PUNCT SCONJ ADP NOUN ADP NOU...   \n",
              "1505  ADJ NOUN VERB PUNCT SCONJ NOUN ADP NOUN VERB P...   \n",
              "1512  ADP NOUN ADJ NOUN ADJ NOUN NOUN VERB VERB ADP ...   \n",
              "1517  ADP DET NOUN NOUN ADJ NOUN VERB ADP ADJ NOUN A...   \n",
              "\n",
              "                                               lemm_srt  \\\n",
              "0     в понедельник 28 июнь у здание мэрия москва на...   \n",
              "4     освещать акция блогер сообщить , что автобус с...   \n",
              "30    барак обама принимать в белый дом свой француз...   \n",
              "32    в частность , лидер намерен обменяться мнение ...   \n",
              "38    в понедельник джаред лофнер в наручник и в соп...   \n",
              "...                                                 ...   \n",
              "1473  напомнить , что причина беспорядок в лондонски...   \n",
              "1501  федеральный авиационный управление пояснить , ...   \n",
              "1505  авиационный управление сообщить , что связь с ...   \n",
              "1512  на заря первый день новый год нефть начать кач...   \n",
              "1517  до сей пора доставка сырой нефть осуществлятьс...   \n",
              "\n",
              "                                           labels_split  \\\n",
              "0     [O, O, O, O, O, O, B_ORG, I_ORG, O, B_LOC, I_L...   \n",
              "4     [O, O, O, O, O, O, O, O, O, O, O, O, O, B_LOC,...   \n",
              "30    [B_PER, I_PER, O, O, B_LOC, I_LOC, O, O, O, B_...   \n",
              "32    [O, O, O, O, O, O, O, O, O, O, O, B_ORG, O, B_...   \n",
              "38    [O, O, B_PER, I_PER, O, O, O, O, O, O, O, O, O...   \n",
              "...                                                 ...   \n",
              "1473  [O, O, O, O, O, O, B_LOC, I_LOC, I_LOC, O, O, ...   \n",
              "1501  [B_ORG, I_ORG, I_ORG, O, O, O, O, O, O, O, O, ...   \n",
              "1505  [B_ORG, I_ORG, O, O, O, O, O, O, O, O, O, O, O...   \n",
              "1512  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "1517  [O, O, O, O, O, O, O, O, O, O, O, B_LOC, I_LOC...   \n",
              "\n",
              "                                            words_split  \n",
              "0     [В, понедельник, 28, июня, у, здания, мэрии, М...  \n",
              "4     [Освещающие, акцию, блоггеры, сообщили, ,, что...  \n",
              "30    [Барак, Обама, принимает, в, Белом, доме, свое...  \n",
              "32    [В, частности, ,, лидеры, намерены, обменяться...  \n",
              "38    [В, понедельник, Джаред, Лофнер, в, наручниках...  \n",
              "...                                                 ...  \n",
              "1473  [Напомним, ,, что, причиной, беспорядков, в, л...  \n",
              "1501  [Федеральное, авиационное, управление, пояснил...  \n",
              "1505  [Авиационное, управление, сообщило, ,, что, св...  \n",
              "1512  [На, заре, первого, дня, Нового, года, нефть, ...  \n",
              "1517  [До, сих, пор, доставка, сырой, нефти, осущест...  \n",
              "\n",
              "[107 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a23b31d-aed6-4285-98f7-49f7e7837596\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "      <th>clf</th>\n",
              "      <th>pos_str</th>\n",
              "      <th>lemm_srt</th>\n",
              "      <th>labels_split</th>\n",
              "      <th>words_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADJ NOUN ADP NOUN NOUN PROPN ADP ADJ ...</td>\n",
              "      <td>в понедельник 28 июнь у здание мэрия москва на...</td>\n",
              "      <td>[O, O, O, O, O, O, B_ORG, I_ORG, O, B_LOC, I_L...</td>\n",
              "      <td>[В, понедельник, 28, июня, у, здания, мэрии, М...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>O O O O O O O O O O O O O B_LOC I_LOC I_LOC O ...</td>\n",
              "      <td>Освещающие акцию блоггеры сообщили , что автоб...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN NOUN VERB PUNCT SCONJ NOUN ADP NOUN V...</td>\n",
              "      <td>освещать акция блогер сообщить , что автобус с...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B_LOC,...</td>\n",
              "      <td>[Освещающие, акцию, блоггеры, сообщили, ,, что...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>B_PER I_PER O O B_LOC I_LOC O O O B_PER I_PER</td>\n",
              "      <td>Барак Обама принимает в Белом доме своего фран...</td>\n",
              "      <td>False</td>\n",
              "      <td>PROPN PROPN VERB ADP ADJ NOUN DET ADJ NOUN PRO...</td>\n",
              "      <td>барак обама принимать в белый дом свой француз...</td>\n",
              "      <td>[B_PER, I_PER, O, O, B_LOC, I_LOC, O, O, O, B_...</td>\n",
              "      <td>[Барак, Обама, принимает, в, Белом, доме, свое...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>O O O O O O O O O O O B_ORG O B_LOC O O O B_LO...</td>\n",
              "      <td>В частности , лидеры намерены обменяться мнени...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN PUNCT NOUN ADJ VERB NOUN ADP NOUN ADJ...</td>\n",
              "      <td>в частность , лидер намерен обменяться мнение ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B_ORG, O, B_...</td>\n",
              "      <td>[В, частности, ,, лидеры, намерены, обменяться...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>O O B_PER I_PER O O O O O O O O O O O B_LOC I_LOC</td>\n",
              "      <td>В понедельник Джаред Лофнер в наручниках и в с...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN PROPN PROPN ADP NOUN CCONJ ADP NOUN N...</td>\n",
              "      <td>в понедельник джаред лофнер в наручник и в соп...</td>\n",
              "      <td>[O, O, B_PER, I_PER, O, O, O, O, O, O, O, O, O...</td>\n",
              "      <td>[В, понедельник, Джаред, Лофнер, в, наручниках...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1473</th>\n",
              "      <td>1473</td>\n",
              "      <td>1473</td>\n",
              "      <td>1473</td>\n",
              "      <td>O O O O O O B_LOC I_LOC I_LOC O O O O O O B_PE...</td>\n",
              "      <td>Напомним , что причиной беспорядков в лондонск...</td>\n",
              "      <td>False</td>\n",
              "      <td>VERB PUNCT SCONJ NOUN NOUN ADP ADJ NOUN PROPN ...</td>\n",
              "      <td>напомнить , что причина беспорядок в лондонски...</td>\n",
              "      <td>[O, O, O, O, O, O, B_LOC, I_LOC, I_LOC, O, O, ...</td>\n",
              "      <td>[Напомним, ,, что, причиной, беспорядков, в, л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1501</th>\n",
              "      <td>1501</td>\n",
              "      <td>1501</td>\n",
              "      <td>1501</td>\n",
              "      <td>B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...</td>\n",
              "      <td>Федеральное авиационное управление пояснило , ...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ ADJ NOUN VERB PUNCT SCONJ ADP NOUN ADP NOU...</td>\n",
              "      <td>федеральный авиационный управление пояснить , ...</td>\n",
              "      <td>[B_ORG, I_ORG, I_ORG, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[Федеральное, авиационное, управление, пояснил...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1505</th>\n",
              "      <td>1505</td>\n",
              "      <td>1505</td>\n",
              "      <td>1505</td>\n",
              "      <td>B_ORG I_ORG O O O O O O O O O O O O O O O B_LO...</td>\n",
              "      <td>Авиационное управление сообщило , что связь с ...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADJ NOUN VERB PUNCT SCONJ NOUN ADP NOUN VERB P...</td>\n",
              "      <td>авиационный управление сообщить , что связь с ...</td>\n",
              "      <td>[B_ORG, I_ORG, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "      <td>[Авиационное, управление, сообщило, ,, что, св...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1512</th>\n",
              "      <td>1512</td>\n",
              "      <td>1512</td>\n",
              "      <td>1512</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP NOUN ADJ NOUN ADJ NOUN NOUN VERB VERB ADP ...</td>\n",
              "      <td>на заря первый день новый год нефть начать кач...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[На, заре, первого, дня, Нового, года, нефть, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>1517</td>\n",
              "      <td>1517</td>\n",
              "      <td>1517</td>\n",
              "      <td>O O O O O O O O O O O B_LOC I_LOC I_LOC</td>\n",
              "      <td>До сих пор доставка сырой нефти осуществлялись...</td>\n",
              "      <td>False</td>\n",
              "      <td>ADP DET NOUN NOUN ADJ NOUN VERB ADP ADJ NOUN A...</td>\n",
              "      <td>до сей пора доставка сырой нефть осуществлятьс...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B_LOC, I_LOC...</td>\n",
              "      <td>[До, сих, пор, доставка, сырой, нефти, осущест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a23b31d-aed6-4285-98f7-49f7e7837596')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a23b31d-aed6-4285-98f7-49f7e7837596 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a23b31d-aed6-4285-98f7-49f7e7837596');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = s.text.str.split(expand=True).stack()\n",
        "labels = s.labels.str.split(expand=True).stack()\n",
        "\n",
        "train_words_df = pd.DataFrame({\n",
        "    'Sentence': words.index.get_level_values(0) + 1, \n",
        "    'Word': words.values,\n",
        "    'Label': labels.values,\n",
        "})"
      ],
      "metadata": {
        "id": "uQVdjzvxcn5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_words_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oK7K9JBEcwhm",
        "outputId": "c38a186e-15dd-4ef2-bc8e-b230662eec9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Sentence           Word  Label\n",
              "0            1              В      O\n",
              "1            1    понедельник      O\n",
              "2            1             28      O\n",
              "3            1           июня      O\n",
              "4            1              у      O\n",
              "...        ...            ...    ...\n",
              "2710      1518         дороге      O\n",
              "2711      1518              в      O\n",
              "2712      1518  тихоокеанский  B_LOC\n",
              "2713      1518           порт  I_LOC\n",
              "2714      1518       Козьмино  I_LOC\n",
              "\n",
              "[2715 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0357501-47c0-41fa-81b7-6ab8c62e6366\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Word</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>В</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>понедельник</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>июня</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>у</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2710</th>\n",
              "      <td>1518</td>\n",
              "      <td>дороге</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>1518</td>\n",
              "      <td>в</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>1518</td>\n",
              "      <td>тихоокеанский</td>\n",
              "      <td>B_LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2713</th>\n",
              "      <td>1518</td>\n",
              "      <td>порт</td>\n",
              "      <td>I_LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2714</th>\n",
              "      <td>1518</td>\n",
              "      <td>Козьмино</td>\n",
              "      <td>I_LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2715 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0357501-47c0-41fa-81b7-6ab8c62e6366')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0357501-47c0-41fa-81b7-6ab8c62e6366 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0357501-47c0-41fa-81b7-6ab8c62e6366');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"], s[\"Label\"])] #, train_words_df[\"POS\"].values.tolist(), train_words_df[\"Lemm\"].values.tolist()"
      ],
      "metadata": {
        "id": "ZF_VvV1bdc4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = train_words_df.groupby(\"Sentence\").apply(agg_func)\n"
      ],
      "metadata": {
        "id": "3C1NIN_ydc4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897c4275-1681-4edd-af34-684410d7d476",
        "id": "JxSREGdsdc4N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence\n",
              "1      [(В, O), (понедельник, O), (28, O), (июня, O),...\n",
              "5      [(Освещающие, O), (акцию, O), (блоггеры, O), (...\n",
              "31     [(Барак, B_PER), (Обама, I_PER), (принимает, O...\n",
              "33     [(В, O), (частности, O), (,, O), (лидеры, O), ...\n",
              "39     [(В, O), (понедельник, O), (Джаред, B_PER), (Л...\n",
              "42     [(Тогда, O), (были, O), (убиты, O), (шесть, O)...\n",
              "45     [(Обама, B_PER), (выступал, O), (в, O), (Белом...\n",
              "46     [(Президент, O), (и, O), (первая, O), (леди, O...\n",
              "85     [(В, O), (тот, O), (же, O), (день, O), (Южная,...\n",
              "92     [(До, O), (сих, O), (пор, O), (среди, O), (гла...\n",
              "100    [(Турция, B_LOC), (поможет, O), (крымским, O),...\n",
              "110    [(Почему, O), (?, O), (Мусульманский, O), (мир...\n",
              "111    [(Кроме, O), (того, O), (,, O), (после, O), (з...\n",
              "119    [(Голос, B_ORG), (Америки, I_ORG), (:, O), (До...\n",
              "130    [(Голос, B_ORG), (Америки, I_ORG), (:, O), (Сп...\n",
              "131    [(В, O), (условиях, O), (политической, O), (не...\n",
              "136    [(В, O), (конце, O), (субботней, O), (классифи...\n",
              "152    [(В, O), (августе, O), (2004, O), (года, O), (...\n",
              "157    [(К, O), (Кронштадтскому, B_LOC), (бульвару, I...\n",
              "161    [(Впрочем, O), (,, O), (показательно, O), (,, ...\n",
              "163    [(Сегодня, O), (на, O), (Кронштадтском, B_LOC)...\n",
              "167    [(\", O), (Эх, O), (,, O), (яблочко, O), (\", O)...\n",
              "186    [(Вот, O), (как, O), (эту, O), (панихиду, O), ...\n",
              "215    [(Продолжает, O), (отбывать, O), (10-и, O), (л...\n",
              "225    [(Соединенные, B_LOC), (Штаты, I_LOC), (,, O),...\n",
              "260    [(В, O), (19, O), (часов, O), (по, O), (Москов...\n",
              "272    [(«, O), (Нужно, O), (обращаться, O), (к, O), ...\n",
              "274    [(Во, O), (время, O), (поездки, O), (политика,...\n",
              "280    [(Около, O), (30, O), (рабочих, O), (на, O), (...\n",
              "282    [(Vestas, B_ORG), (—, O), (основной, O), (рабо...\n",
              "287    [(Завод, O), (закрыт, O), (несмотря, O), (на, ...\n",
              "311    [(Как, O), (известно, O), (,, O), (Иса, B_PER)...\n",
              "319    [(Например, O), (,, O), (за, O), (первое, O), ...\n",
              "338    [(Петербургские, O), (экологи, O), (обнаружили...\n",
              "339    [(Они, O), (требуют, O), (привлечь, O), (к, O)...\n",
              "341    [(Эта, O), (группа, O), (и, O), (Южная, B_ORG)...\n",
              "343    [(Ниже, O), (устья, O), (реки, B_LOC), (Славян...\n",
              "352    [(В, O), (ночь, O), (с, O), (20, O), (на, O), ...\n",
              "353    [(Об, O), (этом, O), (активистам, O), (Гринпис...\n",
              "355    [(Остаётся, O), (неизвестным, O), (даже, O), (...\n",
              "356    [(Все, O), (сбросы, O), (осуществлялись, O), (...\n",
              "406    [(1, O), (февраля, O), (на, O), (ступеньках, O...\n",
              "409    [(Уральцы, O), (никогда, O), (не, O), (забудут...\n",
              "420    [(В, O), (церемонии, O), (также, O), (приняли,...\n",
              "429    [(И, O), (заложил, O), (основу, O), (этому, O)...\n",
              "430    [(В, O), (мае, O), (1981, O), (года, O), (,, O...\n",
              "466    [(Поводом, O), (для, O), (отзыва, O), (стал, O...\n",
              "468    [(Однако, O), (,, O), (как, O), (известно, O),...\n",
              "474    [(Правительство, B_ORG), (Японии, I_ORG), (выр...\n",
              "475    [(Четыре, O), (острова, O), (,, O), (которые, ...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped[136]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ehIjQdeNhO",
        "outputId": "3304d60e-3a2a-46b7-e139-b0c580503089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('В', 'O'),\n",
              " ('конце', 'O'),\n",
              " ('субботней', 'O'),\n",
              " ('классификации', 'O'),\n",
              " ('Михаэль', 'B_PER'),\n",
              " ('Шумахер', 'I_PER'),\n",
              " ('допустил', 'O'),\n",
              " ('ошибку', 'O'),\n",
              " ('в', 'O'),\n",
              " ('повороте', 'O'),\n",
              " ('Раскассэ', 'B_LOC'),\n",
              " ('(', 'O'),\n",
              " ('La', 'B_LOC'),\n",
              " ('Rascasse', 'I_LOC'),\n",
              " (')', 'O'),\n",
              " (',', 'O'),\n",
              " ('заблокировав', 'O'),\n",
              " ('свои', 'O'),\n",
              " ('колёса', 'O'),\n",
              " ('и', 'O'),\n",
              " ('остановившись', 'O'),\n",
              " ('менее', 'O'),\n",
              " ('чем', 'O'),\n",
              " ('в', 'O'),\n",
              " ('метре', 'O'),\n",
              " ('от', 'O'),\n",
              " ('отбойников', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['text'][109]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Gd2DYXi4fnry",
        "outputId": "a57e3c10-be0f-4743-f36f-7d4f18affe40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Почему ? Мусульманский мир довольно обширен … Мустафа Джемилев : Во времена могущества Османской империи в регионе мы и турецкая сторона длительное время были союзниками'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['labels'][109]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l0LK0GavhtDw",
        "outputId": "f18d6590-31ec-4495-e83f-46beb89c399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O O O O O O O B_PER I_PER O O O O B_LOC I_LOC O O O O O O O O O O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gTdB8cQjqR77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTLnNKaNX-rP",
        "outputId": "861fa919-512c-4b4d-aac8-4d7879551c78"
      },
      "source": [
        "import re\n",
        "import gensim\n",
        "import logging\n",
        "import nltk.data \n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm9z6SN3X-rS",
        "outputId": "6ba111b8-1da1-4234-ce26-4c22c7fa3a6e"
      },
      "source": [
        "urllib.request.urlretrieve(\n",
        "    \"http://rusvectores.org/static/models/rusvectores2/ruscorpora_mystem_cbow_300_2_2015.bin.gz\", \n",
        "    \"ruscorpora_mystem_cbow_300_2_2015.bin.gz\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ruscorpora_mystem_cbow_300_2_2015.bin.gz',\n",
              " <http.client.HTTPMessage at 0x7fdff37e7710>)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkuCawyFX-rW"
      },
      "source": [
        "model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'\n",
        "\n",
        "model_ru = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = model_ru.most_similar(positive=['тихоокеанский_A'], topn=10)"
      ],
      "metadata": {
        "id": "djjJuQcxscdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cMbEUoNs1CC",
        "outputId": "26528512-f1dc-4574-db7e-5cf7ba8b8ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('черноморский_A', 0.6890996694564819),\n",
              " ('балтийский_A', 0.5797708034515381),\n",
              " ('лигурийский_A', 0.4728476405143738),\n",
              " ('далматинский_A', 0.4712284803390503),\n",
              " ('военно-морской_A', 0.4682367444038391),\n",
              " ('средиземноморский_A', 0.4595109522342682),\n",
              " ('каспий_S', 0.45920678973197937),\n",
              " ('танкерный_A', 0.4456620216369629),\n",
              " ('нини_S', 0.4446202516555786),\n",
              " ('атлантический_A', 0.44272446632385254)]"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sents = []"
      ],
      "metadata": {
        "id": "GHkUu-R7YHpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 0\n",
        "for i in grouped[103:106]:\n",
        "    for word, t in i:\n",
        "        if t == 'I_LOC':\n",
        "            #print(word)\n",
        "            #print(n)\n",
        "            p = morph.parse(word)[0]\n",
        "            pos = p.tag.POS\n",
        "            if pos == \"ADJF\":\n",
        "                  pos = \"_A\"\n",
        "            else:\n",
        "                  pos = \"_S\"\n",
        "            case = p.tag.case\n",
        "            syn_ten = model_ru.most_similar(positive=[f'{p.normal_form}{pos}'], topn=10)\n",
        "            syn = []\n",
        "            for w, fr in syn_ten:\n",
        "                syn.append(w[:-2])\n",
        "            #print(syn)\n",
        "            comp = []\n",
        "            for s in syn:\n",
        "                p_s = morph.parse(s)[0]\n",
        "                #print(p_s[0])\n",
        "                #c_s = p_s.inflect({case})[0]\n",
        "                comp.append((p_s[0], t))\n",
        "            #print(comp)\n",
        "            for c in comp:\n",
        "                n_i = i.copy()\n",
        "                n_i[n] = c\n",
        "                new_sents.append(n_i)\n",
        "            n_i = i\n",
        "        n += 1\n",
        "    n = 0           "
      ],
      "metadata": {
        "id": "akiXv9K1uvNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2\n",
        "!pip install pymorphy2-dicts\n",
        "!pip install DAWG-Python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9QViW_WzHFR",
        "outputId": "c034e4b3-cc81-41fd-e59d-f6093d8ce47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
            "Collecting pymorphy2-dicts\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts\n",
            "Successfully installed pymorphy2-dicts-2.4.393442.3710985\n",
            "Requirement already satisfied: DAWG-Python in /usr/local/lib/python3.7/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "JCVWuObyzMql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = morph.parse('долгорукому')[0]\n",
        "p.normal_form\n",
        "p.inflect({'gent'})[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jMJoRgkPzUSv",
        "outputId": "cb451966-412a-40e5-e8af-fbf3a387f208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'долгорукого'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = morph.parse('дом')[0]\n",
        "p.tag.POS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GDh1sbzy9utS",
        "outputId": "05cbe3d5-50ec-4328-eabe-b8255f9cd59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NOUN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_sents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcz8lp5NSVdR",
        "outputId": "0241989f-ff76-41d7-f227-0a3336177abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1130"
            ]
          },
          "metadata": {},
          "execution_count": 436
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_sent = []\n",
        "clean_tags = []\n",
        "for i in new_sents:\n",
        "    words = []\n",
        "    tags = []\n",
        "    for w, t in i:\n",
        "        words.append(w)\n",
        "        tags.append(t)\n",
        "    clean_sent.append(words)\n",
        "    clean_tags.append(tags)"
      ],
      "metadata": {
        "id": "qaa49WGGTUEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_new = []\n",
        "for i in clean_sent:\n",
        "    join_new.append(\" \".join(i))"
      ],
      "metadata": {
        "id": "kGrDltY3VZhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_tags = []\n",
        "for i in clean_tags:\n",
        "    join_tags.append(\" \".join(i))"
      ],
      "metadata": {
        "id": "a2SUx77EWqdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(join_new)"
      ],
      "metadata": {
        "id": "mGoBpnGXVja-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.DataFrame(join_tags)"
      ],
      "metadata": {
        "id": "6H_TIHgLXJc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1o6fZcCzXMQ4",
        "outputId": "0323fc79-c3fc-4ec1-a755-11506a3766ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0\n",
              "0    B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...\n",
              "1    B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...\n",
              "2    B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...\n",
              "3    B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...\n",
              "4    B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...\n",
              "..                                                 ...\n",
              "115  O O O O O O O O O O O O O O O O O O O O B_LOC ...\n",
              "116  O O O O O O O O O O O O O O O O O O O O B_LOC ...\n",
              "117  O O O O O O O O O O O O O O O O O O O O B_LOC ...\n",
              "118  O O O O O O O O O O O O O O O O O O O O B_LOC ...\n",
              "119  O O O O O O O O O O O O O O O O O O O O B_LOC ...\n",
              "\n",
              "[120 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-299c67cc-ea27-4a38-8265-ac25021891b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B_ORG I_ORG I_ORG O O O O O O O O O B_LOC I_LO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-299c67cc-ea27-4a38-8265-ac25021891b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-299c67cc-ea27-4a38-8265-ac25021891b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-299c67cc-ea27-4a38-8265-ac25021891b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7uAAl6lsWfwH",
        "outputId": "2c46f631-3d79-4cbf-fc4a-4ef9da3d60c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0\n",
              "0    Федеральное авиационное управление пояснило , ...\n",
              "1    Федеральное авиационное управление пояснило , ...\n",
              "2    Федеральное авиационное управление пояснило , ...\n",
              "3    Федеральное авиационное управление пояснило , ...\n",
              "4    Федеральное авиационное управление пояснило , ...\n",
              "..                                                 ...\n",
              "115  На заре первого дня Нового года нефть начали к...\n",
              "116  На заре первого дня Нового года нефть начали к...\n",
              "117  На заре первого дня Нового года нефть начали к...\n",
              "118  На заре первого дня Нового года нефть начали к...\n",
              "119  На заре первого дня Нового года нефть начали к...\n",
              "\n",
              "[120 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29896738-511e-4448-8453-e442b0440c11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Федеральное авиационное управление пояснило , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Федеральное авиационное управление пояснило , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Федеральное авиационное управление пояснило , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Федеральное авиационное управление пояснило , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Федеральное авиационное управление пояснило , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29896738-511e-4448-8453-e442b0440c11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29896738-511e-4448-8453-e442b0440c11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29896738-511e-4448-8453-e442b0440c11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['tags'] = data2[0]"
      ],
      "metadata": {
        "id": "idhvawHBW-wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "O8gyuUiDXnkt",
        "outputId": "c1be076b-1bd9-40ca-effc-97848f7905aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      0  \\\n",
              "0     В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "1     В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "2     В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "3     В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "4     В понедельник 28 июня у здания мэрии Москвы на...   \n",
              "...                                                 ...   \n",
              "1125  На заре первого дня Нового года нефть начали к...   \n",
              "1126  На заре первого дня Нового года нефть начали к...   \n",
              "1127  На заре первого дня Нового года нефть начали к...   \n",
              "1128  На заре первого дня Нового года нефть начали к...   \n",
              "1129  На заре первого дня Нового года нефть начали к...   \n",
              "\n",
              "                                                   tags  \n",
              "0     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...  \n",
              "1     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...  \n",
              "2     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...  \n",
              "3     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...  \n",
              "4     O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...  \n",
              "...                                                 ...  \n",
              "1125  O O O O O O O O O O O O O O O O O O O O B_LOC ...  \n",
              "1126  O O O O O O O O O O O O O O O O O O O O B_LOC ...  \n",
              "1127  O O O O O O O O O O O O O O O O O O O O B_LOC ...  \n",
              "1128  O O O O O O O O O O O O O O O O O O O O B_LOC ...  \n",
              "1129  O O O O O O O O O O O O O O O O O O O O B_LOC ...  \n",
              "\n",
              "[1130 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-677c13e2-3b9e-4ea1-a625-f0b601d3dbc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В понедельник 28 июня у здания мэрии Москвы на...</td>\n",
              "      <td>O O O O O O B_ORG I_ORG O B_LOC I_LOC O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1125</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1128</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>На заре первого дня Нового года нефть начали к...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O B_LOC ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1130 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-677c13e2-3b9e-4ea1-a625-f0b601d3dbc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-677c13e2-3b9e-4ea1-a625-f0b601d3dbc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-677c13e2-3b9e-4ea1-a625-f0b601d3dbc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 443
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"aug_iloc.csv\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "WzISQWloYwwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "oBaaMkJo-NSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CRF model for NER gave the worst result. Even after using word empendings as features.\n",
        "\n",
        "Deeppavlov's BERT model showed best result.   \n",
        "Among the parameters that influenced the high result was the selection of the input size - 160, which made it possible to increase the batch size to 32. The AdamW optimizer also gave an increase in fine tuning, and the settings of its hyperparameters: epsilon and learning rate.   \n",
        "The number of epochs over 35 led to overfitting and a decrease in the quality of the model. Experiments with dropout and max_grad_norm did not give any improvements, as a rule, everything led to a deterioration in the quality of the model.\n",
        "\n",
        "Attempts to augment the data did not allow to improve the quality of the model. Perhaps this would help if use bert-multilingual model.  \n",
        "Upsampling allowed to improve the results, obviously there are very few examples with the I_LOC tag in the sample, most of the errors fall on it. "
      ],
      "metadata": {
        "id": "1aw8hZI1-pT2"
      }
    }
  ]
}